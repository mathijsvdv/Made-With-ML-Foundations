{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Machine Learning\n",
    "Explore utilities to extend and simplify preprocessing and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up\n",
    "We're having to set a lot of seeds for reproducibility now, so let's wrap it all up in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "cuda = True\n",
    "device = torch.device(\"cuda\" if (\n",
    "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "if device.type == \"cuda\":\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "We'll use the same spiral dataset from previous lessons to demonstrate our utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mlopsfd.datasets import generate_spirals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.320767</td>\n",
       "      <td>0.145567</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029032</td>\n",
       "      <td>0.132386</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180597</td>\n",
       "      <td>0.206408</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079140</td>\n",
       "      <td>0.094877</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.237548</td>\n",
       "      <td>0.109245</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-7.606522</td>\n",
       "      <td>2.025510</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-7.573552</td>\n",
       "      <td>1.841280</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-7.548512</td>\n",
       "      <td>2.280927</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-7.981224</td>\n",
       "      <td>1.829948</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-8.208505</td>\n",
       "      <td>1.741706</td>\n",
       "      <td>c3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2 color\n",
       "0   -0.320767  0.145567    c1\n",
       "1    0.029032  0.132386    c1\n",
       "2    0.180597  0.206408    c1\n",
       "3    0.079140  0.094877    c1\n",
       "4    0.237548  0.109245    c1\n",
       "..        ...       ...   ...\n",
       "495 -7.606522  2.025510    c3\n",
       "496 -7.573552  1.841280    c3\n",
       "497 -7.548512  2.280927    c3\n",
       "498 -7.981224  1.829948    c3\n",
       "499 -8.208505  1.741706    c3\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_spirals()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (1500, 2)\n",
      "y:  (1500,)\n"
     ]
    }
   ],
   "source": [
    "# Data shapes\n",
    "X = df[[\"X1\", \"X2\"]].values\n",
    "y = df[\"color\"].values\n",
    "print (\"X: \", np.shape(X))\n",
    "print (\"y: \", np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data\n",
    "plt.title(\"Generated non-linear data\")\n",
    "colors = {\"c1\": \"red\", \"c2\": \"yellow\", \"c3\": \"blue\"}\n",
    "plt.scatter(X[:, 0], X[:, 1], c=[colors[_y] for _y in y], edgecolors=\"k\", s=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7\n",
    "VAL_SIZE = 0.15\n",
    "TEST_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size):\n",
    "    \"\"\"Split dataset into data splits.\"\"\"\n",
    "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1050, 2), y_train: (1050,)\n",
      "X_val: (225, 2), y_val: (225,)\n",
      "X_test: (225, 2), y_test: (225,)\n",
      "Sample point: [-0.56183286  0.58527567] â†’ c2\n"
     ]
    }
   ],
   "source": [
    "# Create data splits\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    X=X, y=y, train_size=TRAIN_SIZE)\n",
    "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
    "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print (f\"Sample point: {X_train[0]} â†’ {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding\n",
    "Next we'll define a `LabelEncoder` to encode our text labels into unique indices. We're not going to use scikit-learn's LabelEncoder anymore because we want to be able to save and load our instances the way we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(object):\n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self, class_to_index={}):\n",
    "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "\n",
    "    def fit(self, y):\n",
    "        classes = np.unique(y)\n",
    "        for i, class_ in enumerate(classes):\n",
    "            self.class_to_index[class_] = i\n",
    "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
    "        self.classes = list(self.class_to_index.keys())\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        encoded = np.zeros((len(y)), dtype=int)\n",
    "        for i, item in enumerate(y):\n",
    "            encoded[i] = self.class_to_index[item]\n",
    "        return encoded\n",
    "\n",
    "    def decode(self, y):\n",
    "        classes = []\n",
    "        for i, item in enumerate(y):\n",
    "            classes.append(self.index_to_class[item])\n",
    "        return classes\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {'class_to_index': self.class_to_index}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c1': 0, 'c2': 1, 'c3': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "label_encoder.class_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train[0]: c2\n",
      "y_train[0]: 1\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tokens\n",
    "print (f\"y_train[0]: {y_train[0]}\")\n",
    "y_train = label_encoder.encode(y_train)\n",
    "y_val = label_encoder.encode(y_val)\n",
    "y_test = label_encoder.encode(y_test)\n",
    "print (f\"y_train[0]: {y_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: [350 350 350]\n",
      "weights: {0: 0.002857142857142857, 1: 0.002857142857142857, 2: 0.002857142857142857}\n"
     ]
    }
   ],
   "source": [
    "# Class weights\n",
    "counts = np.bincount(y_train)\n",
    "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
    "print (f\"counts: {counts}\\nweights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data\n",
    "We need to standardize our data (zero mean and unit variance) so a specific feature's magnitude doesn't affect how the model learns its weights. We're only going to standardize the inputs X because our outputs y are class values. We're going to compose our own `StandardScaler` class so we can easily save and load it later during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(object):\n",
    "    def __init__(self, mean=None, std=None):\n",
    "        self.mean = np.array(mean)\n",
    "        self.std = np.array(std)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean =  np.mean(X_train, axis=0)\n",
    "        self.std = np.std(X_train, axis=0)\n",
    "\n",
    "    def scale(self, X):\n",
    "        return (X - self.mean) / self.std\n",
    "\n",
    "    def unscale(self, X):\n",
    "        return (X * self.std) + self.mean\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = {\"mean\": self.mean.tolist(), \"std\": self.std.tolist()}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data (mean=0, std=1) using training data\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler on training and test data (don't standardize outputs for classification)\n",
    "X_train = X_scaler.scale(X_train)\n",
    "X_val = X_scaler.scale(X_val)\n",
    "X_test = X_scaler.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test[0]: mean: -0.0, std: 1.0\n",
      "X_test[1]: mean: 0.1, std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check (means should be ~0 and std should be ~1)\n",
    "print (f\"X_test[0]: mean: {np.mean(X_test[:, 0], axis=0):.1f}, std: {np.std(X_test[:, 0], axis=0):.1f}\")\n",
    "print (f\"X_test[1]: mean: {np.mean(X_test[:, 1], axis=0):.1f}, std: {np.std(X_test[:, 1], axis=0):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "We're going to place our data into a `Dataset` and use a `DataLoader` to efficiently create batches for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc351ca49f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed seed for reproducibility\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Dataset(N={len(self)})>\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "        return (X, y)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Processing on a batch.\"\"\"\n",
    "        # Get inputs\n",
    "        X = np.stack([Xy[0] for Xy in batch], axis=0)\n",
    "        y = np.array([Xy[1] for Xy in batch])\n",
    "\n",
    "        # Cast\n",
    "        X = torch.FloatTensor(X.astype(np.float32))\n",
    "        y = torch.LongTensor(y.astype(np.int32))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset=self, \n",
    "            batch_size=batch_size, \n",
    "            collate_fn=self.collate_fn,\n",
    "            shuffle=shuffle, \n",
    "            drop_last=drop_last,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really need the `collate_fn` here but we wanted to make it transparent because we will need it when we want to do specific processing on our batch (ex. padding).\n",
    "\n",
    "> **Note**: when `pin_memory=True` we cannot put a batch directly on the GPU through `torch.cuda.FloatTensor` during `collate_fn`. According to https://discuss.pytorch.org/t/when-to-set-pin-memory-to-true/19723 this is intended: the best practice when data are first loaded on CPU is to keep it on the CPU during data loading, and to convert the samples to the GPU during training. This is faster because the device can then use page-locked (or \"pinned\") memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train dataset:<Dataset(N=1050)>\n",
      "  Val dataset: <Dataset(N=225)>\n",
      "  Test dataset: <Dataset(N=225)>\n",
      "Sample point:\n",
      "  X: [-0.18217904  0.18515521]\n",
      "  y: 1\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = Dataset(X=X_train, y=y_train)\n",
    "val_dataset = Dataset(X=X_val, y=y_val)\n",
    "test_dataset = Dataset(X=X_test, y=y_test)\n",
    "print (\"Datasets:\\n\"\n",
    "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
    "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
    "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {train_dataset[0][0]}\\n\"\n",
    "    f\"  y: {train_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we used batch gradient descent to update our weights. This means that we calculated the gradients using the entire training dataset. We also could've updated our weights using stochastic gradient descent (SGD) where we pass in one training example one at a time. The current standard is **mini-batch gradient descent**, which strikes a balance between batch and SGD, where we update the weights using a mini-batch of n (`BATCH_SIZE`) samples. This is where the `DataLoader` object comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X\n",
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch:\n",
      "  X: torch.Size([64, 2])\n",
      "  y: torch.Size([64])\n",
      "Sample point:\n",
      "  X: tensor([-0.1822,  0.1852], device='cpu')\n",
      "  y: 1\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
    "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
    "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print (\"Sample batch:\\n\"\n",
    "    f\"  X: {batch_X.size()}\\n\"\n",
    "    f\"  y: {batch_y.size()}\\n\"\n",
    "    \"Sample point:\\n\"\n",
    "    f\"  X: {batch_X[0]}\\n\"\n",
    "    f\"  y: {batch_y[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device\n",
    "So far we've been running our operations on the CPU but when we have large datasets and larger models to train, we can benefit by parallelizing tensor operations on a GPU. We can check what device we're using with the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA seeds\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Let's initialize the model we'll be using to show the capbabilities of training utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[1] # 2D\n",
    "HIDDEN_DIM = 100\n",
    "DROPOUT_P = 0.1\n",
    "NUM_CLASSES = len(label_encoder.classes)\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_p, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_in, = inputs\n",
    "        z = F.relu(self.fc1(x_in))\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n",
    "\n",
    "    @classmethod\n",
    "    def from_state_dict(cls, state_dict, dropout_p) -> 'MLP':\n",
    "        hidden_dim, input_dim = state_dict[\"fc1.weight\"].size()\n",
    "        num_classes, _ = state_dict[\"fc2.weight\"].size()\n",
    "        return cls(input_dim=input_dim, hidden_dim=hidden_dim, dropout_p=dropout_p,\n",
    "                   num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fc1.weight', Parameter containing:\n",
      "tensor([[-2.5457e-01,  4.5424e-01],\n",
      "        [ 2.1109e-01,  5.5829e-01],\n",
      "        [ 6.5903e-01,  5.8666e-01],\n",
      "        [-3.7765e-01, -6.7770e-02],\n",
      "        [-3.7235e-01,  1.5953e-01],\n",
      "        [ 1.6267e-01, -5.2810e-04],\n",
      "        [-2.5949e-01,  3.3865e-01],\n",
      "        [-5.5655e-01,  1.1334e-02],\n",
      "        [ 2.7695e-01, -1.9373e-01],\n",
      "        [ 1.8486e-01, -1.9365e-01],\n",
      "        [ 1.8451e-01, -3.4211e-01],\n",
      "        [ 1.8842e-01,  5.9595e-01],\n",
      "        [ 1.3800e-01, -4.5472e-01],\n",
      "        [ 1.8549e-01, -6.4175e-01],\n",
      "        [-5.6152e-01, -4.0109e-02],\n",
      "        [ 1.7428e-01,  5.4698e-01],\n",
      "        [ 2.3953e-01, -4.3423e-01],\n",
      "        [-7.0605e-01,  1.0202e-01],\n",
      "        [-5.2323e-01, -7.0536e-01],\n",
      "        [-2.4355e-01, -3.2761e-01],\n",
      "        [-3.4750e-01,  5.7307e-02],\n",
      "        [ 2.1259e-01,  7.4052e-02],\n",
      "        [-2.0358e-01,  1.5069e-01],\n",
      "        [ 6.3600e-02,  1.4549e-01],\n",
      "        [-1.6464e-01,  5.0790e-01],\n",
      "        [-6.9226e-01,  4.8178e-02],\n",
      "        [ 2.2339e-01, -4.0150e-01],\n",
      "        [-6.0065e-01, -6.9128e-02],\n",
      "        [ 1.0469e-01,  6.2183e-01],\n",
      "        [-4.7082e-01,  3.1473e-01],\n",
      "        [-2.8074e-01,  1.0582e-01],\n",
      "        [ 2.0740e-01,  2.8835e-01],\n",
      "        [ 3.8968e-02, -1.1151e-01],\n",
      "        [-6.0802e-01, -1.3162e-01],\n",
      "        [-3.0755e-01,  1.7601e-01],\n",
      "        [-3.3625e-01,  1.8660e-01],\n",
      "        [ 3.9361e-02, -3.0282e-01],\n",
      "        [ 6.6088e-01,  2.7642e-01],\n",
      "        [ 5.0746e-01,  8.7669e-02],\n",
      "        [-8.4362e-03,  6.9371e-01],\n",
      "        [ 1.6466e-01,  2.4040e-01],\n",
      "        [ 1.1479e-02,  2.1010e-02],\n",
      "        [-1.7196e-01,  5.7200e-01],\n",
      "        [ 4.1670e-01,  5.6629e-01],\n",
      "        [ 6.7594e-02, -2.6531e-01],\n",
      "        [-4.9760e-01, -3.9280e-01],\n",
      "        [-6.0699e-01,  5.9563e-01],\n",
      "        [-6.1974e-01, -4.8507e-01],\n",
      "        [ 1.5046e-01, -4.9424e-01],\n",
      "        [ 2.7296e-01,  6.6648e-01],\n",
      "        [ 2.1398e-02,  2.9438e-01],\n",
      "        [-5.7748e-01,  1.2813e-01],\n",
      "        [ 3.9717e-01, -5.9364e-01],\n",
      "        [ 6.2272e-01, -6.5801e-01],\n",
      "        [-4.8714e-01, -5.7121e-01],\n",
      "        [-5.0090e-01, -8.0663e-02],\n",
      "        [ 2.0187e-03,  3.6100e-01],\n",
      "        [-4.7919e-01, -3.2978e-01],\n",
      "        [ 5.0104e-01,  3.4553e-01],\n",
      "        [ 3.4768e-02,  5.3717e-01],\n",
      "        [-6.0247e-01,  6.0487e-01],\n",
      "        [-7.0675e-01, -4.9370e-02],\n",
      "        [ 4.5079e-01,  6.1515e-02],\n",
      "        [ 4.1856e-01,  3.4834e-02],\n",
      "        [-3.3405e-01, -3.6219e-01],\n",
      "        [-2.2463e-01, -6.3902e-01],\n",
      "        [ 8.5444e-02, -1.8921e-01],\n",
      "        [ 6.4016e-01,  1.8810e-01],\n",
      "        [-6.8507e-01,  2.7024e-01],\n",
      "        [-4.4033e-01,  1.0705e-05],\n",
      "        [-5.6077e-03,  2.3004e-01],\n",
      "        [-1.1851e-01, -3.5341e-01],\n",
      "        [-9.0247e-02, -5.2402e-01],\n",
      "        [ 4.9944e-01, -3.8644e-01],\n",
      "        [ 6.7457e-01, -7.0187e-02],\n",
      "        [ 6.8534e-01, -3.1630e-01],\n",
      "        [ 4.8454e-01, -8.0983e-02],\n",
      "        [ 6.7892e-01,  1.7639e-01],\n",
      "        [ 3.2522e-02,  2.7881e-01],\n",
      "        [-5.2566e-01, -2.3706e-01],\n",
      "        [ 1.9199e-01,  6.6464e-03],\n",
      "        [-6.8588e-01, -2.4035e-01],\n",
      "        [ 2.9528e-01,  6.3532e-02],\n",
      "        [-6.2176e-01,  1.5916e-01],\n",
      "        [-6.8398e-01,  6.3565e-01],\n",
      "        [ 2.7756e-01, -6.9676e-02],\n",
      "        [-3.7361e-01,  1.4455e-01],\n",
      "        [-5.3249e-01,  2.7767e-01],\n",
      "        [ 5.4243e-01, -3.2530e-01],\n",
      "        [-4.3285e-01,  1.5854e-01],\n",
      "        [ 5.6070e-01, -1.1754e-01],\n",
      "        [ 6.4338e-01, -2.0028e-01],\n",
      "        [ 3.0836e-01,  5.0976e-01],\n",
      "        [ 8.3040e-02, -4.1751e-01],\n",
      "        [ 3.5055e-01, -5.3404e-01],\n",
      "        [-1.0988e-02, -4.2207e-01],\n",
      "        [ 4.3774e-01, -4.4348e-01],\n",
      "        [ 2.6654e-01,  3.8776e-01],\n",
      "        [-7.0380e-01,  5.1604e-01],\n",
      "        [ 8.8929e-02,  3.2022e-01]], device='cpu', requires_grad=True)), ('fc1.bias', Parameter containing:\n",
      "tensor([-0.4526, -0.2637,  0.0903,  0.3050, -0.3071, -0.5484,  0.5086, -0.3889,\n",
      "        -0.6410,  0.2312, -0.4876, -0.6228, -0.5237,  0.1513, -0.3289, -0.3053,\n",
      "         0.3952,  0.6950,  0.1228,  0.5186, -0.4140, -0.3564, -0.3437,  0.4962,\n",
      "         0.5227, -0.6694,  0.6843,  0.3912, -0.5382, -0.1985,  0.7044,  0.3704,\n",
      "         0.4940, -0.0921,  0.6106,  0.5530,  0.5977,  0.0934,  0.2969,  0.0136,\n",
      "         0.3659, -0.6746,  0.1036,  0.6874, -0.0519, -0.5704,  0.5241,  0.6645,\n",
      "         0.0123, -0.4082, -0.5893,  0.0608,  0.0506, -0.6560,  0.1802, -0.4716,\n",
      "         0.3178,  0.6907, -0.5386, -0.6951, -0.6098, -0.1401,  0.2073,  0.5707,\n",
      "        -0.4124, -0.0018,  0.3334, -0.3819, -0.2594, -0.5666,  0.2999,  0.3747,\n",
      "         0.0058,  0.4749,  0.1588,  0.1834, -0.2520,  0.6782, -0.1012,  0.2893,\n",
      "        -0.1433, -0.2198,  0.2559,  0.5715, -0.5221, -0.2205,  0.6486, -0.5166,\n",
      "        -0.3007, -0.4320, -0.4566, -0.6317, -0.4966,  0.5369,  0.2959, -0.1055,\n",
      "        -0.1289, -0.1199, -0.1163, -0.5366], device='cpu', requires_grad=True)), ('fc2.weight', Parameter containing:\n",
      "tensor([[-0.0154,  0.0592,  0.0522, -0.0810,  0.0076,  0.0516,  0.0759, -0.0987,\n",
      "         -0.0449,  0.0317,  0.0739, -0.0293,  0.0543,  0.0600,  0.0209,  0.0206,\n",
      "         -0.0811,  0.0445,  0.0549,  0.0446,  0.0976,  0.0321,  0.0086, -0.0440,\n",
      "         -0.0698,  0.0055, -0.0002, -0.0211,  0.0668,  0.0046,  0.0257,  0.0653,\n",
      "          0.0851, -0.0985,  0.0571, -0.0609,  0.0636, -0.0717, -0.0689,  0.0668,\n",
      "         -0.0396,  0.0080, -0.0809,  0.0934,  0.0402,  0.0468, -0.0258,  0.0992,\n",
      "         -0.0123, -0.0581, -0.0344,  0.0329,  0.0979, -0.0277, -0.0428, -0.0107,\n",
      "         -0.0221, -0.0169,  0.0918, -0.0935, -0.0449,  0.0684,  0.0090,  0.0094,\n",
      "         -0.0794, -0.0705,  0.0664,  0.0555, -0.0594,  0.0683, -0.0891, -0.0056,\n",
      "         -0.0363, -0.0717, -0.0815,  0.0803,  0.0710, -0.0432,  0.0114, -0.0938,\n",
      "         -0.0576, -0.0452, -0.0375, -0.0891,  0.0856,  0.0268, -0.0063, -0.0331,\n",
      "          0.0645, -0.0125, -0.0648, -0.0281, -0.0644,  0.0707,  0.0187,  0.0548,\n",
      "         -0.0721,  0.0050,  0.0358, -0.0425],\n",
      "        [-0.0681,  0.0426,  0.0531,  0.0532,  0.0832,  0.0011, -0.0479, -0.0389,\n",
      "         -0.0964, -0.0255, -0.0906, -0.0196, -0.0728, -0.0670,  0.0109,  0.0715,\n",
      "          0.0607,  0.0462,  0.0216, -0.0184,  0.0711, -0.0322, -0.0244, -0.0419,\n",
      "         -0.0961, -0.0632, -0.0318, -0.0488, -0.0811,  0.0141, -0.0103, -0.0807,\n",
      "         -0.0099,  0.0580,  0.0429, -0.0745,  0.0932,  0.0100,  0.0599,  0.0060,\n",
      "         -0.0522,  0.0593, -0.0843, -0.0763,  0.0667,  0.0705,  0.0179,  0.0352,\n",
      "          0.0342,  0.0445, -0.0817,  0.0052, -0.0853, -0.0376,  0.0472, -0.0303,\n",
      "          0.0972, -0.0273,  0.0444,  0.0846, -0.0512, -0.0424, -0.0097,  0.0629,\n",
      "         -0.0521, -0.0324, -0.0194, -0.0572,  0.0410, -0.0968, -0.0811,  0.0281,\n",
      "         -0.0146,  0.0526,  0.0392,  0.0779,  0.0252,  0.0203,  0.0830, -0.0991,\n",
      "          0.0089,  0.0747, -0.0417,  0.0047,  0.0492,  0.0963,  0.0112,  0.0916,\n",
      "          0.0213, -0.0461, -0.0336,  0.0070, -0.0642, -0.0767,  0.0628,  0.0207,\n",
      "          0.0441, -0.0264,  0.0169,  0.0250],\n",
      "        [ 0.0953,  0.0259, -0.0977,  0.0232,  0.0906, -0.0529, -0.0416,  0.0874,\n",
      "          0.0102,  0.0487, -0.0488,  0.0030,  0.0044, -0.0623, -0.0311, -0.0377,\n",
      "         -0.0110, -0.0056, -0.0802,  0.0807, -0.0047,  0.0781, -0.0334, -0.0550,\n",
      "          0.0384,  0.0151,  0.0839,  0.0917, -0.0269,  0.0875, -0.0544, -0.0863,\n",
      "         -0.0767,  0.0575, -0.0880, -0.0425,  0.0320,  0.0955, -0.0653,  0.0045,\n",
      "         -0.0180,  0.0517, -0.0274,  0.0432,  0.0278, -0.0770,  0.0985,  0.0219,\n",
      "         -0.0666,  0.0753, -0.0040,  0.0456,  0.0539,  0.0222,  0.0356,  0.0869,\n",
      "         -0.0969, -0.0192, -0.0251,  0.0549,  0.0439, -0.0845,  0.0992, -0.0979,\n",
      "          0.0558,  0.0932, -0.0697, -0.0552, -0.0490, -0.0793, -0.0533, -0.0560,\n",
      "         -0.0394,  0.0198, -0.0938,  0.0864,  0.0184,  0.0332, -0.0208, -0.0129,\n",
      "          0.0310, -0.0742,  0.0881,  0.0536, -0.0120, -0.0937, -0.0580,  0.0432,\n",
      "          0.0963, -0.0905,  0.0428,  0.0736, -0.0731, -0.0599, -0.0992, -0.0080,\n",
      "          0.0843,  0.0262, -0.0173,  0.0452]], device='cpu',\n",
      "       requires_grad=True)), ('fc2.bias', Parameter containing:\n",
      "tensor([ 0.0794,  0.0852, -0.0810], device='cpu', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = MLP(\n",
    "    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "So far we've been writing training loops that train only using the train data split and then we perform evaluation on our test set. But in reality, we would follow this process:\n",
    "\n",
    "1. Train using mini-batches on one epoch of the train data split.\n",
    "1. Evaluate loss on the validation split and use it to adjust hyperparameters (ex. learning rate).\n",
    "1. After training ends (via stagnation in improvements, desired performance, etc.), evaluate your trained model on the test (hold-out) data split.\n",
    "We'll create a `Trainer` class to keep all of these processes organized.\n",
    "\n",
    "The first function in the class is `train_step` which will train the model using batches from one epoch of the train data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(self, dataloader):\n",
    "    \"\"\"Train step.\"\"\"\n",
    "    # Set model to train mode. This is important to keep `Dropout` layers activated.\n",
    "    self.model.train()\n",
    "    loss = 0.0\n",
    "\n",
    "    # Iterate over train batches\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Step\n",
    "        batch = [item.to(self.device) for item in batch]  # Set device\n",
    "        inputs, targets = batch[:-1], batch[-1]\n",
    "        self.optimizer.zero_grad()  # Reset gradients\n",
    "        z = self.model(inputs)  # Forward pass\n",
    "        J = self.loss_fn(z, targets)  # Define loss\n",
    "        J.backward()  # Backward pass\n",
    "        self.optimizer.step()  # Update weights\n",
    "\n",
    "        # Cumulative Metrics\n",
    "        loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define the `eval_step` which will be used for processing both the validation and test data splits. This is because neither of them require gradient updates and display the same metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(self, dataloader):\n",
    "    \"\"\"Validation or test step.\"\"\"\n",
    "    # Set model to eval mode. This is important to deactivate the `Dropout` layers.\n",
    "    self.model.eval()\n",
    "    loss = 0.0\n",
    "    y_trues, y_probs = [], []\n",
    "\n",
    "    # Iterate over val batches\n",
    "    # Inference mode is set because we don't need any gradients during evaluation\n",
    "    with torch.inference_mode():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, y_true = batch[:-1], batch[-1]\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J - loss) / (i + 1)\n",
    "\n",
    "            # Store outputs\n",
    "            y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "            y_probs.extend(y_prob)\n",
    "            y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "    return loss, np.vstack(y_trues), np.vstack(y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final function is the `predict_step` which will be used for inference. It's fairly similar to the `eval_step` except we don't calculate any metrics. We pass on the predictions which we can use to generate our performance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step(self, dataloader):\n",
    "    \"\"\"Prediction step.\"\"\"\n",
    "    # Set model to eval mode\n",
    "    self.model.eval()\n",
    "    y_probs = []\n",
    "\n",
    "    # Iterate over val batches\n",
    "    with torch.inference_mode():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Forward pass w/ inputs\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            z = self.model(inputs)\n",
    "\n",
    "            # Store outputs\n",
    "            y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "            y_probs.extend(y_prob)\n",
    "\n",
    "    return np.vstack(y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR scheduler\n",
    "As our model starts to optimize and perform better, the loss will reduce and we'll need to make smaller adjustments. If we keep using a fixed learning rate, we'll be overshooting back and forth. Therefore, we're going to add a learning rate scheduler to our optimizer to adjust our learning rate during training. There are many schedulers to choose from but a popular one is `ReduceLROnPlateau` which reduces the learning rate when a metric (ex. validation loss) stops improving. In the example below we'll reduce the learning rate by a factor of 0.1 (`factor=0.1`) when our metric of interest (`self.scheduler.step(val_loss)`) stops decreasing (`mode=\"min\"`) for three (`patience=3`) straight epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the LR scheduler\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode=\"min\", factor=0.1, patience=3)\n",
    "# ...\n",
    "# train_loop():\n",
    "#     ...\n",
    "#     # Steps\n",
    "#     train_loss = trainer.train_step(dataloader=train_dataloader)\n",
    "#     val_loss, _, _ = trainer.eval_step(dataloader=val_dataloader)\n",
    "#     self.scheduler.step(val_loss)\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping\n",
    "We should never train our models for an arbitrary number of epochs but instead we should have explicit stopping criteria (even if you are bootstrapped by compute resources). Common stopping criteria include when validation performance stagnates for certain # of epochs (`patience`), desired performance is reached, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Early stopping\n",
    "# if val_loss < best_val_loss:\n",
    "#     best_val_loss = val_loss\n",
    "#     best_model = trainer.model\n",
    "#     _patience = patience  # reset _patience\n",
    "# else:\n",
    "#     _patience -= 1\n",
    "# if not _patience:  # 0\n",
    "#     print(\"Stopping early!\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Let's put all of this together now to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the `Trainer` provided by the course. I will define a different `EasyTrainer` that I think is easier to use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def train_step(self, dataloader):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = self.model\n",
    "                _patience = patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer module\n",
    "trainer = Trainer(\n",
    "    model=model, device=device, loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.87545, val_loss: 0.77911, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 2 | train_loss: 0.68456, val_loss: 0.62621, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 3 | train_loss: 0.54636, val_loss: 0.49209, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 4 | train_loss: 0.43630, val_loss: 0.38866, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 5 | train_loss: 0.35133, val_loss: 0.31905, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 6 | train_loss: 0.28382, val_loss: 0.27043, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 7 | train_loss: 0.24353, val_loss: 0.23336, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 8 | train_loss: 0.21231, val_loss: 0.20599, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 9 | train_loss: 0.19496, val_loss: 0.18754, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 10 | train_loss: 0.17923, val_loss: 0.17430, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 11 | train_loss: 0.16900, val_loss: 0.16102, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 12 | train_loss: 0.15726, val_loss: 0.14605, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 13 | train_loss: 0.14378, val_loss: 0.13926, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 14 | train_loss: 0.14313, val_loss: 0.13510, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 15 | train_loss: 0.14085, val_loss: 0.12739, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 16 | train_loss: 0.12521, val_loss: 0.12211, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 17 | train_loss: 0.11752, val_loss: 0.11417, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 18 | train_loss: 0.11945, val_loss: 0.10731, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 19 | train_loss: 0.11694, val_loss: 0.11568, lr: 1.00E-02, _patience: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | train_loss: 0.10986, val_loss: 0.10360, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 21 | train_loss: 0.10797, val_loss: 0.10182, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 22 | train_loss: 0.10052, val_loss: 0.09590, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 23 | train_loss: 0.09105, val_loss: 0.09324, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 24 | train_loss: 0.09948, val_loss: 0.09669, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 25 | train_loss: 0.09234, val_loss: 0.08992, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 26 | train_loss: 0.08586, val_loss: 0.08696, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 27 | train_loss: 0.09023, val_loss: 0.08768, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 28 | train_loss: 0.08875, val_loss: 0.08414, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 29 | train_loss: 0.09283, val_loss: 0.08268, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 30 | train_loss: 0.08565, val_loss: 0.08142, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 31 | train_loss: 0.08060, val_loss: 0.08217, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 32 | train_loss: 0.08428, val_loss: 0.07856, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 33 | train_loss: 0.07799, val_loss: 0.07738, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 34 | train_loss: 0.07897, val_loss: 0.08286, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 35 | train_loss: 0.07977, val_loss: 0.07663, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 36 | train_loss: 0.07480, val_loss: 0.07166, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 37 | train_loss: 0.07996, val_loss: 0.07328, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 38 | train_loss: 0.07134, val_loss: 0.07392, lr: 1.00E-02, _patience: 4\n",
      "Epoch: 39 | train_loss: 0.07849, val_loss: 0.07450, lr: 1.00E-02, _patience: 3\n",
      "Epoch: 40 | train_loss: 0.07710, val_loss: 0.07213, lr: 1.00E-03, _patience: 2\n",
      "Epoch: 41 | train_loss: 0.07747, val_loss: 0.07134, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 42 | train_loss: 0.06971, val_loss: 0.07087, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 43 | train_loss: 0.06745, val_loss: 0.07045, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 44 | train_loss: 0.06705, val_loss: 0.07028, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 45 | train_loss: 0.07278, val_loss: 0.06993, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 46 | train_loss: 0.06883, val_loss: 0.07039, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 47 | train_loss: 0.07311, val_loss: 0.06967, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 48 | train_loss: 0.06757, val_loss: 0.06900, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 49 | train_loss: 0.06460, val_loss: 0.06861, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 50 | train_loss: 0.07094, val_loss: 0.06881, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 51 | train_loss: 0.06940, val_loss: 0.06885, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 52 | train_loss: 0.06946, val_loss: 0.06880, lr: 1.00E-03, _patience: 3\n",
      "Epoch: 53 | train_loss: 0.07161, val_loss: 0.06921, lr: 1.00E-04, _patience: 2\n",
      "Epoch: 54 | train_loss: 0.06849, val_loss: 0.06919, lr: 1.00E-04, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train(\n",
    "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, classes):\n",
    "    \"\"\"Per-class performance metrics.\"\"\"\n",
    "    # Performance\n",
    "    performance = {\"overall\": {}, \"class\": {}}\n",
    "\n",
    "    # Overall performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
    "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
    "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
    "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
    "\n",
    "    # Per-class performance\n",
    "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i in range(len(classes)):\n",
    "        performance[\"class\"][classes[i]] = {\n",
    "            \"precision\": metrics[0][i],\n",
    "            \"recall\": metrics[1][i],\n",
    "            \"f1\": metrics[2][i],\n",
    "            \"num_samples\": np.float64(metrics[3][i]),\n",
    "        }\n",
    "\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"precision\": 0.9825685425685426,\n",
      "  \"recall\": 0.9822222222222222,\n",
      "  \"f1\": 0.9822791212264897,\n",
      "  \"num_samples\": 225.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Determine performance\n",
    "performance = get_metrics(\n",
    "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
    "print (json.dumps(performance[\"overall\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving & Loading\n",
    "Many tutorials never show you how to save the components you created so you can load them for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "dir = Path(\"mlp\")\n",
    "dir.mkdir(parents=True, exist_ok=True)\n",
    "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
    "X_scaler.save(fp=Path(dir, \"X_scaler.json\"))\n",
    "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
    "with open(Path(dir, 'performance.json'), \"w\") as fp:\n",
    "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=2, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load artifacts\n",
    "device = torch.device(\"cpu\")\n",
    "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
    "X_scaler = StandardScaler.load(fp=Path(dir, \"X_scaler.json\"))\n",
    "model = MLP(\n",
    "    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "sample = [[0.106737, 0.114197]] # c1\n",
    "X = X_scaler.scale(sample)\n",
    "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
    "dataset = Dataset(X=X, y=y_filler)\n",
    "dataloader = dataset.create_dataloader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c1']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "y_prob = trainer.predict_step(dataloader)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "label_encoder.decode(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous\n",
    "There are lots of other utilities to cover, such as:\n",
    "\n",
    "- Tokenizers to convert text to sequence of indices\n",
    "- Various encoders to represent our data\n",
    "- Padding to ensure uniform data shapes\n",
    "- Experiment tracking to visualize and keep track of all experiments\n",
    "- Hyperparameter optimization to tune our parameters (layers, learning rate, etc.)\n",
    "- and many more!\n",
    "\n",
    "We'll explore these as we require them in future lessons including some in our [MLOps](https://madewithml.com/courses/mlops/) course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `EasyTrainer`\n",
    "Let's encapsulate the whole training loop by defining `EasyTrainer`. This not only stores\n",
    "the model but also the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fc1.weight', Parameter containing:\n",
      "tensor([[-0.4186, -0.5353],\n",
      "        [-0.1315, -0.0952],\n",
      "        [ 0.1397,  0.2314],\n",
      "        [-0.1600, -0.5962],\n",
      "        [-0.0247,  0.6994],\n",
      "        [-0.4654, -0.6202],\n",
      "        [-0.1917, -0.1089],\n",
      "        [-0.0433, -0.6509],\n",
      "        [-0.4101, -0.4368],\n",
      "        [ 0.4389, -0.3832],\n",
      "        [ 0.5626, -0.1240],\n",
      "        [ 0.2825,  0.0843],\n",
      "        [-0.1354, -0.3851],\n",
      "        [-0.1515,  0.4293],\n",
      "        [ 0.4537, -0.4894],\n",
      "        [ 0.5991, -0.3968],\n",
      "        [ 0.1154,  0.3706],\n",
      "        [ 0.4812,  0.2053],\n",
      "        [-0.4302,  0.5093],\n",
      "        [-0.3511,  0.1611],\n",
      "        [ 0.3038,  0.0930],\n",
      "        [ 0.0196,  0.2816],\n",
      "        [ 0.4352, -0.4764],\n",
      "        [ 0.1289, -0.5488],\n",
      "        [-0.4153, -0.6056],\n",
      "        [-0.1902,  0.3969],\n",
      "        [ 0.6588,  0.4475],\n",
      "        [ 0.0467, -0.6897],\n",
      "        [-0.5974,  0.5002],\n",
      "        [ 0.0687,  0.0271],\n",
      "        [-0.3617, -0.2159],\n",
      "        [-0.0560,  0.3130],\n",
      "        [-0.4321,  0.0862],\n",
      "        [-0.1072,  0.2485],\n",
      "        [-0.6742,  0.2697],\n",
      "        [-0.2975, -0.3883],\n",
      "        [ 0.5337,  0.3933],\n",
      "        [ 0.1818,  0.2904],\n",
      "        [ 0.3922, -0.4533],\n",
      "        [-0.1760, -0.6236],\n",
      "        [ 0.1806,  0.1982],\n",
      "        [-0.2737,  0.3279],\n",
      "        [ 0.6672,  0.4799],\n",
      "        [-0.4797, -0.1352],\n",
      "        [-0.1285,  0.2210],\n",
      "        [ 0.2650,  0.3612],\n",
      "        [-0.6987,  0.4356],\n",
      "        [ 0.3586, -0.4192],\n",
      "        [-0.1586,  0.4622],\n",
      "        [-0.1878,  0.2749],\n",
      "        [ 0.4110, -0.1324],\n",
      "        [-0.0238,  0.2277],\n",
      "        [ 0.4005, -0.2774],\n",
      "        [-0.0877,  0.3935],\n",
      "        [ 0.1466,  0.6524],\n",
      "        [-0.5745,  0.6333],\n",
      "        [-0.6594,  0.0305],\n",
      "        [-0.5054,  0.1476],\n",
      "        [-0.3330,  0.0295],\n",
      "        [-0.3652,  0.0972],\n",
      "        [ 0.1040,  0.6300],\n",
      "        [ 0.2879, -0.0075],\n",
      "        [-0.1941, -0.2301],\n",
      "        [-0.0964,  0.5866],\n",
      "        [ 0.5761,  0.4954],\n",
      "        [-0.5767, -0.2659],\n",
      "        [ 0.6414, -0.1124],\n",
      "        [-0.0229, -0.3168],\n",
      "        [-0.3265,  0.5383],\n",
      "        [ 0.7070,  0.3617],\n",
      "        [-0.6519,  0.0849],\n",
      "        [ 0.5895, -0.5866],\n",
      "        [-0.4464,  0.3071],\n",
      "        [ 0.4588, -0.3221],\n",
      "        [-0.6056, -0.6925],\n",
      "        [ 0.0951, -0.4739],\n",
      "        [-0.0919,  0.4668],\n",
      "        [-0.6857,  0.5449],\n",
      "        [-0.6660, -0.1084],\n",
      "        [ 0.0553,  0.0568],\n",
      "        [ 0.5804,  0.3291],\n",
      "        [-0.1328, -0.6364],\n",
      "        [-0.0141,  0.5316],\n",
      "        [-0.5333,  0.4238],\n",
      "        [ 0.6434, -0.5027],\n",
      "        [ 0.0753,  0.2296],\n",
      "        [ 0.7029,  0.3695],\n",
      "        [-0.4882,  0.2349],\n",
      "        [-0.1508, -0.0422],\n",
      "        [-0.2426,  0.6158],\n",
      "        [-0.0504,  0.1075],\n",
      "        [-0.3843,  0.3732],\n",
      "        [ 0.5574,  0.3455],\n",
      "        [ 0.4472, -0.3031],\n",
      "        [-0.1277, -0.1760],\n",
      "        [ 0.0420,  0.6370],\n",
      "        [ 0.6748,  0.0268],\n",
      "        [-0.4847,  0.6468],\n",
      "        [ 0.1927,  0.3934],\n",
      "        [ 0.2201, -0.6419]], device='cpu', requires_grad=True)), ('fc1.bias', Parameter containing:\n",
      "tensor([-0.4465, -0.5147,  0.3154,  0.1000, -0.6094, -0.7039,  0.5985, -0.5635,\n",
      "        -0.4032, -0.6249, -0.5763, -0.6538,  0.0903,  0.1485,  0.0763,  0.1131,\n",
      "        -0.2585, -0.0922,  0.1974, -0.1743, -0.6257,  0.2382, -0.5916, -0.6333,\n",
      "         0.5903,  0.2552, -0.6441,  0.2931, -0.5558,  0.2372, -0.3544, -0.4565,\n",
      "         0.6357,  0.6613,  0.3518, -0.4001,  0.6235, -0.1350,  0.1136, -0.6382,\n",
      "         0.3791,  0.6675,  0.7039, -0.2119,  0.5899,  0.6389, -0.2647,  0.1680,\n",
      "         0.5803,  0.2526,  0.5723,  0.5966,  0.4838, -0.1898, -0.4572,  0.5804,\n",
      "        -0.5523, -0.1302,  0.1525, -0.4399,  0.5890, -0.3977, -0.1333,  0.1310,\n",
      "        -0.3012, -0.4800,  0.5974,  0.0527,  0.2977,  0.4021,  0.1781, -0.5491,\n",
      "         0.2945,  0.1230,  0.6526,  0.0250, -0.6345, -0.4077, -0.3794,  0.3203,\n",
      "        -0.2582, -0.3454,  0.0380,  0.1895,  0.4465, -0.1693, -0.6500, -0.1981,\n",
      "        -0.6146,  0.1278, -0.0857, -0.5442, -0.3599, -0.3736, -0.3015, -0.6272,\n",
      "        -0.4331,  0.4746, -0.2761, -0.1487], device='cpu', requires_grad=True)), ('fc2.weight', Parameter containing:\n",
      "tensor([[ 7.0840e-02,  3.1245e-02, -1.2441e-02, -5.4368e-02,  2.0177e-03,\n",
      "         -6.0675e-02, -9.9270e-02,  6.2190e-02, -5.4423e-02,  3.7383e-04,\n",
      "          1.6697e-02,  5.9855e-02, -8.0666e-02,  6.3965e-02, -4.5986e-02,\n",
      "         -5.4430e-02,  4.9839e-02,  7.0936e-02,  4.2337e-02,  7.3491e-03,\n",
      "          4.3791e-02, -1.0249e-02, -1.6329e-02,  4.6073e-02, -3.0960e-02,\n",
      "          8.3530e-02,  2.0681e-02,  4.7154e-02,  3.2586e-02,  7.4515e-02,\n",
      "         -4.0940e-02,  1.8858e-02, -3.1110e-02, -8.6153e-02,  3.8223e-02,\n",
      "          3.2831e-02, -2.0533e-02, -8.5996e-02,  2.3952e-02, -7.2214e-03,\n",
      "         -9.7992e-02, -8.5751e-03, -5.2453e-02, -6.1823e-02, -1.4559e-02,\n",
      "         -7.5455e-02,  4.0139e-02,  7.3669e-02, -1.9538e-02,  4.4036e-03,\n",
      "          3.3508e-02,  6.1105e-02, -4.1919e-02, -9.0633e-03, -4.7581e-02,\n",
      "          3.6016e-02, -8.5051e-02,  8.9722e-02, -5.9708e-03,  1.6979e-02,\n",
      "         -9.9159e-02,  7.9439e-02, -6.4692e-02,  2.9599e-02, -6.4272e-02,\n",
      "         -1.9547e-02,  9.9307e-02,  3.7075e-02, -5.9250e-02, -8.1032e-02,\n",
      "         -1.0589e-04, -2.9729e-02, -7.3346e-02,  9.2050e-03, -6.6096e-02,\n",
      "         -8.8068e-02, -2.7981e-02,  2.4028e-02,  9.8766e-02, -5.3264e-02,\n",
      "          7.4855e-02,  8.3705e-02, -4.5915e-02,  9.6195e-03,  1.7789e-02,\n",
      "         -4.5605e-02,  8.0216e-02, -6.1417e-02, -3.0133e-03, -8.0376e-02,\n",
      "         -6.4558e-02,  6.9687e-02,  8.1035e-02, -9.4079e-02, -7.8671e-02,\n",
      "          4.9394e-02, -4.3978e-02, -2.2070e-02, -4.6193e-02,  6.9168e-02],\n",
      "        [ 8.3213e-02,  5.2154e-03, -8.6266e-02,  1.5864e-02, -2.7606e-02,\n",
      "         -7.0057e-02,  5.9399e-02,  6.9747e-02, -6.2966e-02, -3.4533e-02,\n",
      "         -5.0188e-02,  4.0038e-02,  8.0609e-02, -1.2548e-02,  6.9886e-03,\n",
      "         -4.3520e-02,  5.1242e-02, -9.9540e-02, -5.5803e-02,  6.3346e-02,\n",
      "          8.5562e-02,  9.6273e-02, -6.3852e-02, -9.9671e-05,  5.4877e-02,\n",
      "         -6.1932e-03,  1.0768e-02,  4.5092e-02, -6.1180e-02,  9.6332e-02,\n",
      "          9.7669e-02,  5.2552e-02, -5.4825e-02, -4.7115e-02,  7.8707e-02,\n",
      "          3.0449e-02, -3.7404e-02,  6.0413e-02,  7.3345e-02,  8.1246e-02,\n",
      "         -6.8984e-02,  2.2407e-02,  9.9480e-02,  6.4126e-02,  1.6591e-02,\n",
      "         -3.4424e-02, -7.6049e-02, -3.2246e-02, -3.6719e-02,  6.7817e-02,\n",
      "          2.9018e-02, -9.4448e-03, -8.2597e-02, -5.5514e-02,  6.6235e-03,\n",
      "          9.9550e-03, -9.8611e-02, -3.8200e-02, -9.0140e-02,  1.7976e-02,\n",
      "          7.0094e-02,  4.4493e-02,  6.0711e-02, -6.3620e-02,  1.1337e-02,\n",
      "          1.0251e-02,  4.3807e-02,  6.7468e-02, -8.6481e-02,  3.7987e-02,\n",
      "         -6.3975e-03, -4.6772e-02, -5.0012e-02,  7.0557e-02,  5.7312e-02,\n",
      "         -3.1718e-02,  6.6702e-03,  7.2954e-02,  4.4533e-02, -8.2391e-02,\n",
      "          1.5850e-02, -5.7454e-02,  9.9148e-02,  5.8430e-02,  7.0999e-02,\n",
      "          3.8348e-02,  2.4592e-03, -8.4278e-02,  6.3893e-02, -9.7751e-02,\n",
      "         -1.3844e-02, -4.2663e-02,  1.0579e-02, -8.4497e-02, -4.1912e-02,\n",
      "          1.5328e-02,  9.3706e-02, -1.8952e-02, -2.9236e-02, -5.1898e-03],\n",
      "        [-7.1542e-02, -1.8817e-02, -4.9752e-02, -9.5992e-02, -8.0018e-03,\n",
      "         -3.2015e-04,  3.2584e-02,  8.1523e-02,  4.8718e-02,  9.8785e-02,\n",
      "          7.1069e-02, -5.5244e-02,  1.3627e-02, -6.3829e-02, -1.9660e-02,\n",
      "          3.8168e-02,  4.2511e-02, -6.0619e-02, -9.4192e-02,  6.6106e-02,\n",
      "          9.0198e-02,  7.2917e-02, -2.3461e-02, -5.4507e-02, -2.9758e-03,\n",
      "          8.6930e-02, -6.6180e-02, -4.1549e-02,  6.9641e-02,  4.6838e-02,\n",
      "          7.3849e-02,  3.5165e-02, -4.2672e-02, -2.6059e-02, -2.7753e-02,\n",
      "         -5.7232e-02, -7.4127e-02,  9.9135e-02,  5.4685e-02, -8.3064e-02,\n",
      "         -7.5244e-02, -7.8030e-02, -4.4881e-04, -8.8974e-02,  7.3034e-02,\n",
      "         -8.6540e-02,  3.7171e-03, -2.1534e-02,  9.6138e-02, -1.0185e-02,\n",
      "          4.7303e-02, -9.8231e-02, -4.7448e-02, -3.4768e-02, -2.6216e-02,\n",
      "          6.6541e-02, -7.4434e-02, -2.6482e-02, -2.3797e-02, -1.9526e-03,\n",
      "         -6.5906e-02,  6.2029e-03,  6.7139e-02,  5.4127e-02, -7.9649e-02,\n",
      "         -7.9849e-02, -4.8152e-02, -4.3958e-02, -1.8136e-02, -8.8452e-02,\n",
      "         -2.0599e-02, -8.0218e-02, -3.1229e-02,  7.1746e-02, -8.1078e-02,\n",
      "         -4.8316e-02, -3.5174e-02,  3.5450e-02, -1.6535e-02, -8.4064e-02,\n",
      "          6.9942e-02, -5.6404e-02, -1.4750e-02, -7.2542e-02, -8.4070e-02,\n",
      "          1.3498e-02, -5.1614e-02, -1.3506e-02, -9.7352e-02, -1.1801e-02,\n",
      "          3.0880e-04,  4.3300e-02,  8.1217e-02,  8.5034e-02,  3.9615e-02,\n",
      "         -5.3082e-02,  6.2122e-02, -3.8136e-02, -3.1014e-02, -3.5711e-02]],\n",
      "       device='cpu', requires_grad=True)), ('fc2.bias', Parameter containing:\n",
      "tensor([ 0.0750, -0.0595, -0.0345], device='cpu', requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = MLP(\n",
    "    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\n",
    "model = model.to(device) # set device\n",
    "print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer & scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyTrainer(object):\n",
    "    def __init__(self, model, device, train_dataloader=None, val_dataloader=None, \n",
    "                 loss_fn=None, optimizer=None, scheduler=None, num_epochs=NUM_EPOCHS,\n",
    "                 patience=PATIENCE):\n",
    "\n",
    "        # Set params\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.loss_fn = loss_fn if loss_fn is not None else nn.CrossEntropyLoss()\n",
    "        self.optimizer = (\n",
    "            optimizer if optimizer is not None else Adam(self.model.parameters())\n",
    "        )\n",
    "        self.scheduler = (\n",
    "            scheduler if scheduler is not None \n",
    "            else torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer)\n",
    "        )\n",
    "        self.num_epochs = num_epochs\n",
    "        self.patience = patience\n",
    "\n",
    "    def train_step(self, dataloader=None):\n",
    "        \"\"\"Train step.\"\"\"\n",
    "        if dataloader is None:\n",
    "            dataloader = self.train_dataloader\n",
    "        \n",
    "        # Set model to train mode\n",
    "        self.model.train()\n",
    "        loss = 0.0\n",
    "\n",
    "        # Iterate over train batches\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Step\n",
    "            batch = [item.to(self.device) for item in batch]  # Set device\n",
    "            inputs, targets = batch[:-1], batch[-1]\n",
    "            self.optimizer.zero_grad()  # Reset gradients\n",
    "            z = self.model(inputs)  # Forward pass\n",
    "            J = self.loss_fn(z, targets)  # Define loss\n",
    "            J.backward()  # Backward pass\n",
    "            self.optimizer.step()  # Update weights\n",
    "\n",
    "            # Cumulative Metrics\n",
    "            loss += (J.detach().item() - loss) / (i + 1)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def eval_step(self, dataloader=None):\n",
    "        \"\"\"Validation or test step.\"\"\"\n",
    "        if dataloader is None:\n",
    "            dataloader = self.val_dataloader\n",
    "        \n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        loss = 0.0\n",
    "        y_trues, y_probs = [], []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Step\n",
    "                batch = [item.to(self.device) for item in batch]  # Set device\n",
    "                inputs, y_true = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)  # Forward pass\n",
    "                J = self.loss_fn(z, y_true).item()\n",
    "\n",
    "                # Cumulative Metrics\n",
    "                loss += (J - loss) / (i + 1)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "                y_trues.extend(y_true.cpu().numpy())\n",
    "\n",
    "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
    "\n",
    "    def predict_step(self, dataloader=None):\n",
    "        \"\"\"Prediction step.\"\"\"\n",
    "        if dataloader is None:\n",
    "            dataloader = self.val_dataloader\n",
    "\n",
    "        # Set model to eval mode\n",
    "        self.model.eval()\n",
    "        y_probs = []\n",
    "\n",
    "        # Iterate over val batches\n",
    "        with torch.inference_mode():\n",
    "            for i, batch in enumerate(dataloader):\n",
    "\n",
    "                # Forward pass w/ inputs\n",
    "                inputs, targets = batch[:-1], batch[-1]\n",
    "                z = self.model(inputs)\n",
    "\n",
    "                # Store outputs\n",
    "                y_prob = F.softmax(z, dim=1).cpu().numpy()\n",
    "                y_probs.extend(y_prob)\n",
    "\n",
    "        return np.vstack(y_probs)\n",
    "\n",
    "    def train(self):\n",
    "        best_val_loss = np.inf\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Steps\n",
    "            train_loss = self.train_step(dataloader=train_dataloader)\n",
    "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
    "            self.scheduler.step(val_loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                _patience = self.patience  # reset _patience\n",
    "            else:\n",
    "                _patience -= 1\n",
    "            if not _patience:  # 0\n",
    "                print(\"Stopping early!\")\n",
    "                break\n",
    "\n",
    "            # Logging\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"train_loss: {train_loss:.5f}, \"\n",
    "                f\"val_loss: {val_loss:.5f}, \"\n",
    "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
    "                f\"_patience: {_patience}\"\n",
    "            )\n",
    "        return self.model\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            \"model\": self.model.state_dict(),\n",
    "            \"train_dataloader\": self.train_dataloader,\n",
    "            \"val_dataloader\": self.val_dataloader,\n",
    "            \"loss_fn\": self.loss_fn,\n",
    "            \"optimizer\": self.optimizer.state_dict(),\n",
    "            \"scheduler\": self.scheduler.state_dict(),\n",
    "            \"num_epochs\": self.num_epochs,\n",
    "            \"patience\": self.patience\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict: dict):\n",
    "        self.model.load_state_dict(state_dict[\"model\"])\n",
    "        self.train_dataloader = state_dict[\"train_dataloader\"]\n",
    "        self.val_dataloader = state_dict[\"val_dataloader\"]\n",
    "        self.loss_fn = state_dict[\"loss_fn\"]\n",
    "        self.optimizer.load_state_dict(state_dict[\"optimizer\"])\n",
    "        self.scheduler.load_state_dict(state_dict[\"scheduler\"])\n",
    "        self.num_epochs = state_dict[\"num_epochs\"]\n",
    "        self.patience = state_dict[\"patience\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EasyTrainer(\n",
    "    model=model, device=device, \n",
    "    train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer, scheduler=scheduler,\n",
    "    num_epochs=NUM_EPOCHS, patience=PATIENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.86883, val_loss: 0.78481, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 2 | train_loss: 0.67722, val_loss: 0.60907, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 3 | train_loss: 0.52912, val_loss: 0.48051, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 4 | train_loss: 0.41867, val_loss: 0.38193, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 5 | train_loss: 0.33587, val_loss: 0.31298, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 6 | train_loss: 0.28599, val_loss: 0.26563, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 7 | train_loss: 0.23913, val_loss: 0.23027, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 8 | train_loss: 0.21087, val_loss: 0.20215, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 9 | train_loss: 0.18504, val_loss: 0.18654, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 10 | train_loss: 0.17749, val_loss: 0.17087, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 11 | train_loss: 0.17096, val_loss: 0.15734, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 12 | train_loss: 0.15342, val_loss: 0.14995, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 13 | train_loss: 0.14171, val_loss: 0.13762, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 14 | train_loss: 0.14502, val_loss: 0.13746, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 15 | train_loss: 0.12904, val_loss: 0.12800, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 16 | train_loss: 0.12962, val_loss: 0.12482, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 17 | train_loss: 0.12611, val_loss: 0.11847, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 18 | train_loss: 0.11368, val_loss: 0.11325, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 19 | train_loss: 0.11045, val_loss: 0.10724, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 20 | train_loss: 0.10831, val_loss: 0.10336, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 21 | train_loss: 0.10338, val_loss: 0.10191, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 22 | train_loss: 0.09917, val_loss: 0.09839, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 23 | train_loss: 0.09866, val_loss: 0.09836, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 24 | train_loss: 0.08888, val_loss: 0.09236, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 25 | train_loss: 0.09260, val_loss: 0.09121, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 26 | train_loss: 0.09680, val_loss: 0.09438, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 27 | train_loss: 0.08334, val_loss: 0.08691, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 28 | train_loss: 0.09051, val_loss: 0.08815, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 29 | train_loss: 0.08471, val_loss: 0.08677, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 30 | train_loss: 0.09174, val_loss: 0.08576, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 31 | train_loss: 0.08808, val_loss: 0.08298, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 32 | train_loss: 0.08807, val_loss: 0.08142, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 33 | train_loss: 0.09205, val_loss: 0.08111, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 34 | train_loss: 0.07769, val_loss: 0.07766, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 35 | train_loss: 0.08033, val_loss: 0.07793, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 36 | train_loss: 0.07589, val_loss: 0.07612, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 37 | train_loss: 0.07445, val_loss: 0.07663, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 38 | train_loss: 0.08174, val_loss: 0.07488, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 39 | train_loss: 0.07196, val_loss: 0.07809, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 40 | train_loss: 0.07296, val_loss: 0.07272, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 41 | train_loss: 0.07420, val_loss: 0.07175, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 42 | train_loss: 0.06883, val_loss: 0.07282, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 43 | train_loss: 0.07265, val_loss: 0.06831, lr: 1.00E-02, _patience: 6\n",
      "Epoch: 44 | train_loss: 0.07091, val_loss: 0.06984, lr: 1.00E-02, _patience: 5\n",
      "Epoch: 45 | train_loss: 0.07329, val_loss: 0.07136, lr: 1.00E-02, _patience: 4\n",
      "Epoch: 46 | train_loss: 0.07015, val_loss: 0.07118, lr: 1.00E-02, _patience: 3\n",
      "Epoch: 47 | train_loss: 0.06905, val_loss: 0.06883, lr: 1.00E-03, _patience: 2\n",
      "Epoch: 48 | train_loss: 0.06864, val_loss: 0.06831, lr: 1.00E-03, _patience: 1\n",
      "Epoch: 49 | train_loss: 0.07006, val_loss: 0.06770, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 50 | train_loss: 0.06501, val_loss: 0.06753, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 51 | train_loss: 0.06408, val_loss: 0.06757, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 52 | train_loss: 0.06167, val_loss: 0.06718, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 53 | train_loss: 0.06477, val_loss: 0.06680, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 54 | train_loss: 0.06456, val_loss: 0.06690, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 55 | train_loss: 0.06963, val_loss: 0.06685, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 56 | train_loss: 0.06510, val_loss: 0.06658, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 57 | train_loss: 0.06470, val_loss: 0.06616, lr: 1.00E-03, _patience: 6\n",
      "Epoch: 58 | train_loss: 0.06829, val_loss: 0.06618, lr: 1.00E-03, _patience: 5\n",
      "Epoch: 59 | train_loss: 0.06759, val_loss: 0.06632, lr: 1.00E-03, _patience: 4\n",
      "Epoch: 60 | train_loss: 0.06864, val_loss: 0.06650, lr: 1.00E-03, _patience: 3\n",
      "Epoch: 61 | train_loss: 0.06774, val_loss: 0.06659, lr: 1.00E-04, _patience: 2\n",
      "Epoch: 62 | train_loss: 0.06423, val_loss: 0.06656, lr: 1.00E-04, _patience: 1\n",
      "Stopping early!\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "best_model = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading with the `EasyTrainer`\n",
    "Saving and loading has just become easier because we can save and load our entire training loop in one go (including model, data, loss and other training parameters).\n",
    "- [ ] Finish `save` and `load` methods in `EasyTrainer` (possibly need one in the dataset or dataloaders as well)\n",
    "- [ ] Run inference on the loaded model like was done for the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.state_dict(), Path(\"mlp\", \"trainer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_state_before = trainer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_state_after = torch.load(Path(\"mlp\", \"trainer.pt\"))\n",
    "\n",
    "model = MLP(\n",
    "    input_dim=INPUT_DIM, hidden_dim=HIDDEN_DIM,\n",
    "    dropout_p=DROPOUT_P, num_classes=NUM_CLASSES\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "new_trainer = EasyTrainer(model=model, device=device)\n",
    "new_trainer.load_state_dict(trainer_state_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('fc1.weight',\n",
       "               tensor([[-0.6558, -1.8043],\n",
       "                       [-0.1315, -0.0952],\n",
       "                       [ 1.5437,  0.7683],\n",
       "                       [-0.8229, -0.4162],\n",
       "                       [-0.5392,  1.1862],\n",
       "                       [-0.5657, -1.0804],\n",
       "                       [-0.5703, -0.0938],\n",
       "                       [-0.7610, -1.0976],\n",
       "                       [-0.5786, -0.9177],\n",
       "                       [ 1.1570, -1.0527],\n",
       "                       [ 1.2828, -0.1041],\n",
       "                       [ 1.1541, -0.0843],\n",
       "                       [-1.1065, -0.1280],\n",
       "                       [ 0.7237,  0.9580],\n",
       "                       [-0.0183, -1.4489],\n",
       "                       [ 0.5599, -1.0856],\n",
       "                       [-0.4530,  0.8780],\n",
       "                       [ 1.9620,  0.9563],\n",
       "                       [-0.4510,  1.0656],\n",
       "                       [-0.5151,  1.0475],\n",
       "                       [ 1.1475, -0.0194],\n",
       "                       [ 1.2364,  0.6246],\n",
       "                       [ 0.4129, -2.0859],\n",
       "                       [-0.7276, -1.0393],\n",
       "                       [-1.4188,  0.0551],\n",
       "                       [ 1.0769,  0.6820],\n",
       "                       [ 1.3297,  0.3422],\n",
       "                       [-0.6409, -1.0140],\n",
       "                       [-1.3946,  1.7160],\n",
       "                       [-0.0485, -0.9490],\n",
       "                       [-1.0594, -0.5647],\n",
       "                       [-0.5381,  0.9154],\n",
       "                       [-1.0867,  0.6213],\n",
       "                       [ 0.7011,  0.7873],\n",
       "                       [-1.7020,  0.9369],\n",
       "                       [-0.6395, -0.9091],\n",
       "                       [ 1.7646,  0.0741],\n",
       "                       [ 2.3322,  0.3077],\n",
       "                       [-0.0591, -1.5176],\n",
       "                       [-0.6425, -1.7085],\n",
       "                       [ 0.3064, -0.5208],\n",
       "                       [-0.7448,  1.1209],\n",
       "                       [ 1.2779,  0.1003],\n",
       "                       [-0.4667, -0.9031],\n",
       "                       [ 0.7919,  0.8311],\n",
       "                       [ 0.7548, -0.0209],\n",
       "                       [-1.6305,  1.8820],\n",
       "                       [-0.0950, -2.0011],\n",
       "                       [ 0.5907,  0.7211],\n",
       "                       [-0.2416,  0.9600],\n",
       "                       [ 0.3792, -0.7352],\n",
       "                       [-0.3907,  0.6536],\n",
       "                       [ 0.2371, -0.8573],\n",
       "                       [-1.0202,  1.1594],\n",
       "                       [ 1.2575,  1.5320],\n",
       "                       [ 0.0035,  1.3368],\n",
       "                       [-2.1205,  0.4865],\n",
       "                       [-1.6998,  0.4360],\n",
       "                       [-0.6739,  0.9644],\n",
       "                       [-0.6984,  0.8756],\n",
       "                       [ 0.7940,  0.6673],\n",
       "                       [ 1.0085, -0.0117],\n",
       "                       [-0.5036, -0.7665],\n",
       "                       [ 0.1911,  1.1469],\n",
       "                       [ 2.1125,  0.9818],\n",
       "                       [-0.3553, -0.9691],\n",
       "                       [ 0.3728, -0.6503],\n",
       "                       [-0.7027, -1.9173],\n",
       "                       [ 0.5758,  1.2517],\n",
       "                       [ 1.4376, -0.0039],\n",
       "                       [-1.6638,  0.8688],\n",
       "                       [ 0.8844, -1.8727],\n",
       "                       [-0.1200,  1.1309],\n",
       "                       [ 0.2114, -0.8910],\n",
       "                       [-1.3194,  0.0551],\n",
       "                       [-0.2696, -1.8888],\n",
       "                       [-0.5841,  0.9951],\n",
       "                       [-0.8586,  1.0295],\n",
       "                       [-1.6918,  0.0386],\n",
       "                       [-0.7874,  0.1555],\n",
       "                       [ 2.9468,  0.4086],\n",
       "                       [-0.6432, -1.0882],\n",
       "                       [ 0.9795,  1.1432],\n",
       "                       [-1.7242,  1.1297],\n",
       "                       [ 0.1639, -1.0391],\n",
       "                       [ 1.7703,  0.9045],\n",
       "                       [ 1.4489, -0.1113],\n",
       "                       [-1.8718,  1.0649],\n",
       "                       [-0.1508, -0.0422],\n",
       "                       [-0.9742,  1.2781],\n",
       "                       [-0.4326,  0.7308],\n",
       "                       [-1.1014,  1.3827],\n",
       "                       [ 1.4419,  1.7327],\n",
       "                       [ 1.1469, -0.0912],\n",
       "                       [-0.0388, -0.0851],\n",
       "                       [-0.2366,  1.3285],\n",
       "                       [ 1.7946,  0.2605],\n",
       "                       [ 0.0076,  1.3037],\n",
       "                       [ 1.5601,  1.5066],\n",
       "                       [ 0.1653, -1.8723]], device='cpu')),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.5728, -0.5147,  0.1542,  0.2321, -1.3321, -1.3557,  0.5390, -1.3049,\n",
       "                       -1.1217, -1.0960, -1.1447, -1.0842,  0.2213,  0.2778,  0.2470,  0.3449,\n",
       "                       -1.0487,  0.2104,  0.2835, -1.1490, -1.1362,  0.0927, -1.1198, -1.1760,\n",
       "                        0.5548,  0.3179, -1.6853,  0.2936, -0.6575,  0.1877, -0.8938, -1.1383,\n",
       "                        0.2267,  0.5828,  0.3048, -1.0327,  0.3172, -0.7258,  0.0437, -0.5574,\n",
       "                        0.5438,  0.1896,  0.5495, -1.0939,  0.5604,  0.5207, -0.7976,  0.1217,\n",
       "                        0.5978,  0.2433,  0.7062,  0.2523,  0.4957, -0.4789, -1.0501,  0.5595,\n",
       "                       -1.1479, -0.8383,  0.1861, -1.3450,  0.4573, -1.0288, -0.8844, -0.1592,\n",
       "                       -0.9313, -1.2253,  0.6225, -0.6282,  0.3124,  0.3294,  0.2737, -1.1582,\n",
       "                        0.2613,  0.3666,  0.6721, -0.6667, -1.2523, -1.5768, -0.8565,  0.2294,\n",
       "                       -0.8425, -0.8032, -0.5233,  0.1807,  0.5416, -0.8009, -1.4654, -0.8655,\n",
       "                       -0.6146, -0.4187, -0.9361, -0.5854, -1.1863, -1.1025, -0.3966, -1.0383,\n",
       "                       -0.4991,  0.3329, -0.9638, -0.8745], device='cpu')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 4.0942e-01,  3.1245e-02,  7.3607e-01, -2.8863e-01, -1.2278e+00,\n",
       "                         1.0690e+00, -1.1776e-01,  1.1638e+00,  1.1243e+00,  7.7283e-01,\n",
       "                        -8.7492e-01, -1.5139e+00, -3.9127e-01,  5.6228e-01, -3.8469e-01,\n",
       "                        -1.9809e-01, -1.5030e+00,  9.9642e-01,  8.0354e-02, -9.5710e-01,\n",
       "                        -1.7391e+00,  9.0668e-01,  3.7639e-01,  1.0057e+00, -1.6995e-01,\n",
       "                         5.4325e-01, -3.6062e-01, -2.9459e-01,  3.9485e-01, -4.1085e-01,\n",
       "                         9.2197e-01, -1.3685e+00, -8.1725e-02,  2.5893e-01, -1.6379e-01,\n",
       "                         9.6395e-01,  5.9280e-01, -2.1521e+00, -3.0472e-01,  3.3843e-01,\n",
       "                        -3.6145e-01, -1.0290e-01,  2.1680e-01,  1.0690e+00,  4.7102e-01,\n",
       "                        -9.8290e-02,  3.9756e-01, -3.5474e-01,  3.1079e-01,  1.1376e-01,\n",
       "                        -3.0486e-01,  7.9469e-02, -3.6311e-01,  3.3485e-01, -1.7605e+00,\n",
       "                         2.6938e-01,  5.5447e-01,  6.1773e-01, -9.5776e-02, -1.3332e+00,\n",
       "                         2.5461e-01, -1.1330e+00,  1.4356e+00,  1.0518e-01, -1.8303e+00,\n",
       "                         1.3281e+00, -2.1691e-01,  3.6129e-01,  3.8993e-01,  5.0102e-01,\n",
       "                        -2.0107e-01,  3.9962e-01,  9.8142e-02, -2.8270e-01, -1.6560e-01,\n",
       "                         7.6549e-02, -1.5629e+00, -8.6749e-01,  8.6506e-01, -2.3837e-01,\n",
       "                        -1.8206e+00,  6.4980e-01, -9.9861e-01, -2.2359e-01, -2.9241e-01,\n",
       "                        -2.1320e+00, -3.8448e-01,  4.8176e-01, -3.0133e-03,  2.1258e-01,\n",
       "                        -1.5921e+00,  1.7853e-01, -1.5155e+00, -4.8662e-01,  2.4251e-02,\n",
       "                        -1.4916e+00, -2.0462e+00,  1.2605e-01, -2.0023e+00,  3.0285e-01],\n",
       "                       [ 3.5063e-01,  5.2154e-03, -4.2232e-01,  1.8287e-01, -3.0166e-01,\n",
       "                        -1.2611e+00,  2.4065e-01, -9.7083e-01, -1.3971e+00,  7.1267e-01,\n",
       "                         1.4531e+00,  1.5685e+00,  4.0355e-01, -2.2358e-01, -2.1250e-01,\n",
       "                        -2.2635e-01,  7.1211e-02, -4.1187e-01,  3.0494e-01, -3.4525e-01,\n",
       "                         1.4612e+00, -3.6232e-01,  3.9747e-01, -7.4390e-01,  3.4223e-01,\n",
       "                        -2.8891e-01,  1.2597e+00,  1.8021e-01, -1.6988e+00,  2.7267e-02,\n",
       "                        -1.4676e+00, -9.5106e-01,  2.9992e-01, -3.0694e-01,  6.7779e-01,\n",
       "                        -7.2166e-01, -3.9928e-01,  3.8227e-01, -8.8079e-02,  2.2558e-01,\n",
       "                        -1.6004e-01,  3.3252e-01, -1.9532e-01, -1.0994e+00, -2.3633e-01,\n",
       "                        -2.1169e-01, -1.5373e+00, -1.4323e-01, -2.8801e-01,  3.7119e-01,\n",
       "                         2.1421e-02,  7.9180e-02, -9.4102e-02, -1.8920e+00,  4.2679e-01,\n",
       "                         6.6292e-02, -1.7871e+00, -1.4044e+00,  6.6167e-01, -5.9904e-01,\n",
       "                        -2.6365e-01,  1.6587e+00, -1.5846e+00, -5.2773e-01,  3.1286e-01,\n",
       "                        -1.3831e+00,  1.5088e-02,  4.1186e-01, -1.8427e-01, -3.6258e-01,\n",
       "                         6.3838e-01,  4.0893e-01,  1.9456e-01, -6.4560e-03,  2.6159e-01,\n",
       "                         3.8707e-01, -6.2473e-01, -1.8151e-01, -1.4310e+00,  2.3777e-01,\n",
       "                         4.4336e-01, -2.5184e-01,  2.4494e-02,  7.8190e-01,  1.0955e-03,\n",
       "                         4.0900e-01,  1.2747e+00, -1.7149e+00,  6.3893e-02, -1.0168e+00,\n",
       "                        -5.1799e-01, -2.2098e+00,  2.9420e-01,  1.2958e+00, -1.4337e-01,\n",
       "                         5.2563e-01,  5.6847e-01,  1.4193e-01,  3.0270e-01,  4.2606e-01],\n",
       "                       [-2.2352e+00, -1.8817e-02, -2.6502e-01,  1.0460e-01,  1.0573e+00,\n",
       "                        -4.0595e-01, -1.3773e-01, -6.3019e-01, -1.2810e-01, -1.8083e+00,\n",
       "                        -1.4593e+00, -1.4827e+00, -1.3492e-02, -2.7389e-01,  7.6866e-01,\n",
       "                         4.5001e-01,  1.2127e+00, -2.5829e-01, -3.6171e-01,  1.1667e+00,\n",
       "                        -1.0901e+00, -2.5251e-02, -1.7181e+00, -1.2823e+00, -2.1343e-01,\n",
       "                        -3.1619e-02, -1.3409e+00,  4.6218e-01,  3.6506e-01,  5.8927e-01,\n",
       "                         7.8611e-01,  1.4570e+00, -2.8110e-01, -4.7422e-02, -2.9272e-01,\n",
       "                        -9.9141e-01, -5.1644e-02,  5.1736e-01,  7.0722e-01, -2.5505e+00,\n",
       "                         1.6743e-01, -2.3160e-01,  1.1786e-01, -2.5094e-01, -6.9468e-03,\n",
       "                         8.2863e-02,  3.6009e-01,  8.6404e-01,  4.0322e-02, -3.2162e-01,\n",
       "                         3.5352e-01, -2.1468e-01,  3.1397e-01,  3.5374e-01,  4.3479e-01,\n",
       "                        -1.3899e-01,  3.2138e-01,  2.1622e-01, -4.3205e-01,  1.3703e+00,\n",
       "                        -2.6831e-02, -1.5741e+00, -4.1397e-01,  2.9652e-01,  3.4926e-01,\n",
       "                        -2.6967e-01,  2.5749e-01, -2.1242e+00, -2.9072e-01,  3.3170e-02,\n",
       "                        -3.3126e-01, -1.5147e+00, -3.5873e-01,  4.8231e-01, -2.4112e-01,\n",
       "                        -1.5982e+00,  1.4443e+00,  8.2424e-01,  4.0667e-01, -2.7575e-01,\n",
       "                         4.4572e-01, -1.2123e+00,  5.2165e-01, -3.5948e-01,  3.7463e-01,\n",
       "                         5.0908e-01, -1.3709e+00,  2.6056e-01, -9.7352e-02,  2.1693e-01,\n",
       "                         1.4871e+00,  5.4809e-01,  5.3693e-01, -1.4192e+00, -6.5896e-02,\n",
       "                         7.0509e-01,  2.6693e-01, -2.6736e-01,  4.7039e-01, -1.6592e+00]],\n",
       "                      device='cpu')),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.0210, -0.0192,  0.0207], device='cpu'))]),\n",
       " 'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc341217b90>,\n",
       " 'val_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc418494b10>,\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'optimizer': {'state': {0: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.3685e-03, -9.7889e-04],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-1.5353e-04,  1.4701e-04],\n",
       "            [ 3.4770e-04,  5.6011e-04],\n",
       "            [ 4.0141e-04,  1.4776e-04],\n",
       "            [-2.5883e-04, -2.0992e-03],\n",
       "            [ 1.5449e-04,  2.8779e-04],\n",
       "            [-1.5961e-04, -2.1166e-03],\n",
       "            [-1.3842e-04, -2.2399e-03],\n",
       "            [ 1.5072e-04, -1.7804e-05],\n",
       "            [-6.3255e-03, -5.2268e-03],\n",
       "            [-6.8567e-03, -5.7894e-03],\n",
       "            [ 6.2771e-04,  2.4082e-04],\n",
       "            [-6.7329e-04, -1.5038e-04],\n",
       "            [-2.5339e-05,  1.1856e-03],\n",
       "            [-1.3936e-05,  5.5602e-04],\n",
       "            [ 1.4005e-03, -3.7320e-04],\n",
       "            [-1.1718e-04, -1.4054e-04],\n",
       "            [-1.7097e-03, -1.7043e-03],\n",
       "            [ 9.6552e-04, -1.8317e-04],\n",
       "            [-5.6341e-03, -4.8512e-03],\n",
       "            [-4.7633e-04, -6.8443e-05],\n",
       "            [ 3.9150e-04, -5.0092e-04],\n",
       "            [-5.4490e-05, -1.8349e-03],\n",
       "            [ 2.7189e-04,  7.2915e-05],\n",
       "            [ 1.9915e-04,  5.5347e-04],\n",
       "            [-5.7647e-04, -3.4285e-04],\n",
       "            [ 4.0012e-04,  9.2164e-04],\n",
       "            [-2.8781e-04, -2.5235e-04],\n",
       "            [ 1.9759e-04,  6.4435e-04],\n",
       "            [-4.3568e-04, -1.7314e-03],\n",
       "            [ 1.5158e-03, -3.9147e-04],\n",
       "            [ 1.1506e-04, -3.3335e-04],\n",
       "            [ 3.8423e-04,  6.4273e-04],\n",
       "            [ 3.6895e-04, -6.1120e-04],\n",
       "            [-8.1468e-05, -1.6746e-03],\n",
       "            [ 5.1763e-04,  1.1785e-04],\n",
       "            [-1.9991e-04,  1.0824e-03],\n",
       "            [ 1.2246e-04,  1.0715e-03],\n",
       "            [ 1.5480e-03, -1.0355e-03],\n",
       "            [ 8.7689e-04,  1.1037e-03],\n",
       "            [-1.0752e-03, -1.4165e-03],\n",
       "            [ 5.6452e-04,  3.2944e-04],\n",
       "            [-2.0407e-04, -2.4012e-03],\n",
       "            [ 1.8807e-04,  5.6039e-04],\n",
       "            [ 5.5348e-04,  6.4214e-04],\n",
       "            [-4.2972e-04, -3.0965e-04],\n",
       "            [ 1.5004e-04,  8.1886e-04],\n",
       "            [ 4.3808e-04,  8.1595e-04],\n",
       "            [-1.7890e-03, -1.7042e-03],\n",
       "            [ 1.0602e-03,  1.3846e-03],\n",
       "            [-8.7528e-04, -6.9610e-04],\n",
       "            [-4.5349e-05,  6.3485e-04],\n",
       "            [-5.5836e-04, -4.5324e-04],\n",
       "            [ 4.4856e-05,  1.9974e-04],\n",
       "            [-7.6765e-04, -4.7949e-04],\n",
       "            [-4.9034e-04, -2.5633e-04],\n",
       "            [-6.2581e-04, -1.3375e-04],\n",
       "            [-2.2984e-03, -2.6768e-03],\n",
       "            [ 1.5975e-03, -5.0898e-04],\n",
       "            [ 3.3004e-04,  5.1178e-04],\n",
       "            [-7.5813e-03, -6.5530e-03],\n",
       "            [-3.7074e-04, -2.8526e-03],\n",
       "            [ 1.8103e-03,  1.7346e-03],\n",
       "            [ 4.2191e-05,  2.5326e-04],\n",
       "            [ 3.1980e-05, -2.1523e-03],\n",
       "            [ 7.0600e-04,  8.8419e-04],\n",
       "            [ 1.2390e-03, -8.7540e-04],\n",
       "            [-7.0661e-04, -1.6852e-04],\n",
       "            [ 8.3661e-04, -1.3591e-04],\n",
       "            [ 1.4837e-04, -4.6583e-04],\n",
       "            [ 5.2257e-04, -4.6976e-04],\n",
       "            [-8.3341e-05, -1.1003e-04],\n",
       "            [ 2.2515e-05,  8.3550e-04],\n",
       "            [ 1.8113e-04,  2.3376e-05],\n",
       "            [ 4.5811e-04, -3.2224e-04],\n",
       "            [ 1.4914e-03, -2.5039e-04],\n",
       "            [ 4.8546e-04, -1.4889e-04],\n",
       "            [-6.2937e-04, -1.2823e-04],\n",
       "            [ 3.0234e-04, -4.3830e-05],\n",
       "            [-3.4690e-04,  7.5189e-04],\n",
       "            [ 2.0117e-04, -1.3202e-03],\n",
       "            [ 1.1593e-03,  1.2195e-03],\n",
       "            [ 4.2052e-04, -6.4088e-04],\n",
       "            [ 3.1860e-05,  6.9035e-04],\n",
       "            [ 2.3286e-04,  4.1042e-04],\n",
       "            [ 8.3210e-06, -1.5833e-05],\n",
       "            [-6.4171e-04, -9.9525e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-2.1352e-04, -9.8869e-05],\n",
       "            [ 7.0911e-04, -2.0344e-04],\n",
       "            [-2.4645e-04, -3.9571e-04],\n",
       "            [ 5.6229e-04,  6.2525e-04],\n",
       "            [-6.9708e-05, -1.7574e-04],\n",
       "            [-5.6052e-45, -5.6052e-45],\n",
       "            [ 8.7715e-04,  1.8032e-04],\n",
       "            [-8.7034e-04,  2.4251e-04],\n",
       "            [-1.0598e-03, -8.6951e-04],\n",
       "            [ 3.9212e-04,  6.0674e-04],\n",
       "            [ 2.7102e-04, -3.0535e-04]], device='cpu'),\n",
       "    'exp_avg_sq': tensor([[2.9894e-05, 2.0862e-05],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [6.0251e-06, 7.8995e-06],\n",
       "            [5.5849e-06, 8.5187e-06],\n",
       "            [4.7381e-05, 2.4069e-05],\n",
       "            [2.1180e-05, 7.8678e-05],\n",
       "            [1.8898e-06, 4.0898e-06],\n",
       "            [2.6482e-05, 7.1318e-05],\n",
       "            [3.5205e-05, 9.7363e-05],\n",
       "            [2.9866e-05, 8.9027e-06],\n",
       "            [1.0974e-04, 6.7453e-05],\n",
       "            [1.1669e-04, 7.4314e-05],\n",
       "            [9.0335e-06, 1.7235e-05],\n",
       "            [6.9564e-06, 7.4705e-06],\n",
       "            [4.1496e-06, 9.2421e-06],\n",
       "            [1.2178e-05, 8.7653e-06],\n",
       "            [7.8970e-05, 2.5813e-05],\n",
       "            [5.2842e-06, 9.1980e-06],\n",
       "            [1.4356e-05, 8.9021e-06],\n",
       "            [3.3591e-05, 1.5344e-05],\n",
       "            [1.0071e-04, 7.5881e-05],\n",
       "            [8.1656e-06, 8.6439e-06],\n",
       "            [4.8495e-06, 4.6709e-06],\n",
       "            [2.1401e-05, 5.3582e-05],\n",
       "            [4.0187e-06, 9.7952e-06],\n",
       "            [5.2072e-06, 4.4688e-06],\n",
       "            [5.9999e-05, 3.8582e-05],\n",
       "            [9.8872e-06, 1.0581e-05],\n",
       "            [1.8265e-05, 7.7799e-06],\n",
       "            [4.3653e-06, 1.2428e-05],\n",
       "            [2.4383e-05, 4.5762e-05],\n",
       "            [9.2719e-05, 3.2864e-05],\n",
       "            [2.8440e-06, 3.0675e-06],\n",
       "            [2.1047e-06, 1.9826e-06],\n",
       "            [7.2711e-06, 5.9379e-06],\n",
       "            [2.4035e-05, 4.4343e-05],\n",
       "            [6.8647e-06, 1.4762e-05],\n",
       "            [5.6567e-06, 2.0663e-05],\n",
       "            [4.1377e-06, 5.7797e-06],\n",
       "            [3.5468e-05, 2.1003e-05],\n",
       "            [3.8189e-06, 5.7153e-06],\n",
       "            [3.6282e-06, 2.8937e-06],\n",
       "            [2.9132e-06, 5.3829e-06],\n",
       "            [1.8301e-05, 5.5533e-05],\n",
       "            [4.2198e-06, 3.8905e-06],\n",
       "            [2.1029e-06, 2.4976e-06],\n",
       "            [1.2512e-05, 9.3198e-06],\n",
       "            [3.7511e-06, 5.0748e-06],\n",
       "            [7.9378e-06, 4.4012e-06],\n",
       "            [1.5468e-05, 8.7927e-06],\n",
       "            [5.8105e-06, 1.0606e-05],\n",
       "            [3.9697e-06, 2.9507e-06],\n",
       "            [4.2912e-06, 1.0321e-05],\n",
       "            [2.9222e-05, 2.1532e-05],\n",
       "            [4.7618e-06, 1.2476e-05],\n",
       "            [5.3888e-06, 2.4542e-06],\n",
       "            [1.3708e-05, 5.2420e-06],\n",
       "            [1.2482e-05, 4.0013e-06],\n",
       "            [2.0079e-05, 1.4950e-05],\n",
       "            [4.7264e-05, 1.6006e-05],\n",
       "            [2.9141e-06, 2.3943e-06],\n",
       "            [1.3464e-04, 8.7124e-05],\n",
       "            [3.6629e-05, 1.1103e-04],\n",
       "            [1.1945e-05, 7.8221e-06],\n",
       "            [4.9133e-06, 9.5781e-06],\n",
       "            [2.6801e-05, 9.5245e-05],\n",
       "            [2.9837e-06, 6.4312e-06],\n",
       "            [1.5170e-05, 1.3957e-05],\n",
       "            [5.4162e-06, 4.7453e-06],\n",
       "            [7.9063e-06, 1.3170e-05],\n",
       "            [7.2473e-06, 6.0861e-06],\n",
       "            [1.3115e-05, 6.8743e-06],\n",
       "            [1.0159e-05, 5.3390e-06],\n",
       "            [5.8869e-06, 8.6440e-06],\n",
       "            [4.8304e-06, 1.0895e-05],\n",
       "            [4.3112e-06, 7.9128e-06],\n",
       "            [1.0641e-04, 2.9429e-05],\n",
       "            [2.0771e-05, 6.9678e-06],\n",
       "            [2.2088e-05, 1.3070e-05],\n",
       "            [1.2947e-06, 1.5947e-06],\n",
       "            [4.1441e-06, 2.3040e-05],\n",
       "            [2.2479e-05, 2.5862e-05],\n",
       "            [4.9452e-06, 9.2864e-06],\n",
       "            [7.5554e-06, 5.3895e-06],\n",
       "            [4.1172e-06, 1.1379e-05],\n",
       "            [7.0791e-06, 1.6573e-05],\n",
       "            [8.2115e-05, 4.8286e-05],\n",
       "            [1.2381e-05, 4.1259e-06],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [1.0595e-05, 7.9708e-06],\n",
       "            [9.4128e-05, 3.4065e-05],\n",
       "            [3.9718e-05, 2.9561e-05],\n",
       "            [2.8540e-06, 7.8989e-06],\n",
       "            [9.6461e-05, 5.6295e-05],\n",
       "            [3.3248e-09, 2.4441e-08],\n",
       "            [6.3192e-05, 2.9412e-05],\n",
       "            [2.2291e-05, 5.4483e-05],\n",
       "            [8.4831e-06, 4.4685e-06],\n",
       "            [3.9400e-06, 1.5397e-05],\n",
       "            [4.6681e-06, 1.0764e-05]], device='cpu')},\n",
       "   1: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 1.2413e-03,  0.0000e+00,  2.1401e-03, -2.1070e-03,  1.2780e-04,\n",
       "             1.7331e-03, -5.4336e-05,  1.7280e-03,  1.8056e-03,  2.5196e-04,\n",
       "            -3.0120e-03, -3.2953e-03, -1.0933e-03,  4.0869e-06, -1.7176e-03,\n",
       "            -1.1794e-03, -4.2960e-04,  1.6638e-03, -9.4908e-04, -1.8080e-04,\n",
       "            -2.6602e-03,  1.0205e-03,  1.1631e-03,  1.4377e-03,  9.3997e-04,\n",
       "             2.4855e-03, -1.7002e-04, -1.4113e-03,  6.0061e-04, -1.4508e-03,\n",
       "             1.5234e-03, -4.4235e-04,  1.0702e-04,  4.2038e-04, -1.2972e-03,\n",
       "             1.3272e-03,  2.6415e-03, -5.5739e-04, -9.1029e-04,  1.3823e-03,\n",
       "            -4.0860e-04, -7.8731e-04,  1.2282e-03,  1.9547e-03,  1.1446e-03,\n",
       "             3.4610e-04,  3.3440e-04,  3.5703e-04,  1.1439e-03,  1.0327e-04,\n",
       "            -2.7144e-05, -6.7892e-04, -9.6110e-04,  6.7140e-04,  2.9252e-04,\n",
       "             2.1769e-04,  6.7627e-04,  9.0693e-04,  3.2402e-05, -6.0541e-04,\n",
       "             1.0902e-03, -3.6970e-03,  2.3651e-03,  1.7198e-03,  2.0758e-04,\n",
       "             1.6676e-03, -4.3561e-04,  1.2385e-03,  1.3972e-04, -5.2263e-04,\n",
       "             1.6364e-03,  1.2285e-03, -3.5640e-04, -2.0757e-03, -4.3214e-04,\n",
       "             1.1349e-03, -4.4187e-04, -1.1329e-04,  9.8619e-04, -4.9398e-04,\n",
       "            -2.8966e-04,  9.5354e-04,  9.8751e-04, -1.0231e-03, -7.8575e-04,\n",
       "             4.3610e-04,  2.5700e-04,  1.0849e-03,  0.0000e+00,  6.0341e-04,\n",
       "            -1.0964e-04,  9.0385e-05,  4.9824e-04,  2.7123e-04,  5.6052e-45,\n",
       "             6.7382e-05, -1.6602e-04, -8.3391e-04,  6.1497e-04,  9.9754e-04],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([2.4884e-05, 0.0000e+00, 1.1075e-04, 2.8478e-05, 1.9747e-05, 3.0582e-05,\n",
       "            1.4319e-05, 2.8817e-05, 3.9024e-05, 1.4432e-05, 5.5994e-05, 5.4243e-05,\n",
       "            6.1636e-05, 6.9576e-05, 1.0334e-04, 6.5142e-05, 2.7396e-05, 1.3353e-04,\n",
       "            4.8722e-05, 1.3593e-05, 5.1978e-05, 1.1991e-04, 6.6532e-06, 2.1585e-05,\n",
       "            4.6962e-05, 6.1669e-05, 2.6836e-05, 4.8969e-05, 9.5377e-06, 7.8949e-05,\n",
       "            2.3910e-05, 3.2371e-05, 2.3612e-05, 2.2335e-05, 9.3993e-05, 1.9217e-05,\n",
       "            6.5282e-05, 1.6510e-05, 7.6668e-05, 2.4473e-05, 2.6667e-05, 2.1374e-05,\n",
       "            1.5012e-05, 1.9666e-05, 4.2970e-05, 9.1575e-06, 8.7729e-06, 9.7040e-05,\n",
       "            4.2006e-05, 5.1129e-05, 3.9294e-05, 1.2390e-05, 4.6126e-05, 1.5978e-05,\n",
       "            1.0419e-05, 1.6949e-05, 9.2859e-06, 7.3573e-06, 9.7850e-05, 1.7123e-05,\n",
       "            2.2947e-05, 6.9213e-05, 4.1763e-05, 1.3542e-05, 9.2946e-06, 3.5421e-05,\n",
       "            2.5060e-05, 1.9104e-05, 4.6314e-05, 5.7135e-05, 1.0356e-04, 1.1956e-05,\n",
       "            3.3585e-05, 5.8598e-05, 4.1799e-05, 7.3911e-06, 3.4269e-05, 7.7023e-06,\n",
       "            1.5150e-05, 1.7780e-05, 1.3203e-05, 1.3162e-05, 7.2062e-06, 1.0011e-04,\n",
       "            4.5737e-05, 1.6265e-05, 4.0442e-05, 7.8629e-06, 0.0000e+00, 7.4622e-06,\n",
       "            3.2206e-05, 1.8701e-05, 7.0091e-06, 4.7804e-05, 6.9405e-09, 2.7263e-05,\n",
       "            2.7236e-05, 2.5877e-05, 1.1910e-05, 9.2307e-06], device='cpu')},\n",
       "   2: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.9148e-03,  0.0000e+00, -6.4087e-04,  2.2770e-03,  9.1002e-05,\n",
       "              2.6836e-05,  1.8530e-03,  8.6032e-05,  3.9000e-05,  5.1196e-04,\n",
       "              6.9420e-06,  2.6434e-06,  1.7608e-03, -4.9971e-04,  3.1602e-03,\n",
       "              2.6920e-03,  1.8821e-04, -8.0562e-04,  1.1994e-03,  2.2188e-04,\n",
       "              2.8725e-07, -6.0225e-04,  2.0838e-03,  1.5501e-04,  2.5328e-03,\n",
       "              3.8492e-04,  1.4026e-09,  2.6370e-03, -4.6602e-04,  1.7343e-03,\n",
       "              2.2572e-04,  2.3688e-04,  1.7973e-03, -5.2248e-05,  2.6328e-03,\n",
       "              1.2512e-04, -1.4213e-04,  1.4913e-04,  2.9005e-03,  2.0072e-03,\n",
       "              1.6903e-03,  1.1882e-03,  9.4613e-04,  5.5799e-05,  4.6623e-04,\n",
       "              9.3147e-04,  2.5528e-04,  3.5379e-03,  7.0568e-04,  4.2017e-04,\n",
       "              1.1599e-03,  7.3700e-04,  2.5529e-03, -2.0822e-04, -8.5732e-06,\n",
       "              1.3828e-03,  6.4003e-04,  4.9042e-04,  1.0241e-03,  2.7613e-04,\n",
       "              4.7320e-04,  1.2209e-07,  8.7426e-05, -1.3467e-04,  2.5461e-05,\n",
       "              1.1793e-05,  2.0349e-03,  2.2759e-03, -1.2885e-04, -4.2406e-04,\n",
       "              1.9066e-03,  1.6041e-03,  7.4799e-04,  2.7313e-03,  3.3153e-03,\n",
       "              2.3426e-03,  1.8831e-04,  2.3103e-04,  4.1449e-04,  1.3264e-03,\n",
       "              2.1472e-04,  7.0703e-04, -6.7006e-05,  2.4181e-03,  2.4755e-03,\n",
       "              1.5362e-05,  3.5085e-07,  5.4447e-04,  0.0000e+00, -3.5008e-06,\n",
       "              1.1446e-04, -1.7291e-04, -3.1090e-06,  7.7901e-07, -5.6052e-45,\n",
       "              2.4671e-05,  9.3661e-05,  8.0640e-04, -2.2069e-05,  1.8491e-03],\n",
       "            [-1.8976e-03,  0.0000e+00, -5.3835e-03, -1.4445e-03,  2.4932e-06,\n",
       "             -3.0759e-05, -4.8041e-04, -1.0689e-04, -4.9258e-05, -5.5717e-04,\n",
       "             -1.4166e-03, -1.2623e-03, -7.2509e-04, -4.2311e-03, -1.5318e-03,\n",
       "             -1.0736e-03,  2.3063e-07, -6.4847e-03, -2.7663e-03,  6.5786e-06,\n",
       "             -1.3122e-03, -7.1421e-05, -2.1086e-03, -1.8271e-04,  5.2461e-05,\n",
       "             -4.5110e-03, -2.2947e-04, -1.3828e-03,  1.9977e-04, -1.4966e-03,\n",
       "             -2.1154e-05,  3.1748e-07, -1.1469e-03, -3.9914e-03, -1.9943e-03,\n",
       "             -1.4882e-04, -5.3266e-03, -4.9536e-03, -1.5862e-03, -2.0874e-03,\n",
       "             -1.1162e-03, -1.9307e-03, -4.2645e-03, -6.2926e-05, -4.5023e-03,\n",
       "             -2.5568e-03,  8.3519e-05, -2.6825e-03, -4.0807e-03, -1.9652e-03,\n",
       "             -3.8733e-04, -1.7048e-03, -1.7078e-03,  1.2500e-04, -4.4936e-03,\n",
       "             -5.2958e-03,  4.7173e-06, -2.9854e-05, -1.2530e-03,  4.6178e-08,\n",
       "             -4.0904e-03, -1.1643e-03, -1.0416e-04, -2.4701e-03, -5.4759e-03,\n",
       "             -1.1933e-05, -1.5765e-03, -2.2191e-03, -4.5739e-03, -3.1064e-03,\n",
       "             -4.6623e-04, -1.6386e-03, -9.9281e-04, -1.2042e-03, -1.5496e-03,\n",
       "             -2.1133e-03,  8.5606e-08,  4.4553e-07, -1.3893e-05, -7.9446e-04,\n",
       "             -6.3985e-03, -8.0693e-04, -3.8430e-03, -1.7195e-03, -1.3740e-03,\n",
       "             -4.7389e-03, -1.3716e-04, -1.8261e-05,  0.0000e+00,  1.3846e-04,\n",
       "              1.0599e-07,  1.4233e-04, -5.3392e-03, -1.3383e-04,  5.6052e-45,\n",
       "             -9.2179e-05, -3.9779e-03, -4.2430e-03, -5.2357e-03, -1.8627e-03],\n",
       "            [-1.7251e-05,  0.0000e+00,  6.0243e-03, -8.3248e-04, -9.3496e-05,\n",
       "              3.9232e-06, -1.3726e-03,  2.0857e-05,  1.0257e-05,  4.5207e-05,\n",
       "              1.4096e-03,  1.2597e-03, -1.0357e-03,  4.7308e-03, -1.6283e-03,\n",
       "             -1.6184e-03, -1.8844e-04,  7.2903e-03,  1.5670e-03, -2.2846e-04,\n",
       "              1.3119e-03,  6.7367e-04,  2.4728e-05,  2.7707e-05, -2.5853e-03,\n",
       "              4.1261e-03,  2.2947e-04, -1.2542e-03,  2.6626e-04, -2.3775e-04,\n",
       "             -2.0456e-04, -2.3719e-04, -6.5039e-04,  4.0437e-03, -6.3851e-04,\n",
       "              2.3703e-05,  5.4687e-03,  4.8044e-03, -1.3143e-03,  8.0191e-05,\n",
       "             -5.7415e-04,  7.4251e-04,  3.3183e-03,  7.1275e-06,  4.0361e-03,\n",
       "              1.6253e-03, -3.3880e-04, -8.5535e-04,  3.3751e-03,  1.5451e-03,\n",
       "             -7.7254e-04,  9.6780e-04, -8.4515e-04,  8.3221e-05,  4.5022e-03,\n",
       "              3.9130e-03, -6.4475e-04, -4.6057e-04,  2.2889e-04, -2.7618e-04,\n",
       "              3.6172e-03,  1.1641e-03,  1.6737e-05,  2.6048e-03,  5.4504e-03,\n",
       "              1.3980e-07, -4.5844e-04, -5.6775e-05,  4.7028e-03,  3.5305e-03,\n",
       "             -1.4403e-03,  3.4473e-05,  2.4482e-04, -1.5271e-03, -1.7657e-03,\n",
       "             -2.2934e-04, -1.8839e-04, -2.3148e-04, -4.0060e-04, -5.3195e-04,\n",
       "              6.1838e-03,  9.9894e-05,  3.9100e-03, -6.9856e-04, -1.1015e-03,\n",
       "              4.7235e-03,  1.3681e-04, -5.2621e-04,  0.0000e+00, -1.3496e-04,\n",
       "             -1.1457e-04,  3.0584e-05,  5.3424e-03,  1.3305e-04,  5.6052e-45,\n",
       "              6.7508e-05,  3.8843e-03,  3.4366e-03,  5.2577e-03,  1.3622e-05]],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([[6.4908e-05, 0.0000e+00, 4.5172e-05, 7.2541e-05, 7.4253e-06, 1.4921e-05,\n",
       "             7.6572e-05, 1.8703e-05, 9.1779e-06, 1.2833e-05, 2.9514e-07, 8.1014e-08,\n",
       "             6.4832e-05, 4.8813e-05, 7.9747e-05, 1.1294e-04, 2.2889e-06, 4.2622e-05,\n",
       "             8.7528e-05, 4.5545e-06, 2.0528e-07, 2.2162e-05, 6.1479e-05, 1.7558e-05,\n",
       "             2.1804e-04, 6.2589e-05, 9.0310e-07, 1.2256e-04, 5.9290e-05, 4.3034e-05,\n",
       "             5.1999e-06, 3.9317e-06, 1.0906e-04, 9.4605e-05, 1.9262e-04, 1.5016e-05,\n",
       "             6.5589e-05, 3.2433e-06, 8.1426e-05, 5.8041e-05, 6.4111e-05, 7.9104e-05,\n",
       "             1.1771e-04, 6.5464e-06, 9.3228e-05, 8.4045e-05, 8.0960e-05, 9.8021e-05,\n",
       "             1.2328e-04, 4.1216e-05, 1.4068e-04, 6.0294e-05, 1.2128e-04, 2.2258e-05,\n",
       "             6.6251e-06, 1.8613e-04, 5.1501e-05, 3.8984e-05, 4.7221e-05, 3.2981e-06,\n",
       "             8.6060e-05, 6.4993e-08, 3.0537e-06, 2.1851e-05, 7.4476e-06, 7.2780e-06,\n",
       "             1.3315e-04, 5.2258e-05, 8.3260e-05, 4.9945e-05, 1.7031e-04, 5.6256e-05,\n",
       "             6.6114e-05, 7.5945e-05, 2.8194e-04, 4.6967e-05, 3.8770e-06, 1.2854e-05,\n",
       "             2.9463e-05, 2.0884e-05, 7.2924e-06, 3.2173e-05, 7.5972e-06, 1.3803e-04,\n",
       "             1.8576e-04, 3.9558e-06, 9.1571e-07, 5.5460e-05, 0.0000e+00, 4.1506e-05,\n",
       "             1.3975e-06, 3.6500e-05, 7.4952e-06, 6.6582e-07, 1.7253e-08, 4.6141e-06,\n",
       "             5.3332e-06, 1.1449e-04, 5.3597e-06, 6.4235e-05],\n",
       "            [6.6722e-05, 0.0000e+00, 1.3387e-04, 7.1131e-05, 9.7337e-07, 1.2453e-05,\n",
       "             9.1711e-05, 1.6653e-05, 7.4060e-06, 1.5622e-05, 1.0625e-05, 6.0159e-06,\n",
       "             5.7119e-05, 9.0648e-05, 1.1068e-04, 1.8146e-04, 7.2226e-07, 1.7081e-04,\n",
       "             6.4408e-05, 9.6095e-07, 1.0813e-05, 8.3958e-05, 6.5160e-05, 1.6684e-05,\n",
       "             2.1017e-04, 1.2507e-04, 1.5685e-05, 1.3952e-04, 6.5477e-06, 5.9716e-05,\n",
       "             3.3990e-06, 7.7238e-08, 8.0088e-05, 1.5967e-04, 1.1736e-04, 1.3784e-05,\n",
       "             2.4043e-04, 7.2247e-05, 1.1309e-04, 5.9302e-05, 1.1321e-04, 6.7086e-05,\n",
       "             3.1161e-04, 5.6012e-06, 1.7609e-04, 1.7313e-04, 1.0401e-05, 1.2129e-04,\n",
       "             1.8508e-04, 4.2316e-05, 2.4041e-04, 6.9049e-05, 1.7614e-04, 3.1937e-06,\n",
       "             5.9308e-05, 1.9877e-04, 8.0618e-06, 6.9463e-06, 2.7703e-05, 1.9432e-07,\n",
       "             1.7198e-04, 4.9560e-06, 2.5006e-06, 2.7078e-05, 9.8456e-05, 6.5633e-06,\n",
       "             2.2639e-04, 5.6147e-05, 1.1864e-04, 1.7805e-04, 1.0598e-04, 6.3804e-05,\n",
       "             5.8399e-05, 1.1424e-04, 2.9579e-04, 5.0576e-05, 1.2032e-07, 5.3376e-06,\n",
       "             8.3701e-06, 2.0288e-05, 1.2876e-04, 2.9857e-05, 3.1037e-05, 7.2702e-05,\n",
       "             2.6582e-04, 6.6650e-05, 1.5067e-05, 6.7038e-06, 0.0000e+00, 1.1897e-05,\n",
       "             8.5883e-08, 2.6474e-06, 8.8264e-05, 8.8810e-06, 9.3212e-09, 4.7053e-06,\n",
       "             6.3238e-05, 1.2195e-04, 7.5259e-05, 6.7891e-05],\n",
       "            [4.5509e-06, 0.0000e+00, 1.5556e-04, 2.7954e-05, 1.0383e-05, 5.1690e-07,\n",
       "             6.9467e-05, 5.9025e-07, 5.7430e-07, 2.9873e-06, 9.0229e-06, 5.5513e-06,\n",
       "             3.3280e-05, 1.1667e-04, 4.2215e-05, 9.2492e-05, 3.1782e-06, 1.9297e-04,\n",
       "             1.0182e-04, 5.5986e-06, 9.9865e-06, 9.4177e-05, 5.0393e-06, 5.6285e-07,\n",
       "             1.3614e-04, 1.4957e-04, 1.2885e-05, 3.9855e-05, 6.1949e-05, 2.5701e-05,\n",
       "             1.9740e-06, 4.4134e-06, 1.0760e-04, 1.8225e-04, 1.5694e-04, 7.3093e-07,\n",
       "             2.4798e-04, 7.6159e-05, 4.0709e-05, 2.4062e-06, 9.0308e-05, 1.0141e-04,\n",
       "             3.0613e-04, 1.2629e-06, 2.0115e-04, 1.7053e-04, 8.1140e-05, 3.6939e-05,\n",
       "             2.2321e-04, 5.6785e-05, 1.5545e-04, 7.6325e-05, 8.9253e-05, 2.3009e-05,\n",
       "             6.6458e-05, 2.5965e-04, 4.7672e-05, 3.5964e-05, 4.6474e-05, 3.8536e-06,\n",
       "             2.0909e-04, 4.4806e-06, 1.6336e-07, 5.0364e-05, 1.0358e-04, 4.8466e-07,\n",
       "             1.4324e-04, 3.7833e-06, 1.6976e-04, 1.6752e-04, 1.3052e-04, 1.0001e-05,\n",
       "             8.3333e-05, 6.1249e-05, 1.5919e-04, 4.4816e-06, 4.4414e-06, 2.2213e-05,\n",
       "             2.3331e-05, 2.0145e-05, 1.3291e-04, 2.8081e-06, 4.2382e-05, 1.1949e-04,\n",
       "             1.2478e-04, 7.1384e-05, 1.1799e-05, 5.3296e-05, 0.0000e+00, 5.4644e-05,\n",
       "             1.6489e-06, 3.7039e-05, 9.2785e-05, 7.1852e-06, 1.2497e-09, 9.6387e-06,\n",
       "             6.0108e-05, 1.8237e-04, 8.1837e-05, 7.3964e-06]], device='cpu')},\n",
       "   3: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 0.0031, -0.0027, -0.0004], device='cpu'),\n",
       "    'exp_avg_sq': tensor([0.0002, 0.0003, 0.0003], device='cpu')}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'scheduler': {'factor': 0.1,\n",
       "  'min_lrs': [0],\n",
       "  'patience': 3,\n",
       "  'verbose': False,\n",
       "  'cooldown': 0,\n",
       "  'cooldown_counter': 0,\n",
       "  'mode': 'min',\n",
       "  'threshold': 0.0001,\n",
       "  'threshold_mode': 'rel',\n",
       "  'best': 0.0661608474329114,\n",
       "  'num_bad_epochs': 2,\n",
       "  'mode_worse': inf,\n",
       "  'eps': 1e-08,\n",
       "  'last_epoch': 63,\n",
       "  '_last_lr': [0.0001]},\n",
       " 'num_epochs': 100,\n",
       " 'patience': 6}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_state_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('fc1.weight',\n",
       "               tensor([[-0.6558, -1.8043],\n",
       "                       [-0.1315, -0.0952],\n",
       "                       [ 1.5437,  0.7683],\n",
       "                       [-0.8229, -0.4162],\n",
       "                       [-0.5392,  1.1862],\n",
       "                       [-0.5657, -1.0804],\n",
       "                       [-0.5703, -0.0938],\n",
       "                       [-0.7610, -1.0976],\n",
       "                       [-0.5786, -0.9177],\n",
       "                       [ 1.1570, -1.0527],\n",
       "                       [ 1.2828, -0.1041],\n",
       "                       [ 1.1541, -0.0843],\n",
       "                       [-1.1065, -0.1280],\n",
       "                       [ 0.7237,  0.9580],\n",
       "                       [-0.0183, -1.4489],\n",
       "                       [ 0.5599, -1.0856],\n",
       "                       [-0.4530,  0.8780],\n",
       "                       [ 1.9620,  0.9563],\n",
       "                       [-0.4510,  1.0656],\n",
       "                       [-0.5151,  1.0475],\n",
       "                       [ 1.1475, -0.0194],\n",
       "                       [ 1.2364,  0.6246],\n",
       "                       [ 0.4129, -2.0859],\n",
       "                       [-0.7276, -1.0393],\n",
       "                       [-1.4188,  0.0551],\n",
       "                       [ 1.0769,  0.6820],\n",
       "                       [ 1.3297,  0.3422],\n",
       "                       [-0.6409, -1.0140],\n",
       "                       [-1.3946,  1.7160],\n",
       "                       [-0.0485, -0.9490],\n",
       "                       [-1.0594, -0.5647],\n",
       "                       [-0.5381,  0.9154],\n",
       "                       [-1.0867,  0.6213],\n",
       "                       [ 0.7011,  0.7873],\n",
       "                       [-1.7020,  0.9369],\n",
       "                       [-0.6395, -0.9091],\n",
       "                       [ 1.7646,  0.0741],\n",
       "                       [ 2.3322,  0.3077],\n",
       "                       [-0.0591, -1.5176],\n",
       "                       [-0.6425, -1.7085],\n",
       "                       [ 0.3064, -0.5208],\n",
       "                       [-0.7448,  1.1209],\n",
       "                       [ 1.2779,  0.1003],\n",
       "                       [-0.4667, -0.9031],\n",
       "                       [ 0.7919,  0.8311],\n",
       "                       [ 0.7548, -0.0209],\n",
       "                       [-1.6305,  1.8820],\n",
       "                       [-0.0950, -2.0011],\n",
       "                       [ 0.5907,  0.7211],\n",
       "                       [-0.2416,  0.9600],\n",
       "                       [ 0.3792, -0.7352],\n",
       "                       [-0.3907,  0.6536],\n",
       "                       [ 0.2371, -0.8573],\n",
       "                       [-1.0202,  1.1594],\n",
       "                       [ 1.2575,  1.5320],\n",
       "                       [ 0.0035,  1.3368],\n",
       "                       [-2.1205,  0.4865],\n",
       "                       [-1.6998,  0.4360],\n",
       "                       [-0.6739,  0.9644],\n",
       "                       [-0.6984,  0.8756],\n",
       "                       [ 0.7940,  0.6673],\n",
       "                       [ 1.0085, -0.0117],\n",
       "                       [-0.5036, -0.7665],\n",
       "                       [ 0.1911,  1.1469],\n",
       "                       [ 2.1125,  0.9818],\n",
       "                       [-0.3553, -0.9691],\n",
       "                       [ 0.3728, -0.6503],\n",
       "                       [-0.7027, -1.9173],\n",
       "                       [ 0.5758,  1.2517],\n",
       "                       [ 1.4376, -0.0039],\n",
       "                       [-1.6638,  0.8688],\n",
       "                       [ 0.8844, -1.8727],\n",
       "                       [-0.1200,  1.1309],\n",
       "                       [ 0.2114, -0.8910],\n",
       "                       [-1.3194,  0.0551],\n",
       "                       [-0.2696, -1.8888],\n",
       "                       [-0.5841,  0.9951],\n",
       "                       [-0.8586,  1.0295],\n",
       "                       [-1.6918,  0.0386],\n",
       "                       [-0.7874,  0.1555],\n",
       "                       [ 2.9468,  0.4086],\n",
       "                       [-0.6432, -1.0882],\n",
       "                       [ 0.9795,  1.1432],\n",
       "                       [-1.7242,  1.1297],\n",
       "                       [ 0.1639, -1.0391],\n",
       "                       [ 1.7703,  0.9045],\n",
       "                       [ 1.4489, -0.1113],\n",
       "                       [-1.8718,  1.0649],\n",
       "                       [-0.1508, -0.0422],\n",
       "                       [-0.9742,  1.2781],\n",
       "                       [-0.4326,  0.7308],\n",
       "                       [-1.1014,  1.3827],\n",
       "                       [ 1.4419,  1.7327],\n",
       "                       [ 1.1469, -0.0912],\n",
       "                       [-0.0388, -0.0851],\n",
       "                       [-0.2366,  1.3285],\n",
       "                       [ 1.7946,  0.2605],\n",
       "                       [ 0.0076,  1.3037],\n",
       "                       [ 1.5601,  1.5066],\n",
       "                       [ 0.1653, -1.8723]], device='cpu')),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.5728, -0.5147,  0.1542,  0.2321, -1.3321, -1.3557,  0.5390, -1.3049,\n",
       "                       -1.1217, -1.0960, -1.1447, -1.0842,  0.2213,  0.2778,  0.2470,  0.3449,\n",
       "                       -1.0487,  0.2104,  0.2835, -1.1490, -1.1362,  0.0927, -1.1198, -1.1760,\n",
       "                        0.5548,  0.3179, -1.6853,  0.2936, -0.6575,  0.1877, -0.8938, -1.1383,\n",
       "                        0.2267,  0.5828,  0.3048, -1.0327,  0.3172, -0.7258,  0.0437, -0.5574,\n",
       "                        0.5438,  0.1896,  0.5495, -1.0939,  0.5604,  0.5207, -0.7976,  0.1217,\n",
       "                        0.5978,  0.2433,  0.7062,  0.2523,  0.4957, -0.4789, -1.0501,  0.5595,\n",
       "                       -1.1479, -0.8383,  0.1861, -1.3450,  0.4573, -1.0288, -0.8844, -0.1592,\n",
       "                       -0.9313, -1.2253,  0.6225, -0.6282,  0.3124,  0.3294,  0.2737, -1.1582,\n",
       "                        0.2613,  0.3666,  0.6721, -0.6667, -1.2523, -1.5768, -0.8565,  0.2294,\n",
       "                       -0.8425, -0.8032, -0.5233,  0.1807,  0.5416, -0.8009, -1.4654, -0.8655,\n",
       "                       -0.6146, -0.4187, -0.9361, -0.5854, -1.1863, -1.1025, -0.3966, -1.0383,\n",
       "                       -0.4991,  0.3329, -0.9638, -0.8745], device='cpu')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 4.0942e-01,  3.1245e-02,  7.3607e-01, -2.8863e-01, -1.2278e+00,\n",
       "                         1.0690e+00, -1.1776e-01,  1.1638e+00,  1.1243e+00,  7.7283e-01,\n",
       "                        -8.7492e-01, -1.5139e+00, -3.9127e-01,  5.6228e-01, -3.8469e-01,\n",
       "                        -1.9809e-01, -1.5030e+00,  9.9642e-01,  8.0354e-02, -9.5710e-01,\n",
       "                        -1.7391e+00,  9.0668e-01,  3.7639e-01,  1.0057e+00, -1.6995e-01,\n",
       "                         5.4325e-01, -3.6062e-01, -2.9459e-01,  3.9485e-01, -4.1085e-01,\n",
       "                         9.2197e-01, -1.3685e+00, -8.1725e-02,  2.5893e-01, -1.6379e-01,\n",
       "                         9.6395e-01,  5.9280e-01, -2.1521e+00, -3.0472e-01,  3.3843e-01,\n",
       "                        -3.6145e-01, -1.0290e-01,  2.1680e-01,  1.0690e+00,  4.7102e-01,\n",
       "                        -9.8290e-02,  3.9756e-01, -3.5474e-01,  3.1079e-01,  1.1376e-01,\n",
       "                        -3.0486e-01,  7.9469e-02, -3.6311e-01,  3.3485e-01, -1.7605e+00,\n",
       "                         2.6938e-01,  5.5447e-01,  6.1773e-01, -9.5776e-02, -1.3332e+00,\n",
       "                         2.5461e-01, -1.1330e+00,  1.4356e+00,  1.0518e-01, -1.8303e+00,\n",
       "                         1.3281e+00, -2.1691e-01,  3.6129e-01,  3.8993e-01,  5.0102e-01,\n",
       "                        -2.0107e-01,  3.9962e-01,  9.8142e-02, -2.8270e-01, -1.6560e-01,\n",
       "                         7.6549e-02, -1.5629e+00, -8.6749e-01,  8.6506e-01, -2.3837e-01,\n",
       "                        -1.8206e+00,  6.4980e-01, -9.9861e-01, -2.2359e-01, -2.9241e-01,\n",
       "                        -2.1320e+00, -3.8448e-01,  4.8176e-01, -3.0133e-03,  2.1258e-01,\n",
       "                        -1.5921e+00,  1.7853e-01, -1.5155e+00, -4.8662e-01,  2.4251e-02,\n",
       "                        -1.4916e+00, -2.0462e+00,  1.2605e-01, -2.0023e+00,  3.0285e-01],\n",
       "                       [ 3.5063e-01,  5.2154e-03, -4.2232e-01,  1.8287e-01, -3.0166e-01,\n",
       "                        -1.2611e+00,  2.4065e-01, -9.7083e-01, -1.3971e+00,  7.1267e-01,\n",
       "                         1.4531e+00,  1.5685e+00,  4.0355e-01, -2.2358e-01, -2.1250e-01,\n",
       "                        -2.2635e-01,  7.1211e-02, -4.1187e-01,  3.0494e-01, -3.4525e-01,\n",
       "                         1.4612e+00, -3.6232e-01,  3.9747e-01, -7.4390e-01,  3.4223e-01,\n",
       "                        -2.8891e-01,  1.2597e+00,  1.8021e-01, -1.6988e+00,  2.7267e-02,\n",
       "                        -1.4676e+00, -9.5106e-01,  2.9992e-01, -3.0694e-01,  6.7779e-01,\n",
       "                        -7.2166e-01, -3.9928e-01,  3.8227e-01, -8.8079e-02,  2.2558e-01,\n",
       "                        -1.6004e-01,  3.3252e-01, -1.9532e-01, -1.0994e+00, -2.3633e-01,\n",
       "                        -2.1169e-01, -1.5373e+00, -1.4323e-01, -2.8801e-01,  3.7119e-01,\n",
       "                         2.1421e-02,  7.9180e-02, -9.4102e-02, -1.8920e+00,  4.2679e-01,\n",
       "                         6.6292e-02, -1.7871e+00, -1.4044e+00,  6.6167e-01, -5.9904e-01,\n",
       "                        -2.6365e-01,  1.6587e+00, -1.5846e+00, -5.2773e-01,  3.1286e-01,\n",
       "                        -1.3831e+00,  1.5088e-02,  4.1186e-01, -1.8427e-01, -3.6258e-01,\n",
       "                         6.3838e-01,  4.0893e-01,  1.9456e-01, -6.4560e-03,  2.6159e-01,\n",
       "                         3.8707e-01, -6.2473e-01, -1.8151e-01, -1.4310e+00,  2.3777e-01,\n",
       "                         4.4336e-01, -2.5184e-01,  2.4494e-02,  7.8190e-01,  1.0955e-03,\n",
       "                         4.0900e-01,  1.2747e+00, -1.7149e+00,  6.3893e-02, -1.0168e+00,\n",
       "                        -5.1799e-01, -2.2098e+00,  2.9420e-01,  1.2958e+00, -1.4337e-01,\n",
       "                         5.2563e-01,  5.6847e-01,  1.4193e-01,  3.0270e-01,  4.2606e-01],\n",
       "                       [-2.2352e+00, -1.8817e-02, -2.6502e-01,  1.0460e-01,  1.0573e+00,\n",
       "                        -4.0595e-01, -1.3773e-01, -6.3019e-01, -1.2810e-01, -1.8083e+00,\n",
       "                        -1.4593e+00, -1.4827e+00, -1.3492e-02, -2.7389e-01,  7.6866e-01,\n",
       "                         4.5001e-01,  1.2127e+00, -2.5829e-01, -3.6171e-01,  1.1667e+00,\n",
       "                        -1.0901e+00, -2.5251e-02, -1.7181e+00, -1.2823e+00, -2.1343e-01,\n",
       "                        -3.1619e-02, -1.3409e+00,  4.6218e-01,  3.6506e-01,  5.8927e-01,\n",
       "                         7.8611e-01,  1.4570e+00, -2.8110e-01, -4.7422e-02, -2.9272e-01,\n",
       "                        -9.9141e-01, -5.1644e-02,  5.1736e-01,  7.0722e-01, -2.5505e+00,\n",
       "                         1.6743e-01, -2.3160e-01,  1.1786e-01, -2.5094e-01, -6.9468e-03,\n",
       "                         8.2863e-02,  3.6009e-01,  8.6404e-01,  4.0322e-02, -3.2162e-01,\n",
       "                         3.5352e-01, -2.1468e-01,  3.1397e-01,  3.5374e-01,  4.3479e-01,\n",
       "                        -1.3899e-01,  3.2138e-01,  2.1622e-01, -4.3205e-01,  1.3703e+00,\n",
       "                        -2.6831e-02, -1.5741e+00, -4.1397e-01,  2.9652e-01,  3.4926e-01,\n",
       "                        -2.6967e-01,  2.5749e-01, -2.1242e+00, -2.9072e-01,  3.3170e-02,\n",
       "                        -3.3126e-01, -1.5147e+00, -3.5873e-01,  4.8231e-01, -2.4112e-01,\n",
       "                        -1.5982e+00,  1.4443e+00,  8.2424e-01,  4.0667e-01, -2.7575e-01,\n",
       "                         4.4572e-01, -1.2123e+00,  5.2165e-01, -3.5948e-01,  3.7463e-01,\n",
       "                         5.0908e-01, -1.3709e+00,  2.6056e-01, -9.7352e-02,  2.1693e-01,\n",
       "                         1.4871e+00,  5.4809e-01,  5.3693e-01, -1.4192e+00, -6.5896e-02,\n",
       "                         7.0509e-01,  2.6693e-01, -2.6736e-01,  4.7039e-01, -1.6592e+00]],\n",
       "                      device='cpu')),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.0210, -0.0192,  0.0207], device='cpu'))]),\n",
       " 'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc2f7846d10>,\n",
       " 'val_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc2f71b3f50>,\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'optimizer': {'state': {0: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.3685e-03, -9.7889e-04],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-1.5353e-04,  1.4701e-04],\n",
       "            [ 3.4770e-04,  5.6011e-04],\n",
       "            [ 4.0141e-04,  1.4776e-04],\n",
       "            [-2.5883e-04, -2.0992e-03],\n",
       "            [ 1.5449e-04,  2.8779e-04],\n",
       "            [-1.5961e-04, -2.1166e-03],\n",
       "            [-1.3842e-04, -2.2399e-03],\n",
       "            [ 1.5072e-04, -1.7804e-05],\n",
       "            [-6.3255e-03, -5.2268e-03],\n",
       "            [-6.8567e-03, -5.7894e-03],\n",
       "            [ 6.2771e-04,  2.4082e-04],\n",
       "            [-6.7329e-04, -1.5038e-04],\n",
       "            [-2.5339e-05,  1.1856e-03],\n",
       "            [-1.3936e-05,  5.5602e-04],\n",
       "            [ 1.4005e-03, -3.7320e-04],\n",
       "            [-1.1718e-04, -1.4054e-04],\n",
       "            [-1.7097e-03, -1.7043e-03],\n",
       "            [ 9.6552e-04, -1.8317e-04],\n",
       "            [-5.6341e-03, -4.8512e-03],\n",
       "            [-4.7633e-04, -6.8443e-05],\n",
       "            [ 3.9150e-04, -5.0092e-04],\n",
       "            [-5.4490e-05, -1.8349e-03],\n",
       "            [ 2.7189e-04,  7.2915e-05],\n",
       "            [ 1.9915e-04,  5.5347e-04],\n",
       "            [-5.7647e-04, -3.4285e-04],\n",
       "            [ 4.0012e-04,  9.2164e-04],\n",
       "            [-2.8781e-04, -2.5235e-04],\n",
       "            [ 1.9759e-04,  6.4435e-04],\n",
       "            [-4.3568e-04, -1.7314e-03],\n",
       "            [ 1.5158e-03, -3.9147e-04],\n",
       "            [ 1.1506e-04, -3.3335e-04],\n",
       "            [ 3.8423e-04,  6.4273e-04],\n",
       "            [ 3.6895e-04, -6.1120e-04],\n",
       "            [-8.1468e-05, -1.6746e-03],\n",
       "            [ 5.1763e-04,  1.1785e-04],\n",
       "            [-1.9991e-04,  1.0824e-03],\n",
       "            [ 1.2246e-04,  1.0715e-03],\n",
       "            [ 1.5480e-03, -1.0355e-03],\n",
       "            [ 8.7689e-04,  1.1037e-03],\n",
       "            [-1.0752e-03, -1.4165e-03],\n",
       "            [ 5.6452e-04,  3.2944e-04],\n",
       "            [-2.0407e-04, -2.4012e-03],\n",
       "            [ 1.8807e-04,  5.6039e-04],\n",
       "            [ 5.5348e-04,  6.4214e-04],\n",
       "            [-4.2972e-04, -3.0965e-04],\n",
       "            [ 1.5004e-04,  8.1886e-04],\n",
       "            [ 4.3808e-04,  8.1595e-04],\n",
       "            [-1.7890e-03, -1.7042e-03],\n",
       "            [ 1.0602e-03,  1.3846e-03],\n",
       "            [-8.7528e-04, -6.9610e-04],\n",
       "            [-4.5349e-05,  6.3485e-04],\n",
       "            [-5.5836e-04, -4.5324e-04],\n",
       "            [ 4.4856e-05,  1.9974e-04],\n",
       "            [-7.6765e-04, -4.7949e-04],\n",
       "            [-4.9034e-04, -2.5633e-04],\n",
       "            [-6.2581e-04, -1.3375e-04],\n",
       "            [-2.2984e-03, -2.6768e-03],\n",
       "            [ 1.5975e-03, -5.0898e-04],\n",
       "            [ 3.3004e-04,  5.1178e-04],\n",
       "            [-7.5813e-03, -6.5530e-03],\n",
       "            [-3.7074e-04, -2.8526e-03],\n",
       "            [ 1.8103e-03,  1.7346e-03],\n",
       "            [ 4.2191e-05,  2.5326e-04],\n",
       "            [ 3.1980e-05, -2.1523e-03],\n",
       "            [ 7.0600e-04,  8.8419e-04],\n",
       "            [ 1.2390e-03, -8.7540e-04],\n",
       "            [-7.0661e-04, -1.6852e-04],\n",
       "            [ 8.3661e-04, -1.3591e-04],\n",
       "            [ 1.4837e-04, -4.6583e-04],\n",
       "            [ 5.2257e-04, -4.6976e-04],\n",
       "            [-8.3341e-05, -1.1003e-04],\n",
       "            [ 2.2515e-05,  8.3550e-04],\n",
       "            [ 1.8113e-04,  2.3376e-05],\n",
       "            [ 4.5811e-04, -3.2224e-04],\n",
       "            [ 1.4914e-03, -2.5039e-04],\n",
       "            [ 4.8546e-04, -1.4889e-04],\n",
       "            [-6.2937e-04, -1.2823e-04],\n",
       "            [ 3.0234e-04, -4.3830e-05],\n",
       "            [-3.4690e-04,  7.5189e-04],\n",
       "            [ 2.0117e-04, -1.3202e-03],\n",
       "            [ 1.1593e-03,  1.2195e-03],\n",
       "            [ 4.2052e-04, -6.4088e-04],\n",
       "            [ 3.1860e-05,  6.9035e-04],\n",
       "            [ 2.3286e-04,  4.1042e-04],\n",
       "            [ 8.3210e-06, -1.5833e-05],\n",
       "            [-6.4171e-04, -9.9525e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-2.1352e-04, -9.8869e-05],\n",
       "            [ 7.0911e-04, -2.0344e-04],\n",
       "            [-2.4645e-04, -3.9571e-04],\n",
       "            [ 5.6229e-04,  6.2525e-04],\n",
       "            [-6.9708e-05, -1.7574e-04],\n",
       "            [-5.6052e-45, -5.6052e-45],\n",
       "            [ 8.7715e-04,  1.8032e-04],\n",
       "            [-8.7034e-04,  2.4251e-04],\n",
       "            [-1.0598e-03, -8.6951e-04],\n",
       "            [ 3.9212e-04,  6.0674e-04],\n",
       "            [ 2.7102e-04, -3.0535e-04]], device='cpu'),\n",
       "    'exp_avg_sq': tensor([[2.9894e-05, 2.0862e-05],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [6.0251e-06, 7.8995e-06],\n",
       "            [5.5849e-06, 8.5187e-06],\n",
       "            [4.7381e-05, 2.4069e-05],\n",
       "            [2.1180e-05, 7.8678e-05],\n",
       "            [1.8898e-06, 4.0898e-06],\n",
       "            [2.6482e-05, 7.1318e-05],\n",
       "            [3.5205e-05, 9.7363e-05],\n",
       "            [2.9866e-05, 8.9027e-06],\n",
       "            [1.0974e-04, 6.7453e-05],\n",
       "            [1.1669e-04, 7.4314e-05],\n",
       "            [9.0335e-06, 1.7235e-05],\n",
       "            [6.9564e-06, 7.4705e-06],\n",
       "            [4.1496e-06, 9.2421e-06],\n",
       "            [1.2178e-05, 8.7653e-06],\n",
       "            [7.8970e-05, 2.5813e-05],\n",
       "            [5.2842e-06, 9.1980e-06],\n",
       "            [1.4356e-05, 8.9021e-06],\n",
       "            [3.3591e-05, 1.5344e-05],\n",
       "            [1.0071e-04, 7.5881e-05],\n",
       "            [8.1656e-06, 8.6439e-06],\n",
       "            [4.8495e-06, 4.6709e-06],\n",
       "            [2.1401e-05, 5.3582e-05],\n",
       "            [4.0187e-06, 9.7952e-06],\n",
       "            [5.2072e-06, 4.4688e-06],\n",
       "            [5.9999e-05, 3.8582e-05],\n",
       "            [9.8872e-06, 1.0581e-05],\n",
       "            [1.8265e-05, 7.7799e-06],\n",
       "            [4.3653e-06, 1.2428e-05],\n",
       "            [2.4383e-05, 4.5762e-05],\n",
       "            [9.2719e-05, 3.2864e-05],\n",
       "            [2.8440e-06, 3.0675e-06],\n",
       "            [2.1047e-06, 1.9826e-06],\n",
       "            [7.2711e-06, 5.9379e-06],\n",
       "            [2.4035e-05, 4.4343e-05],\n",
       "            [6.8647e-06, 1.4762e-05],\n",
       "            [5.6567e-06, 2.0663e-05],\n",
       "            [4.1377e-06, 5.7797e-06],\n",
       "            [3.5468e-05, 2.1003e-05],\n",
       "            [3.8189e-06, 5.7153e-06],\n",
       "            [3.6282e-06, 2.8937e-06],\n",
       "            [2.9132e-06, 5.3829e-06],\n",
       "            [1.8301e-05, 5.5533e-05],\n",
       "            [4.2198e-06, 3.8905e-06],\n",
       "            [2.1029e-06, 2.4976e-06],\n",
       "            [1.2512e-05, 9.3198e-06],\n",
       "            [3.7511e-06, 5.0748e-06],\n",
       "            [7.9378e-06, 4.4012e-06],\n",
       "            [1.5468e-05, 8.7927e-06],\n",
       "            [5.8105e-06, 1.0606e-05],\n",
       "            [3.9697e-06, 2.9507e-06],\n",
       "            [4.2912e-06, 1.0321e-05],\n",
       "            [2.9222e-05, 2.1532e-05],\n",
       "            [4.7618e-06, 1.2476e-05],\n",
       "            [5.3888e-06, 2.4542e-06],\n",
       "            [1.3708e-05, 5.2420e-06],\n",
       "            [1.2482e-05, 4.0013e-06],\n",
       "            [2.0079e-05, 1.4950e-05],\n",
       "            [4.7264e-05, 1.6006e-05],\n",
       "            [2.9141e-06, 2.3943e-06],\n",
       "            [1.3464e-04, 8.7124e-05],\n",
       "            [3.6629e-05, 1.1103e-04],\n",
       "            [1.1945e-05, 7.8221e-06],\n",
       "            [4.9133e-06, 9.5781e-06],\n",
       "            [2.6801e-05, 9.5245e-05],\n",
       "            [2.9837e-06, 6.4312e-06],\n",
       "            [1.5170e-05, 1.3957e-05],\n",
       "            [5.4162e-06, 4.7453e-06],\n",
       "            [7.9063e-06, 1.3170e-05],\n",
       "            [7.2473e-06, 6.0861e-06],\n",
       "            [1.3115e-05, 6.8743e-06],\n",
       "            [1.0159e-05, 5.3390e-06],\n",
       "            [5.8869e-06, 8.6440e-06],\n",
       "            [4.8304e-06, 1.0895e-05],\n",
       "            [4.3112e-06, 7.9128e-06],\n",
       "            [1.0641e-04, 2.9429e-05],\n",
       "            [2.0771e-05, 6.9678e-06],\n",
       "            [2.2088e-05, 1.3070e-05],\n",
       "            [1.2947e-06, 1.5947e-06],\n",
       "            [4.1441e-06, 2.3040e-05],\n",
       "            [2.2479e-05, 2.5862e-05],\n",
       "            [4.9452e-06, 9.2864e-06],\n",
       "            [7.5554e-06, 5.3895e-06],\n",
       "            [4.1172e-06, 1.1379e-05],\n",
       "            [7.0791e-06, 1.6573e-05],\n",
       "            [8.2115e-05, 4.8286e-05],\n",
       "            [1.2381e-05, 4.1259e-06],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [1.0595e-05, 7.9708e-06],\n",
       "            [9.4128e-05, 3.4065e-05],\n",
       "            [3.9718e-05, 2.9561e-05],\n",
       "            [2.8540e-06, 7.8989e-06],\n",
       "            [9.6461e-05, 5.6295e-05],\n",
       "            [3.3248e-09, 2.4441e-08],\n",
       "            [6.3192e-05, 2.9412e-05],\n",
       "            [2.2291e-05, 5.4483e-05],\n",
       "            [8.4831e-06, 4.4685e-06],\n",
       "            [3.9400e-06, 1.5397e-05],\n",
       "            [4.6681e-06, 1.0764e-05]], device='cpu')},\n",
       "   1: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 1.2413e-03,  0.0000e+00,  2.1401e-03, -2.1070e-03,  1.2780e-04,\n",
       "             1.7331e-03, -5.4336e-05,  1.7280e-03,  1.8056e-03,  2.5196e-04,\n",
       "            -3.0120e-03, -3.2953e-03, -1.0933e-03,  4.0869e-06, -1.7176e-03,\n",
       "            -1.1794e-03, -4.2960e-04,  1.6638e-03, -9.4908e-04, -1.8080e-04,\n",
       "            -2.6602e-03,  1.0205e-03,  1.1631e-03,  1.4377e-03,  9.3997e-04,\n",
       "             2.4855e-03, -1.7002e-04, -1.4113e-03,  6.0061e-04, -1.4508e-03,\n",
       "             1.5234e-03, -4.4235e-04,  1.0702e-04,  4.2038e-04, -1.2972e-03,\n",
       "             1.3272e-03,  2.6415e-03, -5.5739e-04, -9.1029e-04,  1.3823e-03,\n",
       "            -4.0860e-04, -7.8731e-04,  1.2282e-03,  1.9547e-03,  1.1446e-03,\n",
       "             3.4610e-04,  3.3440e-04,  3.5703e-04,  1.1439e-03,  1.0327e-04,\n",
       "            -2.7144e-05, -6.7892e-04, -9.6110e-04,  6.7140e-04,  2.9252e-04,\n",
       "             2.1769e-04,  6.7627e-04,  9.0693e-04,  3.2402e-05, -6.0541e-04,\n",
       "             1.0902e-03, -3.6970e-03,  2.3651e-03,  1.7198e-03,  2.0758e-04,\n",
       "             1.6676e-03, -4.3561e-04,  1.2385e-03,  1.3972e-04, -5.2263e-04,\n",
       "             1.6364e-03,  1.2285e-03, -3.5640e-04, -2.0757e-03, -4.3214e-04,\n",
       "             1.1349e-03, -4.4187e-04, -1.1329e-04,  9.8619e-04, -4.9398e-04,\n",
       "            -2.8966e-04,  9.5354e-04,  9.8751e-04, -1.0231e-03, -7.8575e-04,\n",
       "             4.3610e-04,  2.5700e-04,  1.0849e-03,  0.0000e+00,  6.0341e-04,\n",
       "            -1.0964e-04,  9.0385e-05,  4.9824e-04,  2.7123e-04,  5.6052e-45,\n",
       "             6.7382e-05, -1.6602e-04, -8.3391e-04,  6.1497e-04,  9.9754e-04],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([2.4884e-05, 0.0000e+00, 1.1075e-04, 2.8478e-05, 1.9747e-05, 3.0582e-05,\n",
       "            1.4319e-05, 2.8817e-05, 3.9024e-05, 1.4432e-05, 5.5994e-05, 5.4243e-05,\n",
       "            6.1636e-05, 6.9576e-05, 1.0334e-04, 6.5142e-05, 2.7396e-05, 1.3353e-04,\n",
       "            4.8722e-05, 1.3593e-05, 5.1978e-05, 1.1991e-04, 6.6532e-06, 2.1585e-05,\n",
       "            4.6962e-05, 6.1669e-05, 2.6836e-05, 4.8969e-05, 9.5377e-06, 7.8949e-05,\n",
       "            2.3910e-05, 3.2371e-05, 2.3612e-05, 2.2335e-05, 9.3993e-05, 1.9217e-05,\n",
       "            6.5282e-05, 1.6510e-05, 7.6668e-05, 2.4473e-05, 2.6667e-05, 2.1374e-05,\n",
       "            1.5012e-05, 1.9666e-05, 4.2970e-05, 9.1575e-06, 8.7729e-06, 9.7040e-05,\n",
       "            4.2006e-05, 5.1129e-05, 3.9294e-05, 1.2390e-05, 4.6126e-05, 1.5978e-05,\n",
       "            1.0419e-05, 1.6949e-05, 9.2859e-06, 7.3573e-06, 9.7850e-05, 1.7123e-05,\n",
       "            2.2947e-05, 6.9213e-05, 4.1763e-05, 1.3542e-05, 9.2946e-06, 3.5421e-05,\n",
       "            2.5060e-05, 1.9104e-05, 4.6314e-05, 5.7135e-05, 1.0356e-04, 1.1956e-05,\n",
       "            3.3585e-05, 5.8598e-05, 4.1799e-05, 7.3911e-06, 3.4269e-05, 7.7023e-06,\n",
       "            1.5150e-05, 1.7780e-05, 1.3203e-05, 1.3162e-05, 7.2062e-06, 1.0011e-04,\n",
       "            4.5737e-05, 1.6265e-05, 4.0442e-05, 7.8629e-06, 0.0000e+00, 7.4622e-06,\n",
       "            3.2206e-05, 1.8701e-05, 7.0091e-06, 4.7804e-05, 6.9405e-09, 2.7263e-05,\n",
       "            2.7236e-05, 2.5877e-05, 1.1910e-05, 9.2307e-06], device='cpu')},\n",
       "   2: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.9148e-03,  0.0000e+00, -6.4087e-04,  2.2770e-03,  9.1002e-05,\n",
       "              2.6836e-05,  1.8530e-03,  8.6032e-05,  3.9000e-05,  5.1196e-04,\n",
       "              6.9420e-06,  2.6434e-06,  1.7608e-03, -4.9971e-04,  3.1602e-03,\n",
       "              2.6920e-03,  1.8821e-04, -8.0562e-04,  1.1994e-03,  2.2188e-04,\n",
       "              2.8725e-07, -6.0225e-04,  2.0838e-03,  1.5501e-04,  2.5328e-03,\n",
       "              3.8492e-04,  1.4026e-09,  2.6370e-03, -4.6602e-04,  1.7343e-03,\n",
       "              2.2572e-04,  2.3688e-04,  1.7973e-03, -5.2248e-05,  2.6328e-03,\n",
       "              1.2512e-04, -1.4213e-04,  1.4913e-04,  2.9005e-03,  2.0072e-03,\n",
       "              1.6903e-03,  1.1882e-03,  9.4613e-04,  5.5799e-05,  4.6623e-04,\n",
       "              9.3147e-04,  2.5528e-04,  3.5379e-03,  7.0568e-04,  4.2017e-04,\n",
       "              1.1599e-03,  7.3700e-04,  2.5529e-03, -2.0822e-04, -8.5732e-06,\n",
       "              1.3828e-03,  6.4003e-04,  4.9042e-04,  1.0241e-03,  2.7613e-04,\n",
       "              4.7320e-04,  1.2209e-07,  8.7426e-05, -1.3467e-04,  2.5461e-05,\n",
       "              1.1793e-05,  2.0349e-03,  2.2759e-03, -1.2885e-04, -4.2406e-04,\n",
       "              1.9066e-03,  1.6041e-03,  7.4799e-04,  2.7313e-03,  3.3153e-03,\n",
       "              2.3426e-03,  1.8831e-04,  2.3103e-04,  4.1449e-04,  1.3264e-03,\n",
       "              2.1472e-04,  7.0703e-04, -6.7006e-05,  2.4181e-03,  2.4755e-03,\n",
       "              1.5362e-05,  3.5085e-07,  5.4447e-04,  0.0000e+00, -3.5008e-06,\n",
       "              1.1446e-04, -1.7291e-04, -3.1090e-06,  7.7901e-07, -5.6052e-45,\n",
       "              2.4671e-05,  9.3661e-05,  8.0640e-04, -2.2069e-05,  1.8491e-03],\n",
       "            [-1.8976e-03,  0.0000e+00, -5.3835e-03, -1.4445e-03,  2.4932e-06,\n",
       "             -3.0759e-05, -4.8041e-04, -1.0689e-04, -4.9258e-05, -5.5717e-04,\n",
       "             -1.4166e-03, -1.2623e-03, -7.2509e-04, -4.2311e-03, -1.5318e-03,\n",
       "             -1.0736e-03,  2.3063e-07, -6.4847e-03, -2.7663e-03,  6.5786e-06,\n",
       "             -1.3122e-03, -7.1421e-05, -2.1086e-03, -1.8271e-04,  5.2461e-05,\n",
       "             -4.5110e-03, -2.2947e-04, -1.3828e-03,  1.9977e-04, -1.4966e-03,\n",
       "             -2.1154e-05,  3.1748e-07, -1.1469e-03, -3.9914e-03, -1.9943e-03,\n",
       "             -1.4882e-04, -5.3266e-03, -4.9536e-03, -1.5862e-03, -2.0874e-03,\n",
       "             -1.1162e-03, -1.9307e-03, -4.2645e-03, -6.2926e-05, -4.5023e-03,\n",
       "             -2.5568e-03,  8.3519e-05, -2.6825e-03, -4.0807e-03, -1.9652e-03,\n",
       "             -3.8733e-04, -1.7048e-03, -1.7078e-03,  1.2500e-04, -4.4936e-03,\n",
       "             -5.2958e-03,  4.7173e-06, -2.9854e-05, -1.2530e-03,  4.6178e-08,\n",
       "             -4.0904e-03, -1.1643e-03, -1.0416e-04, -2.4701e-03, -5.4759e-03,\n",
       "             -1.1933e-05, -1.5765e-03, -2.2191e-03, -4.5739e-03, -3.1064e-03,\n",
       "             -4.6623e-04, -1.6386e-03, -9.9281e-04, -1.2042e-03, -1.5496e-03,\n",
       "             -2.1133e-03,  8.5606e-08,  4.4553e-07, -1.3893e-05, -7.9446e-04,\n",
       "             -6.3985e-03, -8.0693e-04, -3.8430e-03, -1.7195e-03, -1.3740e-03,\n",
       "             -4.7389e-03, -1.3716e-04, -1.8261e-05,  0.0000e+00,  1.3846e-04,\n",
       "              1.0599e-07,  1.4233e-04, -5.3392e-03, -1.3383e-04,  5.6052e-45,\n",
       "             -9.2179e-05, -3.9779e-03, -4.2430e-03, -5.2357e-03, -1.8627e-03],\n",
       "            [-1.7251e-05,  0.0000e+00,  6.0243e-03, -8.3248e-04, -9.3496e-05,\n",
       "              3.9232e-06, -1.3726e-03,  2.0857e-05,  1.0257e-05,  4.5207e-05,\n",
       "              1.4096e-03,  1.2597e-03, -1.0357e-03,  4.7308e-03, -1.6283e-03,\n",
       "             -1.6184e-03, -1.8844e-04,  7.2903e-03,  1.5670e-03, -2.2846e-04,\n",
       "              1.3119e-03,  6.7367e-04,  2.4728e-05,  2.7707e-05, -2.5853e-03,\n",
       "              4.1261e-03,  2.2947e-04, -1.2542e-03,  2.6626e-04, -2.3775e-04,\n",
       "             -2.0456e-04, -2.3719e-04, -6.5039e-04,  4.0437e-03, -6.3851e-04,\n",
       "              2.3703e-05,  5.4687e-03,  4.8044e-03, -1.3143e-03,  8.0191e-05,\n",
       "             -5.7415e-04,  7.4251e-04,  3.3183e-03,  7.1275e-06,  4.0361e-03,\n",
       "              1.6253e-03, -3.3880e-04, -8.5535e-04,  3.3751e-03,  1.5451e-03,\n",
       "             -7.7254e-04,  9.6780e-04, -8.4515e-04,  8.3221e-05,  4.5022e-03,\n",
       "              3.9130e-03, -6.4475e-04, -4.6057e-04,  2.2889e-04, -2.7618e-04,\n",
       "              3.6172e-03,  1.1641e-03,  1.6737e-05,  2.6048e-03,  5.4504e-03,\n",
       "              1.3980e-07, -4.5844e-04, -5.6775e-05,  4.7028e-03,  3.5305e-03,\n",
       "             -1.4403e-03,  3.4473e-05,  2.4482e-04, -1.5271e-03, -1.7657e-03,\n",
       "             -2.2934e-04, -1.8839e-04, -2.3148e-04, -4.0060e-04, -5.3195e-04,\n",
       "              6.1838e-03,  9.9894e-05,  3.9100e-03, -6.9856e-04, -1.1015e-03,\n",
       "              4.7235e-03,  1.3681e-04, -5.2621e-04,  0.0000e+00, -1.3496e-04,\n",
       "             -1.1457e-04,  3.0584e-05,  5.3424e-03,  1.3305e-04,  5.6052e-45,\n",
       "              6.7508e-05,  3.8843e-03,  3.4366e-03,  5.2577e-03,  1.3622e-05]],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([[6.4908e-05, 0.0000e+00, 4.5172e-05, 7.2541e-05, 7.4253e-06, 1.4921e-05,\n",
       "             7.6572e-05, 1.8703e-05, 9.1779e-06, 1.2833e-05, 2.9514e-07, 8.1014e-08,\n",
       "             6.4832e-05, 4.8813e-05, 7.9747e-05, 1.1294e-04, 2.2889e-06, 4.2622e-05,\n",
       "             8.7528e-05, 4.5545e-06, 2.0528e-07, 2.2162e-05, 6.1479e-05, 1.7558e-05,\n",
       "             2.1804e-04, 6.2589e-05, 9.0310e-07, 1.2256e-04, 5.9290e-05, 4.3034e-05,\n",
       "             5.1999e-06, 3.9317e-06, 1.0906e-04, 9.4605e-05, 1.9262e-04, 1.5016e-05,\n",
       "             6.5589e-05, 3.2433e-06, 8.1426e-05, 5.8041e-05, 6.4111e-05, 7.9104e-05,\n",
       "             1.1771e-04, 6.5464e-06, 9.3228e-05, 8.4045e-05, 8.0960e-05, 9.8021e-05,\n",
       "             1.2328e-04, 4.1216e-05, 1.4068e-04, 6.0294e-05, 1.2128e-04, 2.2258e-05,\n",
       "             6.6251e-06, 1.8613e-04, 5.1501e-05, 3.8984e-05, 4.7221e-05, 3.2981e-06,\n",
       "             8.6060e-05, 6.4993e-08, 3.0537e-06, 2.1851e-05, 7.4476e-06, 7.2780e-06,\n",
       "             1.3315e-04, 5.2258e-05, 8.3260e-05, 4.9945e-05, 1.7031e-04, 5.6256e-05,\n",
       "             6.6114e-05, 7.5945e-05, 2.8194e-04, 4.6967e-05, 3.8770e-06, 1.2854e-05,\n",
       "             2.9463e-05, 2.0884e-05, 7.2924e-06, 3.2173e-05, 7.5972e-06, 1.3803e-04,\n",
       "             1.8576e-04, 3.9558e-06, 9.1571e-07, 5.5460e-05, 0.0000e+00, 4.1506e-05,\n",
       "             1.3975e-06, 3.6500e-05, 7.4952e-06, 6.6582e-07, 1.7253e-08, 4.6141e-06,\n",
       "             5.3332e-06, 1.1449e-04, 5.3597e-06, 6.4235e-05],\n",
       "            [6.6722e-05, 0.0000e+00, 1.3387e-04, 7.1131e-05, 9.7337e-07, 1.2453e-05,\n",
       "             9.1711e-05, 1.6653e-05, 7.4060e-06, 1.5622e-05, 1.0625e-05, 6.0159e-06,\n",
       "             5.7119e-05, 9.0648e-05, 1.1068e-04, 1.8146e-04, 7.2226e-07, 1.7081e-04,\n",
       "             6.4408e-05, 9.6095e-07, 1.0813e-05, 8.3958e-05, 6.5160e-05, 1.6684e-05,\n",
       "             2.1017e-04, 1.2507e-04, 1.5685e-05, 1.3952e-04, 6.5477e-06, 5.9716e-05,\n",
       "             3.3990e-06, 7.7238e-08, 8.0088e-05, 1.5967e-04, 1.1736e-04, 1.3784e-05,\n",
       "             2.4043e-04, 7.2247e-05, 1.1309e-04, 5.9302e-05, 1.1321e-04, 6.7086e-05,\n",
       "             3.1161e-04, 5.6012e-06, 1.7609e-04, 1.7313e-04, 1.0401e-05, 1.2129e-04,\n",
       "             1.8508e-04, 4.2316e-05, 2.4041e-04, 6.9049e-05, 1.7614e-04, 3.1937e-06,\n",
       "             5.9308e-05, 1.9877e-04, 8.0618e-06, 6.9463e-06, 2.7703e-05, 1.9432e-07,\n",
       "             1.7198e-04, 4.9560e-06, 2.5006e-06, 2.7078e-05, 9.8456e-05, 6.5633e-06,\n",
       "             2.2639e-04, 5.6147e-05, 1.1864e-04, 1.7805e-04, 1.0598e-04, 6.3804e-05,\n",
       "             5.8399e-05, 1.1424e-04, 2.9579e-04, 5.0576e-05, 1.2032e-07, 5.3376e-06,\n",
       "             8.3701e-06, 2.0288e-05, 1.2876e-04, 2.9857e-05, 3.1037e-05, 7.2702e-05,\n",
       "             2.6582e-04, 6.6650e-05, 1.5067e-05, 6.7038e-06, 0.0000e+00, 1.1897e-05,\n",
       "             8.5883e-08, 2.6474e-06, 8.8264e-05, 8.8810e-06, 9.3212e-09, 4.7053e-06,\n",
       "             6.3238e-05, 1.2195e-04, 7.5259e-05, 6.7891e-05],\n",
       "            [4.5509e-06, 0.0000e+00, 1.5556e-04, 2.7954e-05, 1.0383e-05, 5.1690e-07,\n",
       "             6.9467e-05, 5.9025e-07, 5.7430e-07, 2.9873e-06, 9.0229e-06, 5.5513e-06,\n",
       "             3.3280e-05, 1.1667e-04, 4.2215e-05, 9.2492e-05, 3.1782e-06, 1.9297e-04,\n",
       "             1.0182e-04, 5.5986e-06, 9.9865e-06, 9.4177e-05, 5.0393e-06, 5.6285e-07,\n",
       "             1.3614e-04, 1.4957e-04, 1.2885e-05, 3.9855e-05, 6.1949e-05, 2.5701e-05,\n",
       "             1.9740e-06, 4.4134e-06, 1.0760e-04, 1.8225e-04, 1.5694e-04, 7.3093e-07,\n",
       "             2.4798e-04, 7.6159e-05, 4.0709e-05, 2.4062e-06, 9.0308e-05, 1.0141e-04,\n",
       "             3.0613e-04, 1.2629e-06, 2.0115e-04, 1.7053e-04, 8.1140e-05, 3.6939e-05,\n",
       "             2.2321e-04, 5.6785e-05, 1.5545e-04, 7.6325e-05, 8.9253e-05, 2.3009e-05,\n",
       "             6.6458e-05, 2.5965e-04, 4.7672e-05, 3.5964e-05, 4.6474e-05, 3.8536e-06,\n",
       "             2.0909e-04, 4.4806e-06, 1.6336e-07, 5.0364e-05, 1.0358e-04, 4.8466e-07,\n",
       "             1.4324e-04, 3.7833e-06, 1.6976e-04, 1.6752e-04, 1.3052e-04, 1.0001e-05,\n",
       "             8.3333e-05, 6.1249e-05, 1.5919e-04, 4.4816e-06, 4.4414e-06, 2.2213e-05,\n",
       "             2.3331e-05, 2.0145e-05, 1.3291e-04, 2.8081e-06, 4.2382e-05, 1.1949e-04,\n",
       "             1.2478e-04, 7.1384e-05, 1.1799e-05, 5.3296e-05, 0.0000e+00, 5.4644e-05,\n",
       "             1.6489e-06, 3.7039e-05, 9.2785e-05, 7.1852e-06, 1.2497e-09, 9.6387e-06,\n",
       "             6.0108e-05, 1.8237e-04, 8.1837e-05, 7.3964e-06]], device='cpu')},\n",
       "   3: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 0.0031, -0.0027, -0.0004], device='cpu'),\n",
       "    'exp_avg_sq': tensor([0.0002, 0.0003, 0.0003], device='cpu')}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'scheduler': {'factor': 0.1,\n",
       "  'min_lrs': [0],\n",
       "  'patience': 3,\n",
       "  'verbose': False,\n",
       "  'cooldown': 0,\n",
       "  'cooldown_counter': 0,\n",
       "  'mode': 'min',\n",
       "  'threshold': 0.0001,\n",
       "  'threshold_mode': 'rel',\n",
       "  'best': 0.0661608474329114,\n",
       "  'num_bad_epochs': 2,\n",
       "  'mode_worse': inf,\n",
       "  'eps': 1e-08,\n",
       "  'last_epoch': 63,\n",
       "  '_last_lr': [0.0001]},\n",
       " 'num_epochs': 100,\n",
       " 'patience': 6}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_state_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('fc1.weight',\n",
       "               tensor([[-0.6558, -1.8043],\n",
       "                       [-0.1315, -0.0952],\n",
       "                       [ 1.5437,  0.7683],\n",
       "                       [-0.8229, -0.4162],\n",
       "                       [-0.5392,  1.1862],\n",
       "                       [-0.5657, -1.0804],\n",
       "                       [-0.5703, -0.0938],\n",
       "                       [-0.7610, -1.0976],\n",
       "                       [-0.5786, -0.9177],\n",
       "                       [ 1.1570, -1.0527],\n",
       "                       [ 1.2828, -0.1041],\n",
       "                       [ 1.1541, -0.0843],\n",
       "                       [-1.1065, -0.1280],\n",
       "                       [ 0.7237,  0.9580],\n",
       "                       [-0.0183, -1.4489],\n",
       "                       [ 0.5599, -1.0856],\n",
       "                       [-0.4530,  0.8780],\n",
       "                       [ 1.9620,  0.9563],\n",
       "                       [-0.4510,  1.0656],\n",
       "                       [-0.5151,  1.0475],\n",
       "                       [ 1.1475, -0.0194],\n",
       "                       [ 1.2364,  0.6246],\n",
       "                       [ 0.4129, -2.0859],\n",
       "                       [-0.7276, -1.0393],\n",
       "                       [-1.4188,  0.0551],\n",
       "                       [ 1.0769,  0.6820],\n",
       "                       [ 1.3297,  0.3422],\n",
       "                       [-0.6409, -1.0140],\n",
       "                       [-1.3946,  1.7160],\n",
       "                       [-0.0485, -0.9490],\n",
       "                       [-1.0594, -0.5647],\n",
       "                       [-0.5381,  0.9154],\n",
       "                       [-1.0867,  0.6213],\n",
       "                       [ 0.7011,  0.7873],\n",
       "                       [-1.7020,  0.9369],\n",
       "                       [-0.6395, -0.9091],\n",
       "                       [ 1.7646,  0.0741],\n",
       "                       [ 2.3322,  0.3077],\n",
       "                       [-0.0591, -1.5176],\n",
       "                       [-0.6425, -1.7085],\n",
       "                       [ 0.3064, -0.5208],\n",
       "                       [-0.7448,  1.1209],\n",
       "                       [ 1.2779,  0.1003],\n",
       "                       [-0.4667, -0.9031],\n",
       "                       [ 0.7919,  0.8311],\n",
       "                       [ 0.7548, -0.0209],\n",
       "                       [-1.6305,  1.8820],\n",
       "                       [-0.0950, -2.0011],\n",
       "                       [ 0.5907,  0.7211],\n",
       "                       [-0.2416,  0.9600],\n",
       "                       [ 0.3792, -0.7352],\n",
       "                       [-0.3907,  0.6536],\n",
       "                       [ 0.2371, -0.8573],\n",
       "                       [-1.0202,  1.1594],\n",
       "                       [ 1.2575,  1.5320],\n",
       "                       [ 0.0035,  1.3368],\n",
       "                       [-2.1205,  0.4865],\n",
       "                       [-1.6998,  0.4360],\n",
       "                       [-0.6739,  0.9644],\n",
       "                       [-0.6984,  0.8756],\n",
       "                       [ 0.7940,  0.6673],\n",
       "                       [ 1.0085, -0.0117],\n",
       "                       [-0.5036, -0.7665],\n",
       "                       [ 0.1911,  1.1469],\n",
       "                       [ 2.1125,  0.9818],\n",
       "                       [-0.3553, -0.9691],\n",
       "                       [ 0.3728, -0.6503],\n",
       "                       [-0.7027, -1.9173],\n",
       "                       [ 0.5758,  1.2517],\n",
       "                       [ 1.4376, -0.0039],\n",
       "                       [-1.6638,  0.8688],\n",
       "                       [ 0.8844, -1.8727],\n",
       "                       [-0.1200,  1.1309],\n",
       "                       [ 0.2114, -0.8910],\n",
       "                       [-1.3194,  0.0551],\n",
       "                       [-0.2696, -1.8888],\n",
       "                       [-0.5841,  0.9951],\n",
       "                       [-0.8586,  1.0295],\n",
       "                       [-1.6918,  0.0386],\n",
       "                       [-0.7874,  0.1555],\n",
       "                       [ 2.9468,  0.4086],\n",
       "                       [-0.6432, -1.0882],\n",
       "                       [ 0.9795,  1.1432],\n",
       "                       [-1.7242,  1.1297],\n",
       "                       [ 0.1639, -1.0391],\n",
       "                       [ 1.7703,  0.9045],\n",
       "                       [ 1.4489, -0.1113],\n",
       "                       [-1.8718,  1.0649],\n",
       "                       [-0.1508, -0.0422],\n",
       "                       [-0.9742,  1.2781],\n",
       "                       [-0.4326,  0.7308],\n",
       "                       [-1.1014,  1.3827],\n",
       "                       [ 1.4419,  1.7327],\n",
       "                       [ 1.1469, -0.0912],\n",
       "                       [-0.0388, -0.0851],\n",
       "                       [-0.2366,  1.3285],\n",
       "                       [ 1.7946,  0.2605],\n",
       "                       [ 0.0076,  1.3037],\n",
       "                       [ 1.5601,  1.5066],\n",
       "                       [ 0.1653, -1.8723]], device='cpu')),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.5728, -0.5147,  0.1542,  0.2321, -1.3321, -1.3557,  0.5390, -1.3049,\n",
       "                       -1.1217, -1.0960, -1.1447, -1.0842,  0.2213,  0.2778,  0.2470,  0.3449,\n",
       "                       -1.0487,  0.2104,  0.2835, -1.1490, -1.1362,  0.0927, -1.1198, -1.1760,\n",
       "                        0.5548,  0.3179, -1.6853,  0.2936, -0.6575,  0.1877, -0.8938, -1.1383,\n",
       "                        0.2267,  0.5828,  0.3048, -1.0327,  0.3172, -0.7258,  0.0437, -0.5574,\n",
       "                        0.5438,  0.1896,  0.5495, -1.0939,  0.5604,  0.5207, -0.7976,  0.1217,\n",
       "                        0.5978,  0.2433,  0.7062,  0.2523,  0.4957, -0.4789, -1.0501,  0.5595,\n",
       "                       -1.1479, -0.8383,  0.1861, -1.3450,  0.4573, -1.0288, -0.8844, -0.1592,\n",
       "                       -0.9313, -1.2253,  0.6225, -0.6282,  0.3124,  0.3294,  0.2737, -1.1582,\n",
       "                        0.2613,  0.3666,  0.6721, -0.6667, -1.2523, -1.5768, -0.8565,  0.2294,\n",
       "                       -0.8425, -0.8032, -0.5233,  0.1807,  0.5416, -0.8009, -1.4654, -0.8655,\n",
       "                       -0.6146, -0.4187, -0.9361, -0.5854, -1.1863, -1.1025, -0.3966, -1.0383,\n",
       "                       -0.4991,  0.3329, -0.9638, -0.8745], device='cpu')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 4.0942e-01,  3.1245e-02,  7.3607e-01, -2.8863e-01, -1.2278e+00,\n",
       "                         1.0690e+00, -1.1776e-01,  1.1638e+00,  1.1243e+00,  7.7283e-01,\n",
       "                        -8.7492e-01, -1.5139e+00, -3.9127e-01,  5.6228e-01, -3.8469e-01,\n",
       "                        -1.9809e-01, -1.5030e+00,  9.9642e-01,  8.0354e-02, -9.5710e-01,\n",
       "                        -1.7391e+00,  9.0668e-01,  3.7639e-01,  1.0057e+00, -1.6995e-01,\n",
       "                         5.4325e-01, -3.6062e-01, -2.9459e-01,  3.9485e-01, -4.1085e-01,\n",
       "                         9.2197e-01, -1.3685e+00, -8.1725e-02,  2.5893e-01, -1.6379e-01,\n",
       "                         9.6395e-01,  5.9280e-01, -2.1521e+00, -3.0472e-01,  3.3843e-01,\n",
       "                        -3.6145e-01, -1.0290e-01,  2.1680e-01,  1.0690e+00,  4.7102e-01,\n",
       "                        -9.8290e-02,  3.9756e-01, -3.5474e-01,  3.1079e-01,  1.1376e-01,\n",
       "                        -3.0486e-01,  7.9469e-02, -3.6311e-01,  3.3485e-01, -1.7605e+00,\n",
       "                         2.6938e-01,  5.5447e-01,  6.1773e-01, -9.5776e-02, -1.3332e+00,\n",
       "                         2.5461e-01, -1.1330e+00,  1.4356e+00,  1.0518e-01, -1.8303e+00,\n",
       "                         1.3281e+00, -2.1691e-01,  3.6129e-01,  3.8993e-01,  5.0102e-01,\n",
       "                        -2.0107e-01,  3.9962e-01,  9.8142e-02, -2.8270e-01, -1.6560e-01,\n",
       "                         7.6549e-02, -1.5629e+00, -8.6749e-01,  8.6506e-01, -2.3837e-01,\n",
       "                        -1.8206e+00,  6.4980e-01, -9.9861e-01, -2.2359e-01, -2.9241e-01,\n",
       "                        -2.1320e+00, -3.8448e-01,  4.8176e-01, -3.0133e-03,  2.1258e-01,\n",
       "                        -1.5921e+00,  1.7853e-01, -1.5155e+00, -4.8662e-01,  2.4251e-02,\n",
       "                        -1.4916e+00, -2.0462e+00,  1.2605e-01, -2.0023e+00,  3.0285e-01],\n",
       "                       [ 3.5063e-01,  5.2154e-03, -4.2232e-01,  1.8287e-01, -3.0166e-01,\n",
       "                        -1.2611e+00,  2.4065e-01, -9.7083e-01, -1.3971e+00,  7.1267e-01,\n",
       "                         1.4531e+00,  1.5685e+00,  4.0355e-01, -2.2358e-01, -2.1250e-01,\n",
       "                        -2.2635e-01,  7.1211e-02, -4.1187e-01,  3.0494e-01, -3.4525e-01,\n",
       "                         1.4612e+00, -3.6232e-01,  3.9747e-01, -7.4390e-01,  3.4223e-01,\n",
       "                        -2.8891e-01,  1.2597e+00,  1.8021e-01, -1.6988e+00,  2.7267e-02,\n",
       "                        -1.4676e+00, -9.5106e-01,  2.9992e-01, -3.0694e-01,  6.7779e-01,\n",
       "                        -7.2166e-01, -3.9928e-01,  3.8227e-01, -8.8079e-02,  2.2558e-01,\n",
       "                        -1.6004e-01,  3.3252e-01, -1.9532e-01, -1.0994e+00, -2.3633e-01,\n",
       "                        -2.1169e-01, -1.5373e+00, -1.4323e-01, -2.8801e-01,  3.7119e-01,\n",
       "                         2.1421e-02,  7.9180e-02, -9.4102e-02, -1.8920e+00,  4.2679e-01,\n",
       "                         6.6292e-02, -1.7871e+00, -1.4044e+00,  6.6167e-01, -5.9904e-01,\n",
       "                        -2.6365e-01,  1.6587e+00, -1.5846e+00, -5.2773e-01,  3.1286e-01,\n",
       "                        -1.3831e+00,  1.5088e-02,  4.1186e-01, -1.8427e-01, -3.6258e-01,\n",
       "                         6.3838e-01,  4.0893e-01,  1.9456e-01, -6.4560e-03,  2.6159e-01,\n",
       "                         3.8707e-01, -6.2473e-01, -1.8151e-01, -1.4310e+00,  2.3777e-01,\n",
       "                         4.4336e-01, -2.5184e-01,  2.4494e-02,  7.8190e-01,  1.0955e-03,\n",
       "                         4.0900e-01,  1.2747e+00, -1.7149e+00,  6.3893e-02, -1.0168e+00,\n",
       "                        -5.1799e-01, -2.2098e+00,  2.9420e-01,  1.2958e+00, -1.4337e-01,\n",
       "                         5.2563e-01,  5.6847e-01,  1.4193e-01,  3.0270e-01,  4.2606e-01],\n",
       "                       [-2.2352e+00, -1.8817e-02, -2.6502e-01,  1.0460e-01,  1.0573e+00,\n",
       "                        -4.0595e-01, -1.3773e-01, -6.3019e-01, -1.2810e-01, -1.8083e+00,\n",
       "                        -1.4593e+00, -1.4827e+00, -1.3492e-02, -2.7389e-01,  7.6866e-01,\n",
       "                         4.5001e-01,  1.2127e+00, -2.5829e-01, -3.6171e-01,  1.1667e+00,\n",
       "                        -1.0901e+00, -2.5251e-02, -1.7181e+00, -1.2823e+00, -2.1343e-01,\n",
       "                        -3.1619e-02, -1.3409e+00,  4.6218e-01,  3.6506e-01,  5.8927e-01,\n",
       "                         7.8611e-01,  1.4570e+00, -2.8110e-01, -4.7422e-02, -2.9272e-01,\n",
       "                        -9.9141e-01, -5.1644e-02,  5.1736e-01,  7.0722e-01, -2.5505e+00,\n",
       "                         1.6743e-01, -2.3160e-01,  1.1786e-01, -2.5094e-01, -6.9468e-03,\n",
       "                         8.2863e-02,  3.6009e-01,  8.6404e-01,  4.0322e-02, -3.2162e-01,\n",
       "                         3.5352e-01, -2.1468e-01,  3.1397e-01,  3.5374e-01,  4.3479e-01,\n",
       "                        -1.3899e-01,  3.2138e-01,  2.1622e-01, -4.3205e-01,  1.3703e+00,\n",
       "                        -2.6831e-02, -1.5741e+00, -4.1397e-01,  2.9652e-01,  3.4926e-01,\n",
       "                        -2.6967e-01,  2.5749e-01, -2.1242e+00, -2.9072e-01,  3.3170e-02,\n",
       "                        -3.3126e-01, -1.5147e+00, -3.5873e-01,  4.8231e-01, -2.4112e-01,\n",
       "                        -1.5982e+00,  1.4443e+00,  8.2424e-01,  4.0667e-01, -2.7575e-01,\n",
       "                         4.4572e-01, -1.2123e+00,  5.2165e-01, -3.5948e-01,  3.7463e-01,\n",
       "                         5.0908e-01, -1.3709e+00,  2.6056e-01, -9.7352e-02,  2.1693e-01,\n",
       "                         1.4871e+00,  5.4809e-01,  5.3693e-01, -1.4192e+00, -6.5896e-02,\n",
       "                         7.0509e-01,  2.6693e-01, -2.6736e-01,  4.7039e-01, -1.6592e+00]],\n",
       "                      device='cpu')),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.0210, -0.0192,  0.0207], device='cpu'))]),\n",
       " 'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc341217b90>,\n",
       " 'val_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc418494b10>,\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'optimizer': {'state': {0: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.3685e-03, -9.7889e-04],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-1.5353e-04,  1.4701e-04],\n",
       "            [ 3.4770e-04,  5.6011e-04],\n",
       "            [ 4.0141e-04,  1.4776e-04],\n",
       "            [-2.5883e-04, -2.0992e-03],\n",
       "            [ 1.5449e-04,  2.8779e-04],\n",
       "            [-1.5961e-04, -2.1166e-03],\n",
       "            [-1.3842e-04, -2.2399e-03],\n",
       "            [ 1.5072e-04, -1.7804e-05],\n",
       "            [-6.3255e-03, -5.2268e-03],\n",
       "            [-6.8567e-03, -5.7894e-03],\n",
       "            [ 6.2771e-04,  2.4082e-04],\n",
       "            [-6.7329e-04, -1.5038e-04],\n",
       "            [-2.5339e-05,  1.1856e-03],\n",
       "            [-1.3936e-05,  5.5602e-04],\n",
       "            [ 1.4005e-03, -3.7320e-04],\n",
       "            [-1.1718e-04, -1.4054e-04],\n",
       "            [-1.7097e-03, -1.7043e-03],\n",
       "            [ 9.6552e-04, -1.8317e-04],\n",
       "            [-5.6341e-03, -4.8512e-03],\n",
       "            [-4.7633e-04, -6.8443e-05],\n",
       "            [ 3.9150e-04, -5.0092e-04],\n",
       "            [-5.4490e-05, -1.8349e-03],\n",
       "            [ 2.7189e-04,  7.2915e-05],\n",
       "            [ 1.9915e-04,  5.5347e-04],\n",
       "            [-5.7647e-04, -3.4285e-04],\n",
       "            [ 4.0012e-04,  9.2164e-04],\n",
       "            [-2.8781e-04, -2.5235e-04],\n",
       "            [ 1.9759e-04,  6.4435e-04],\n",
       "            [-4.3568e-04, -1.7314e-03],\n",
       "            [ 1.5158e-03, -3.9147e-04],\n",
       "            [ 1.1506e-04, -3.3335e-04],\n",
       "            [ 3.8423e-04,  6.4273e-04],\n",
       "            [ 3.6895e-04, -6.1120e-04],\n",
       "            [-8.1468e-05, -1.6746e-03],\n",
       "            [ 5.1763e-04,  1.1785e-04],\n",
       "            [-1.9991e-04,  1.0824e-03],\n",
       "            [ 1.2246e-04,  1.0715e-03],\n",
       "            [ 1.5480e-03, -1.0355e-03],\n",
       "            [ 8.7689e-04,  1.1037e-03],\n",
       "            [-1.0752e-03, -1.4165e-03],\n",
       "            [ 5.6452e-04,  3.2944e-04],\n",
       "            [-2.0407e-04, -2.4012e-03],\n",
       "            [ 1.8807e-04,  5.6039e-04],\n",
       "            [ 5.5348e-04,  6.4214e-04],\n",
       "            [-4.2972e-04, -3.0965e-04],\n",
       "            [ 1.5004e-04,  8.1886e-04],\n",
       "            [ 4.3808e-04,  8.1595e-04],\n",
       "            [-1.7890e-03, -1.7042e-03],\n",
       "            [ 1.0602e-03,  1.3846e-03],\n",
       "            [-8.7528e-04, -6.9610e-04],\n",
       "            [-4.5349e-05,  6.3485e-04],\n",
       "            [-5.5836e-04, -4.5324e-04],\n",
       "            [ 4.4856e-05,  1.9974e-04],\n",
       "            [-7.6765e-04, -4.7949e-04],\n",
       "            [-4.9034e-04, -2.5633e-04],\n",
       "            [-6.2581e-04, -1.3375e-04],\n",
       "            [-2.2984e-03, -2.6768e-03],\n",
       "            [ 1.5975e-03, -5.0898e-04],\n",
       "            [ 3.3004e-04,  5.1178e-04],\n",
       "            [-7.5813e-03, -6.5530e-03],\n",
       "            [-3.7074e-04, -2.8526e-03],\n",
       "            [ 1.8103e-03,  1.7346e-03],\n",
       "            [ 4.2191e-05,  2.5326e-04],\n",
       "            [ 3.1980e-05, -2.1523e-03],\n",
       "            [ 7.0600e-04,  8.8419e-04],\n",
       "            [ 1.2390e-03, -8.7540e-04],\n",
       "            [-7.0661e-04, -1.6852e-04],\n",
       "            [ 8.3661e-04, -1.3591e-04],\n",
       "            [ 1.4837e-04, -4.6583e-04],\n",
       "            [ 5.2257e-04, -4.6976e-04],\n",
       "            [-8.3341e-05, -1.1003e-04],\n",
       "            [ 2.2515e-05,  8.3550e-04],\n",
       "            [ 1.8113e-04,  2.3376e-05],\n",
       "            [ 4.5811e-04, -3.2224e-04],\n",
       "            [ 1.4914e-03, -2.5039e-04],\n",
       "            [ 4.8546e-04, -1.4889e-04],\n",
       "            [-6.2937e-04, -1.2823e-04],\n",
       "            [ 3.0234e-04, -4.3830e-05],\n",
       "            [-3.4690e-04,  7.5189e-04],\n",
       "            [ 2.0117e-04, -1.3202e-03],\n",
       "            [ 1.1593e-03,  1.2195e-03],\n",
       "            [ 4.2052e-04, -6.4088e-04],\n",
       "            [ 3.1860e-05,  6.9035e-04],\n",
       "            [ 2.3286e-04,  4.1042e-04],\n",
       "            [ 8.3210e-06, -1.5833e-05],\n",
       "            [-6.4171e-04, -9.9525e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-2.1352e-04, -9.8869e-05],\n",
       "            [ 7.0911e-04, -2.0344e-04],\n",
       "            [-2.4645e-04, -3.9571e-04],\n",
       "            [ 5.6229e-04,  6.2525e-04],\n",
       "            [-6.9708e-05, -1.7574e-04],\n",
       "            [-5.6052e-45, -5.6052e-45],\n",
       "            [ 8.7715e-04,  1.8032e-04],\n",
       "            [-8.7034e-04,  2.4251e-04],\n",
       "            [-1.0598e-03, -8.6951e-04],\n",
       "            [ 3.9212e-04,  6.0674e-04],\n",
       "            [ 2.7102e-04, -3.0535e-04]], device='cpu'),\n",
       "    'exp_avg_sq': tensor([[2.9894e-05, 2.0862e-05],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [6.0251e-06, 7.8995e-06],\n",
       "            [5.5849e-06, 8.5187e-06],\n",
       "            [4.7381e-05, 2.4069e-05],\n",
       "            [2.1180e-05, 7.8678e-05],\n",
       "            [1.8898e-06, 4.0898e-06],\n",
       "            [2.6482e-05, 7.1318e-05],\n",
       "            [3.5205e-05, 9.7363e-05],\n",
       "            [2.9866e-05, 8.9027e-06],\n",
       "            [1.0974e-04, 6.7453e-05],\n",
       "            [1.1669e-04, 7.4314e-05],\n",
       "            [9.0335e-06, 1.7235e-05],\n",
       "            [6.9564e-06, 7.4705e-06],\n",
       "            [4.1496e-06, 9.2421e-06],\n",
       "            [1.2178e-05, 8.7653e-06],\n",
       "            [7.8970e-05, 2.5813e-05],\n",
       "            [5.2842e-06, 9.1980e-06],\n",
       "            [1.4356e-05, 8.9021e-06],\n",
       "            [3.3591e-05, 1.5344e-05],\n",
       "            [1.0071e-04, 7.5881e-05],\n",
       "            [8.1656e-06, 8.6439e-06],\n",
       "            [4.8495e-06, 4.6709e-06],\n",
       "            [2.1401e-05, 5.3582e-05],\n",
       "            [4.0187e-06, 9.7952e-06],\n",
       "            [5.2072e-06, 4.4688e-06],\n",
       "            [5.9999e-05, 3.8582e-05],\n",
       "            [9.8872e-06, 1.0581e-05],\n",
       "            [1.8265e-05, 7.7799e-06],\n",
       "            [4.3653e-06, 1.2428e-05],\n",
       "            [2.4383e-05, 4.5762e-05],\n",
       "            [9.2719e-05, 3.2864e-05],\n",
       "            [2.8440e-06, 3.0675e-06],\n",
       "            [2.1047e-06, 1.9826e-06],\n",
       "            [7.2711e-06, 5.9379e-06],\n",
       "            [2.4035e-05, 4.4343e-05],\n",
       "            [6.8647e-06, 1.4762e-05],\n",
       "            [5.6567e-06, 2.0663e-05],\n",
       "            [4.1377e-06, 5.7797e-06],\n",
       "            [3.5468e-05, 2.1003e-05],\n",
       "            [3.8189e-06, 5.7153e-06],\n",
       "            [3.6282e-06, 2.8937e-06],\n",
       "            [2.9132e-06, 5.3829e-06],\n",
       "            [1.8301e-05, 5.5533e-05],\n",
       "            [4.2198e-06, 3.8905e-06],\n",
       "            [2.1029e-06, 2.4976e-06],\n",
       "            [1.2512e-05, 9.3198e-06],\n",
       "            [3.7511e-06, 5.0748e-06],\n",
       "            [7.9378e-06, 4.4012e-06],\n",
       "            [1.5468e-05, 8.7927e-06],\n",
       "            [5.8105e-06, 1.0606e-05],\n",
       "            [3.9697e-06, 2.9507e-06],\n",
       "            [4.2912e-06, 1.0321e-05],\n",
       "            [2.9222e-05, 2.1532e-05],\n",
       "            [4.7618e-06, 1.2476e-05],\n",
       "            [5.3888e-06, 2.4542e-06],\n",
       "            [1.3708e-05, 5.2420e-06],\n",
       "            [1.2482e-05, 4.0013e-06],\n",
       "            [2.0079e-05, 1.4950e-05],\n",
       "            [4.7264e-05, 1.6006e-05],\n",
       "            [2.9141e-06, 2.3943e-06],\n",
       "            [1.3464e-04, 8.7124e-05],\n",
       "            [3.6629e-05, 1.1103e-04],\n",
       "            [1.1945e-05, 7.8221e-06],\n",
       "            [4.9133e-06, 9.5781e-06],\n",
       "            [2.6801e-05, 9.5245e-05],\n",
       "            [2.9837e-06, 6.4312e-06],\n",
       "            [1.5170e-05, 1.3957e-05],\n",
       "            [5.4162e-06, 4.7453e-06],\n",
       "            [7.9063e-06, 1.3170e-05],\n",
       "            [7.2473e-06, 6.0861e-06],\n",
       "            [1.3115e-05, 6.8743e-06],\n",
       "            [1.0159e-05, 5.3390e-06],\n",
       "            [5.8869e-06, 8.6440e-06],\n",
       "            [4.8304e-06, 1.0895e-05],\n",
       "            [4.3112e-06, 7.9128e-06],\n",
       "            [1.0641e-04, 2.9429e-05],\n",
       "            [2.0771e-05, 6.9678e-06],\n",
       "            [2.2088e-05, 1.3070e-05],\n",
       "            [1.2947e-06, 1.5947e-06],\n",
       "            [4.1441e-06, 2.3040e-05],\n",
       "            [2.2479e-05, 2.5862e-05],\n",
       "            [4.9452e-06, 9.2864e-06],\n",
       "            [7.5554e-06, 5.3895e-06],\n",
       "            [4.1172e-06, 1.1379e-05],\n",
       "            [7.0791e-06, 1.6573e-05],\n",
       "            [8.2115e-05, 4.8286e-05],\n",
       "            [1.2381e-05, 4.1259e-06],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [1.0595e-05, 7.9708e-06],\n",
       "            [9.4128e-05, 3.4065e-05],\n",
       "            [3.9718e-05, 2.9561e-05],\n",
       "            [2.8540e-06, 7.8989e-06],\n",
       "            [9.6461e-05, 5.6295e-05],\n",
       "            [3.3248e-09, 2.4441e-08],\n",
       "            [6.3192e-05, 2.9412e-05],\n",
       "            [2.2291e-05, 5.4483e-05],\n",
       "            [8.4831e-06, 4.4685e-06],\n",
       "            [3.9400e-06, 1.5397e-05],\n",
       "            [4.6681e-06, 1.0764e-05]], device='cpu')},\n",
       "   1: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 1.2413e-03,  0.0000e+00,  2.1401e-03, -2.1070e-03,  1.2780e-04,\n",
       "             1.7331e-03, -5.4336e-05,  1.7280e-03,  1.8056e-03,  2.5196e-04,\n",
       "            -3.0120e-03, -3.2953e-03, -1.0933e-03,  4.0869e-06, -1.7176e-03,\n",
       "            -1.1794e-03, -4.2960e-04,  1.6638e-03, -9.4908e-04, -1.8080e-04,\n",
       "            -2.6602e-03,  1.0205e-03,  1.1631e-03,  1.4377e-03,  9.3997e-04,\n",
       "             2.4855e-03, -1.7002e-04, -1.4113e-03,  6.0061e-04, -1.4508e-03,\n",
       "             1.5234e-03, -4.4235e-04,  1.0702e-04,  4.2038e-04, -1.2972e-03,\n",
       "             1.3272e-03,  2.6415e-03, -5.5739e-04, -9.1029e-04,  1.3823e-03,\n",
       "            -4.0860e-04, -7.8731e-04,  1.2282e-03,  1.9547e-03,  1.1446e-03,\n",
       "             3.4610e-04,  3.3440e-04,  3.5703e-04,  1.1439e-03,  1.0327e-04,\n",
       "            -2.7144e-05, -6.7892e-04, -9.6110e-04,  6.7140e-04,  2.9252e-04,\n",
       "             2.1769e-04,  6.7627e-04,  9.0693e-04,  3.2402e-05, -6.0541e-04,\n",
       "             1.0902e-03, -3.6970e-03,  2.3651e-03,  1.7198e-03,  2.0758e-04,\n",
       "             1.6676e-03, -4.3561e-04,  1.2385e-03,  1.3972e-04, -5.2263e-04,\n",
       "             1.6364e-03,  1.2285e-03, -3.5640e-04, -2.0757e-03, -4.3214e-04,\n",
       "             1.1349e-03, -4.4187e-04, -1.1329e-04,  9.8619e-04, -4.9398e-04,\n",
       "            -2.8966e-04,  9.5354e-04,  9.8751e-04, -1.0231e-03, -7.8575e-04,\n",
       "             4.3610e-04,  2.5700e-04,  1.0849e-03,  0.0000e+00,  6.0341e-04,\n",
       "            -1.0964e-04,  9.0385e-05,  4.9824e-04,  2.7123e-04,  5.6052e-45,\n",
       "             6.7382e-05, -1.6602e-04, -8.3391e-04,  6.1497e-04,  9.9754e-04],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([2.4884e-05, 0.0000e+00, 1.1075e-04, 2.8478e-05, 1.9747e-05, 3.0582e-05,\n",
       "            1.4319e-05, 2.8817e-05, 3.9024e-05, 1.4432e-05, 5.5994e-05, 5.4243e-05,\n",
       "            6.1636e-05, 6.9576e-05, 1.0334e-04, 6.5142e-05, 2.7396e-05, 1.3353e-04,\n",
       "            4.8722e-05, 1.3593e-05, 5.1978e-05, 1.1991e-04, 6.6532e-06, 2.1585e-05,\n",
       "            4.6962e-05, 6.1669e-05, 2.6836e-05, 4.8969e-05, 9.5377e-06, 7.8949e-05,\n",
       "            2.3910e-05, 3.2371e-05, 2.3612e-05, 2.2335e-05, 9.3993e-05, 1.9217e-05,\n",
       "            6.5282e-05, 1.6510e-05, 7.6668e-05, 2.4473e-05, 2.6667e-05, 2.1374e-05,\n",
       "            1.5012e-05, 1.9666e-05, 4.2970e-05, 9.1575e-06, 8.7729e-06, 9.7040e-05,\n",
       "            4.2006e-05, 5.1129e-05, 3.9294e-05, 1.2390e-05, 4.6126e-05, 1.5978e-05,\n",
       "            1.0419e-05, 1.6949e-05, 9.2859e-06, 7.3573e-06, 9.7850e-05, 1.7123e-05,\n",
       "            2.2947e-05, 6.9213e-05, 4.1763e-05, 1.3542e-05, 9.2946e-06, 3.5421e-05,\n",
       "            2.5060e-05, 1.9104e-05, 4.6314e-05, 5.7135e-05, 1.0356e-04, 1.1956e-05,\n",
       "            3.3585e-05, 5.8598e-05, 4.1799e-05, 7.3911e-06, 3.4269e-05, 7.7023e-06,\n",
       "            1.5150e-05, 1.7780e-05, 1.3203e-05, 1.3162e-05, 7.2062e-06, 1.0011e-04,\n",
       "            4.5737e-05, 1.6265e-05, 4.0442e-05, 7.8629e-06, 0.0000e+00, 7.4622e-06,\n",
       "            3.2206e-05, 1.8701e-05, 7.0091e-06, 4.7804e-05, 6.9405e-09, 2.7263e-05,\n",
       "            2.7236e-05, 2.5877e-05, 1.1910e-05, 9.2307e-06], device='cpu')},\n",
       "   2: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.9148e-03,  0.0000e+00, -6.4087e-04,  2.2770e-03,  9.1002e-05,\n",
       "              2.6836e-05,  1.8530e-03,  8.6032e-05,  3.9000e-05,  5.1196e-04,\n",
       "              6.9420e-06,  2.6434e-06,  1.7608e-03, -4.9971e-04,  3.1602e-03,\n",
       "              2.6920e-03,  1.8821e-04, -8.0562e-04,  1.1994e-03,  2.2188e-04,\n",
       "              2.8725e-07, -6.0225e-04,  2.0838e-03,  1.5501e-04,  2.5328e-03,\n",
       "              3.8492e-04,  1.4026e-09,  2.6370e-03, -4.6602e-04,  1.7343e-03,\n",
       "              2.2572e-04,  2.3688e-04,  1.7973e-03, -5.2248e-05,  2.6328e-03,\n",
       "              1.2512e-04, -1.4213e-04,  1.4913e-04,  2.9005e-03,  2.0072e-03,\n",
       "              1.6903e-03,  1.1882e-03,  9.4613e-04,  5.5799e-05,  4.6623e-04,\n",
       "              9.3147e-04,  2.5528e-04,  3.5379e-03,  7.0568e-04,  4.2017e-04,\n",
       "              1.1599e-03,  7.3700e-04,  2.5529e-03, -2.0822e-04, -8.5732e-06,\n",
       "              1.3828e-03,  6.4003e-04,  4.9042e-04,  1.0241e-03,  2.7613e-04,\n",
       "              4.7320e-04,  1.2209e-07,  8.7426e-05, -1.3467e-04,  2.5461e-05,\n",
       "              1.1793e-05,  2.0349e-03,  2.2759e-03, -1.2885e-04, -4.2406e-04,\n",
       "              1.9066e-03,  1.6041e-03,  7.4799e-04,  2.7313e-03,  3.3153e-03,\n",
       "              2.3426e-03,  1.8831e-04,  2.3103e-04,  4.1449e-04,  1.3264e-03,\n",
       "              2.1472e-04,  7.0703e-04, -6.7006e-05,  2.4181e-03,  2.4755e-03,\n",
       "              1.5362e-05,  3.5085e-07,  5.4447e-04,  0.0000e+00, -3.5008e-06,\n",
       "              1.1446e-04, -1.7291e-04, -3.1090e-06,  7.7901e-07, -5.6052e-45,\n",
       "              2.4671e-05,  9.3661e-05,  8.0640e-04, -2.2069e-05,  1.8491e-03],\n",
       "            [-1.8976e-03,  0.0000e+00, -5.3835e-03, -1.4445e-03,  2.4932e-06,\n",
       "             -3.0759e-05, -4.8041e-04, -1.0689e-04, -4.9258e-05, -5.5717e-04,\n",
       "             -1.4166e-03, -1.2623e-03, -7.2509e-04, -4.2311e-03, -1.5318e-03,\n",
       "             -1.0736e-03,  2.3063e-07, -6.4847e-03, -2.7663e-03,  6.5786e-06,\n",
       "             -1.3122e-03, -7.1421e-05, -2.1086e-03, -1.8271e-04,  5.2461e-05,\n",
       "             -4.5110e-03, -2.2947e-04, -1.3828e-03,  1.9977e-04, -1.4966e-03,\n",
       "             -2.1154e-05,  3.1748e-07, -1.1469e-03, -3.9914e-03, -1.9943e-03,\n",
       "             -1.4882e-04, -5.3266e-03, -4.9536e-03, -1.5862e-03, -2.0874e-03,\n",
       "             -1.1162e-03, -1.9307e-03, -4.2645e-03, -6.2926e-05, -4.5023e-03,\n",
       "             -2.5568e-03,  8.3519e-05, -2.6825e-03, -4.0807e-03, -1.9652e-03,\n",
       "             -3.8733e-04, -1.7048e-03, -1.7078e-03,  1.2500e-04, -4.4936e-03,\n",
       "             -5.2958e-03,  4.7173e-06, -2.9854e-05, -1.2530e-03,  4.6178e-08,\n",
       "             -4.0904e-03, -1.1643e-03, -1.0416e-04, -2.4701e-03, -5.4759e-03,\n",
       "             -1.1933e-05, -1.5765e-03, -2.2191e-03, -4.5739e-03, -3.1064e-03,\n",
       "             -4.6623e-04, -1.6386e-03, -9.9281e-04, -1.2042e-03, -1.5496e-03,\n",
       "             -2.1133e-03,  8.5606e-08,  4.4553e-07, -1.3893e-05, -7.9446e-04,\n",
       "             -6.3985e-03, -8.0693e-04, -3.8430e-03, -1.7195e-03, -1.3740e-03,\n",
       "             -4.7389e-03, -1.3716e-04, -1.8261e-05,  0.0000e+00,  1.3846e-04,\n",
       "              1.0599e-07,  1.4233e-04, -5.3392e-03, -1.3383e-04,  5.6052e-45,\n",
       "             -9.2179e-05, -3.9779e-03, -4.2430e-03, -5.2357e-03, -1.8627e-03],\n",
       "            [-1.7251e-05,  0.0000e+00,  6.0243e-03, -8.3248e-04, -9.3496e-05,\n",
       "              3.9232e-06, -1.3726e-03,  2.0857e-05,  1.0257e-05,  4.5207e-05,\n",
       "              1.4096e-03,  1.2597e-03, -1.0357e-03,  4.7308e-03, -1.6283e-03,\n",
       "             -1.6184e-03, -1.8844e-04,  7.2903e-03,  1.5670e-03, -2.2846e-04,\n",
       "              1.3119e-03,  6.7367e-04,  2.4728e-05,  2.7707e-05, -2.5853e-03,\n",
       "              4.1261e-03,  2.2947e-04, -1.2542e-03,  2.6626e-04, -2.3775e-04,\n",
       "             -2.0456e-04, -2.3719e-04, -6.5039e-04,  4.0437e-03, -6.3851e-04,\n",
       "              2.3703e-05,  5.4687e-03,  4.8044e-03, -1.3143e-03,  8.0191e-05,\n",
       "             -5.7415e-04,  7.4251e-04,  3.3183e-03,  7.1275e-06,  4.0361e-03,\n",
       "              1.6253e-03, -3.3880e-04, -8.5535e-04,  3.3751e-03,  1.5451e-03,\n",
       "             -7.7254e-04,  9.6780e-04, -8.4515e-04,  8.3221e-05,  4.5022e-03,\n",
       "              3.9130e-03, -6.4475e-04, -4.6057e-04,  2.2889e-04, -2.7618e-04,\n",
       "              3.6172e-03,  1.1641e-03,  1.6737e-05,  2.6048e-03,  5.4504e-03,\n",
       "              1.3980e-07, -4.5844e-04, -5.6775e-05,  4.7028e-03,  3.5305e-03,\n",
       "             -1.4403e-03,  3.4473e-05,  2.4482e-04, -1.5271e-03, -1.7657e-03,\n",
       "             -2.2934e-04, -1.8839e-04, -2.3148e-04, -4.0060e-04, -5.3195e-04,\n",
       "              6.1838e-03,  9.9894e-05,  3.9100e-03, -6.9856e-04, -1.1015e-03,\n",
       "              4.7235e-03,  1.3681e-04, -5.2621e-04,  0.0000e+00, -1.3496e-04,\n",
       "             -1.1457e-04,  3.0584e-05,  5.3424e-03,  1.3305e-04,  5.6052e-45,\n",
       "              6.7508e-05,  3.8843e-03,  3.4366e-03,  5.2577e-03,  1.3622e-05]],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([[6.4908e-05, 0.0000e+00, 4.5172e-05, 7.2541e-05, 7.4253e-06, 1.4921e-05,\n",
       "             7.6572e-05, 1.8703e-05, 9.1779e-06, 1.2833e-05, 2.9514e-07, 8.1014e-08,\n",
       "             6.4832e-05, 4.8813e-05, 7.9747e-05, 1.1294e-04, 2.2889e-06, 4.2622e-05,\n",
       "             8.7528e-05, 4.5545e-06, 2.0528e-07, 2.2162e-05, 6.1479e-05, 1.7558e-05,\n",
       "             2.1804e-04, 6.2589e-05, 9.0310e-07, 1.2256e-04, 5.9290e-05, 4.3034e-05,\n",
       "             5.1999e-06, 3.9317e-06, 1.0906e-04, 9.4605e-05, 1.9262e-04, 1.5016e-05,\n",
       "             6.5589e-05, 3.2433e-06, 8.1426e-05, 5.8041e-05, 6.4111e-05, 7.9104e-05,\n",
       "             1.1771e-04, 6.5464e-06, 9.3228e-05, 8.4045e-05, 8.0960e-05, 9.8021e-05,\n",
       "             1.2328e-04, 4.1216e-05, 1.4068e-04, 6.0294e-05, 1.2128e-04, 2.2258e-05,\n",
       "             6.6251e-06, 1.8613e-04, 5.1501e-05, 3.8984e-05, 4.7221e-05, 3.2981e-06,\n",
       "             8.6060e-05, 6.4993e-08, 3.0537e-06, 2.1851e-05, 7.4476e-06, 7.2780e-06,\n",
       "             1.3315e-04, 5.2258e-05, 8.3260e-05, 4.9945e-05, 1.7031e-04, 5.6256e-05,\n",
       "             6.6114e-05, 7.5945e-05, 2.8194e-04, 4.6967e-05, 3.8770e-06, 1.2854e-05,\n",
       "             2.9463e-05, 2.0884e-05, 7.2924e-06, 3.2173e-05, 7.5972e-06, 1.3803e-04,\n",
       "             1.8576e-04, 3.9558e-06, 9.1571e-07, 5.5460e-05, 0.0000e+00, 4.1506e-05,\n",
       "             1.3975e-06, 3.6500e-05, 7.4952e-06, 6.6582e-07, 1.7253e-08, 4.6141e-06,\n",
       "             5.3332e-06, 1.1449e-04, 5.3597e-06, 6.4235e-05],\n",
       "            [6.6722e-05, 0.0000e+00, 1.3387e-04, 7.1131e-05, 9.7337e-07, 1.2453e-05,\n",
       "             9.1711e-05, 1.6653e-05, 7.4060e-06, 1.5622e-05, 1.0625e-05, 6.0159e-06,\n",
       "             5.7119e-05, 9.0648e-05, 1.1068e-04, 1.8146e-04, 7.2226e-07, 1.7081e-04,\n",
       "             6.4408e-05, 9.6095e-07, 1.0813e-05, 8.3958e-05, 6.5160e-05, 1.6684e-05,\n",
       "             2.1017e-04, 1.2507e-04, 1.5685e-05, 1.3952e-04, 6.5477e-06, 5.9716e-05,\n",
       "             3.3990e-06, 7.7238e-08, 8.0088e-05, 1.5967e-04, 1.1736e-04, 1.3784e-05,\n",
       "             2.4043e-04, 7.2247e-05, 1.1309e-04, 5.9302e-05, 1.1321e-04, 6.7086e-05,\n",
       "             3.1161e-04, 5.6012e-06, 1.7609e-04, 1.7313e-04, 1.0401e-05, 1.2129e-04,\n",
       "             1.8508e-04, 4.2316e-05, 2.4041e-04, 6.9049e-05, 1.7614e-04, 3.1937e-06,\n",
       "             5.9308e-05, 1.9877e-04, 8.0618e-06, 6.9463e-06, 2.7703e-05, 1.9432e-07,\n",
       "             1.7198e-04, 4.9560e-06, 2.5006e-06, 2.7078e-05, 9.8456e-05, 6.5633e-06,\n",
       "             2.2639e-04, 5.6147e-05, 1.1864e-04, 1.7805e-04, 1.0598e-04, 6.3804e-05,\n",
       "             5.8399e-05, 1.1424e-04, 2.9579e-04, 5.0576e-05, 1.2032e-07, 5.3376e-06,\n",
       "             8.3701e-06, 2.0288e-05, 1.2876e-04, 2.9857e-05, 3.1037e-05, 7.2702e-05,\n",
       "             2.6582e-04, 6.6650e-05, 1.5067e-05, 6.7038e-06, 0.0000e+00, 1.1897e-05,\n",
       "             8.5883e-08, 2.6474e-06, 8.8264e-05, 8.8810e-06, 9.3212e-09, 4.7053e-06,\n",
       "             6.3238e-05, 1.2195e-04, 7.5259e-05, 6.7891e-05],\n",
       "            [4.5509e-06, 0.0000e+00, 1.5556e-04, 2.7954e-05, 1.0383e-05, 5.1690e-07,\n",
       "             6.9467e-05, 5.9025e-07, 5.7430e-07, 2.9873e-06, 9.0229e-06, 5.5513e-06,\n",
       "             3.3280e-05, 1.1667e-04, 4.2215e-05, 9.2492e-05, 3.1782e-06, 1.9297e-04,\n",
       "             1.0182e-04, 5.5986e-06, 9.9865e-06, 9.4177e-05, 5.0393e-06, 5.6285e-07,\n",
       "             1.3614e-04, 1.4957e-04, 1.2885e-05, 3.9855e-05, 6.1949e-05, 2.5701e-05,\n",
       "             1.9740e-06, 4.4134e-06, 1.0760e-04, 1.8225e-04, 1.5694e-04, 7.3093e-07,\n",
       "             2.4798e-04, 7.6159e-05, 4.0709e-05, 2.4062e-06, 9.0308e-05, 1.0141e-04,\n",
       "             3.0613e-04, 1.2629e-06, 2.0115e-04, 1.7053e-04, 8.1140e-05, 3.6939e-05,\n",
       "             2.2321e-04, 5.6785e-05, 1.5545e-04, 7.6325e-05, 8.9253e-05, 2.3009e-05,\n",
       "             6.6458e-05, 2.5965e-04, 4.7672e-05, 3.5964e-05, 4.6474e-05, 3.8536e-06,\n",
       "             2.0909e-04, 4.4806e-06, 1.6336e-07, 5.0364e-05, 1.0358e-04, 4.8466e-07,\n",
       "             1.4324e-04, 3.7833e-06, 1.6976e-04, 1.6752e-04, 1.3052e-04, 1.0001e-05,\n",
       "             8.3333e-05, 6.1249e-05, 1.5919e-04, 4.4816e-06, 4.4414e-06, 2.2213e-05,\n",
       "             2.3331e-05, 2.0145e-05, 1.3291e-04, 2.8081e-06, 4.2382e-05, 1.1949e-04,\n",
       "             1.2478e-04, 7.1384e-05, 1.1799e-05, 5.3296e-05, 0.0000e+00, 5.4644e-05,\n",
       "             1.6489e-06, 3.7039e-05, 9.2785e-05, 7.1852e-06, 1.2497e-09, 9.6387e-06,\n",
       "             6.0108e-05, 1.8237e-04, 8.1837e-05, 7.3964e-06]], device='cpu')},\n",
       "   3: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 0.0031, -0.0027, -0.0004], device='cpu'),\n",
       "    'exp_avg_sq': tensor([0.0002, 0.0003, 0.0003], device='cpu')}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'scheduler': {'factor': 0.1,\n",
       "  'min_lrs': [0],\n",
       "  'patience': 3,\n",
       "  'verbose': False,\n",
       "  'cooldown': 0,\n",
       "  'cooldown_counter': 0,\n",
       "  'mode': 'min',\n",
       "  'threshold': 0.0001,\n",
       "  'threshold_mode': 'rel',\n",
       "  'best': 0.0661608474329114,\n",
       "  'num_bad_epochs': 2,\n",
       "  'mode_worse': inf,\n",
       "  'eps': 1e-08,\n",
       "  'last_epoch': 63,\n",
       "  '_last_lr': [0.0001]},\n",
       " 'num_epochs': 100,\n",
       " 'patience': 6}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('fc1.weight',\n",
       "               tensor([[-0.6558, -1.8043],\n",
       "                       [-0.1315, -0.0952],\n",
       "                       [ 1.5437,  0.7683],\n",
       "                       [-0.8229, -0.4162],\n",
       "                       [-0.5392,  1.1862],\n",
       "                       [-0.5657, -1.0804],\n",
       "                       [-0.5703, -0.0938],\n",
       "                       [-0.7610, -1.0976],\n",
       "                       [-0.5786, -0.9177],\n",
       "                       [ 1.1570, -1.0527],\n",
       "                       [ 1.2828, -0.1041],\n",
       "                       [ 1.1541, -0.0843],\n",
       "                       [-1.1065, -0.1280],\n",
       "                       [ 0.7237,  0.9580],\n",
       "                       [-0.0183, -1.4489],\n",
       "                       [ 0.5599, -1.0856],\n",
       "                       [-0.4530,  0.8780],\n",
       "                       [ 1.9620,  0.9563],\n",
       "                       [-0.4510,  1.0656],\n",
       "                       [-0.5151,  1.0475],\n",
       "                       [ 1.1475, -0.0194],\n",
       "                       [ 1.2364,  0.6246],\n",
       "                       [ 0.4129, -2.0859],\n",
       "                       [-0.7276, -1.0393],\n",
       "                       [-1.4188,  0.0551],\n",
       "                       [ 1.0769,  0.6820],\n",
       "                       [ 1.3297,  0.3422],\n",
       "                       [-0.6409, -1.0140],\n",
       "                       [-1.3946,  1.7160],\n",
       "                       [-0.0485, -0.9490],\n",
       "                       [-1.0594, -0.5647],\n",
       "                       [-0.5381,  0.9154],\n",
       "                       [-1.0867,  0.6213],\n",
       "                       [ 0.7011,  0.7873],\n",
       "                       [-1.7020,  0.9369],\n",
       "                       [-0.6395, -0.9091],\n",
       "                       [ 1.7646,  0.0741],\n",
       "                       [ 2.3322,  0.3077],\n",
       "                       [-0.0591, -1.5176],\n",
       "                       [-0.6425, -1.7085],\n",
       "                       [ 0.3064, -0.5208],\n",
       "                       [-0.7448,  1.1209],\n",
       "                       [ 1.2779,  0.1003],\n",
       "                       [-0.4667, -0.9031],\n",
       "                       [ 0.7919,  0.8311],\n",
       "                       [ 0.7548, -0.0209],\n",
       "                       [-1.6305,  1.8820],\n",
       "                       [-0.0950, -2.0011],\n",
       "                       [ 0.5907,  0.7211],\n",
       "                       [-0.2416,  0.9600],\n",
       "                       [ 0.3792, -0.7352],\n",
       "                       [-0.3907,  0.6536],\n",
       "                       [ 0.2371, -0.8573],\n",
       "                       [-1.0202,  1.1594],\n",
       "                       [ 1.2575,  1.5320],\n",
       "                       [ 0.0035,  1.3368],\n",
       "                       [-2.1205,  0.4865],\n",
       "                       [-1.6998,  0.4360],\n",
       "                       [-0.6739,  0.9644],\n",
       "                       [-0.6984,  0.8756],\n",
       "                       [ 0.7940,  0.6673],\n",
       "                       [ 1.0085, -0.0117],\n",
       "                       [-0.5036, -0.7665],\n",
       "                       [ 0.1911,  1.1469],\n",
       "                       [ 2.1125,  0.9818],\n",
       "                       [-0.3553, -0.9691],\n",
       "                       [ 0.3728, -0.6503],\n",
       "                       [-0.7027, -1.9173],\n",
       "                       [ 0.5758,  1.2517],\n",
       "                       [ 1.4376, -0.0039],\n",
       "                       [-1.6638,  0.8688],\n",
       "                       [ 0.8844, -1.8727],\n",
       "                       [-0.1200,  1.1309],\n",
       "                       [ 0.2114, -0.8910],\n",
       "                       [-1.3194,  0.0551],\n",
       "                       [-0.2696, -1.8888],\n",
       "                       [-0.5841,  0.9951],\n",
       "                       [-0.8586,  1.0295],\n",
       "                       [-1.6918,  0.0386],\n",
       "                       [-0.7874,  0.1555],\n",
       "                       [ 2.9468,  0.4086],\n",
       "                       [-0.6432, -1.0882],\n",
       "                       [ 0.9795,  1.1432],\n",
       "                       [-1.7242,  1.1297],\n",
       "                       [ 0.1639, -1.0391],\n",
       "                       [ 1.7703,  0.9045],\n",
       "                       [ 1.4489, -0.1113],\n",
       "                       [-1.8718,  1.0649],\n",
       "                       [-0.1508, -0.0422],\n",
       "                       [-0.9742,  1.2781],\n",
       "                       [-0.4326,  0.7308],\n",
       "                       [-1.1014,  1.3827],\n",
       "                       [ 1.4419,  1.7327],\n",
       "                       [ 1.1469, -0.0912],\n",
       "                       [-0.0388, -0.0851],\n",
       "                       [-0.2366,  1.3285],\n",
       "                       [ 1.7946,  0.2605],\n",
       "                       [ 0.0076,  1.3037],\n",
       "                       [ 1.5601,  1.5066],\n",
       "                       [ 0.1653, -1.8723]], device='cpu')),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.5728, -0.5147,  0.1542,  0.2321, -1.3321, -1.3557,  0.5390, -1.3049,\n",
       "                       -1.1217, -1.0960, -1.1447, -1.0842,  0.2213,  0.2778,  0.2470,  0.3449,\n",
       "                       -1.0487,  0.2104,  0.2835, -1.1490, -1.1362,  0.0927, -1.1198, -1.1760,\n",
       "                        0.5548,  0.3179, -1.6853,  0.2936, -0.6575,  0.1877, -0.8938, -1.1383,\n",
       "                        0.2267,  0.5828,  0.3048, -1.0327,  0.3172, -0.7258,  0.0437, -0.5574,\n",
       "                        0.5438,  0.1896,  0.5495, -1.0939,  0.5604,  0.5207, -0.7976,  0.1217,\n",
       "                        0.5978,  0.2433,  0.7062,  0.2523,  0.4957, -0.4789, -1.0501,  0.5595,\n",
       "                       -1.1479, -0.8383,  0.1861, -1.3450,  0.4573, -1.0288, -0.8844, -0.1592,\n",
       "                       -0.9313, -1.2253,  0.6225, -0.6282,  0.3124,  0.3294,  0.2737, -1.1582,\n",
       "                        0.2613,  0.3666,  0.6721, -0.6667, -1.2523, -1.5768, -0.8565,  0.2294,\n",
       "                       -0.8425, -0.8032, -0.5233,  0.1807,  0.5416, -0.8009, -1.4654, -0.8655,\n",
       "                       -0.6146, -0.4187, -0.9361, -0.5854, -1.1863, -1.1025, -0.3966, -1.0383,\n",
       "                       -0.4991,  0.3329, -0.9638, -0.8745], device='cpu')),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 4.0942e-01,  3.1245e-02,  7.3607e-01, -2.8863e-01, -1.2278e+00,\n",
       "                         1.0690e+00, -1.1776e-01,  1.1638e+00,  1.1243e+00,  7.7283e-01,\n",
       "                        -8.7492e-01, -1.5139e+00, -3.9127e-01,  5.6228e-01, -3.8469e-01,\n",
       "                        -1.9809e-01, -1.5030e+00,  9.9642e-01,  8.0354e-02, -9.5710e-01,\n",
       "                        -1.7391e+00,  9.0668e-01,  3.7639e-01,  1.0057e+00, -1.6995e-01,\n",
       "                         5.4325e-01, -3.6062e-01, -2.9459e-01,  3.9485e-01, -4.1085e-01,\n",
       "                         9.2197e-01, -1.3685e+00, -8.1725e-02,  2.5893e-01, -1.6379e-01,\n",
       "                         9.6395e-01,  5.9280e-01, -2.1521e+00, -3.0472e-01,  3.3843e-01,\n",
       "                        -3.6145e-01, -1.0290e-01,  2.1680e-01,  1.0690e+00,  4.7102e-01,\n",
       "                        -9.8290e-02,  3.9756e-01, -3.5474e-01,  3.1079e-01,  1.1376e-01,\n",
       "                        -3.0486e-01,  7.9469e-02, -3.6311e-01,  3.3485e-01, -1.7605e+00,\n",
       "                         2.6938e-01,  5.5447e-01,  6.1773e-01, -9.5776e-02, -1.3332e+00,\n",
       "                         2.5461e-01, -1.1330e+00,  1.4356e+00,  1.0518e-01, -1.8303e+00,\n",
       "                         1.3281e+00, -2.1691e-01,  3.6129e-01,  3.8993e-01,  5.0102e-01,\n",
       "                        -2.0107e-01,  3.9962e-01,  9.8142e-02, -2.8270e-01, -1.6560e-01,\n",
       "                         7.6549e-02, -1.5629e+00, -8.6749e-01,  8.6506e-01, -2.3837e-01,\n",
       "                        -1.8206e+00,  6.4980e-01, -9.9861e-01, -2.2359e-01, -2.9241e-01,\n",
       "                        -2.1320e+00, -3.8448e-01,  4.8176e-01, -3.0133e-03,  2.1258e-01,\n",
       "                        -1.5921e+00,  1.7853e-01, -1.5155e+00, -4.8662e-01,  2.4251e-02,\n",
       "                        -1.4916e+00, -2.0462e+00,  1.2605e-01, -2.0023e+00,  3.0285e-01],\n",
       "                       [ 3.5063e-01,  5.2154e-03, -4.2232e-01,  1.8287e-01, -3.0166e-01,\n",
       "                        -1.2611e+00,  2.4065e-01, -9.7083e-01, -1.3971e+00,  7.1267e-01,\n",
       "                         1.4531e+00,  1.5685e+00,  4.0355e-01, -2.2358e-01, -2.1250e-01,\n",
       "                        -2.2635e-01,  7.1211e-02, -4.1187e-01,  3.0494e-01, -3.4525e-01,\n",
       "                         1.4612e+00, -3.6232e-01,  3.9747e-01, -7.4390e-01,  3.4223e-01,\n",
       "                        -2.8891e-01,  1.2597e+00,  1.8021e-01, -1.6988e+00,  2.7267e-02,\n",
       "                        -1.4676e+00, -9.5106e-01,  2.9992e-01, -3.0694e-01,  6.7779e-01,\n",
       "                        -7.2166e-01, -3.9928e-01,  3.8227e-01, -8.8079e-02,  2.2558e-01,\n",
       "                        -1.6004e-01,  3.3252e-01, -1.9532e-01, -1.0994e+00, -2.3633e-01,\n",
       "                        -2.1169e-01, -1.5373e+00, -1.4323e-01, -2.8801e-01,  3.7119e-01,\n",
       "                         2.1421e-02,  7.9180e-02, -9.4102e-02, -1.8920e+00,  4.2679e-01,\n",
       "                         6.6292e-02, -1.7871e+00, -1.4044e+00,  6.6167e-01, -5.9904e-01,\n",
       "                        -2.6365e-01,  1.6587e+00, -1.5846e+00, -5.2773e-01,  3.1286e-01,\n",
       "                        -1.3831e+00,  1.5088e-02,  4.1186e-01, -1.8427e-01, -3.6258e-01,\n",
       "                         6.3838e-01,  4.0893e-01,  1.9456e-01, -6.4560e-03,  2.6159e-01,\n",
       "                         3.8707e-01, -6.2473e-01, -1.8151e-01, -1.4310e+00,  2.3777e-01,\n",
       "                         4.4336e-01, -2.5184e-01,  2.4494e-02,  7.8190e-01,  1.0955e-03,\n",
       "                         4.0900e-01,  1.2747e+00, -1.7149e+00,  6.3893e-02, -1.0168e+00,\n",
       "                        -5.1799e-01, -2.2098e+00,  2.9420e-01,  1.2958e+00, -1.4337e-01,\n",
       "                         5.2563e-01,  5.6847e-01,  1.4193e-01,  3.0270e-01,  4.2606e-01],\n",
       "                       [-2.2352e+00, -1.8817e-02, -2.6502e-01,  1.0460e-01,  1.0573e+00,\n",
       "                        -4.0595e-01, -1.3773e-01, -6.3019e-01, -1.2810e-01, -1.8083e+00,\n",
       "                        -1.4593e+00, -1.4827e+00, -1.3492e-02, -2.7389e-01,  7.6866e-01,\n",
       "                         4.5001e-01,  1.2127e+00, -2.5829e-01, -3.6171e-01,  1.1667e+00,\n",
       "                        -1.0901e+00, -2.5251e-02, -1.7181e+00, -1.2823e+00, -2.1343e-01,\n",
       "                        -3.1619e-02, -1.3409e+00,  4.6218e-01,  3.6506e-01,  5.8927e-01,\n",
       "                         7.8611e-01,  1.4570e+00, -2.8110e-01, -4.7422e-02, -2.9272e-01,\n",
       "                        -9.9141e-01, -5.1644e-02,  5.1736e-01,  7.0722e-01, -2.5505e+00,\n",
       "                         1.6743e-01, -2.3160e-01,  1.1786e-01, -2.5094e-01, -6.9468e-03,\n",
       "                         8.2863e-02,  3.6009e-01,  8.6404e-01,  4.0322e-02, -3.2162e-01,\n",
       "                         3.5352e-01, -2.1468e-01,  3.1397e-01,  3.5374e-01,  4.3479e-01,\n",
       "                        -1.3899e-01,  3.2138e-01,  2.1622e-01, -4.3205e-01,  1.3703e+00,\n",
       "                        -2.6831e-02, -1.5741e+00, -4.1397e-01,  2.9652e-01,  3.4926e-01,\n",
       "                        -2.6967e-01,  2.5749e-01, -2.1242e+00, -2.9072e-01,  3.3170e-02,\n",
       "                        -3.3126e-01, -1.5147e+00, -3.5873e-01,  4.8231e-01, -2.4112e-01,\n",
       "                        -1.5982e+00,  1.4443e+00,  8.2424e-01,  4.0667e-01, -2.7575e-01,\n",
       "                         4.4572e-01, -1.2123e+00,  5.2165e-01, -3.5948e-01,  3.7463e-01,\n",
       "                         5.0908e-01, -1.3709e+00,  2.6056e-01, -9.7352e-02,  2.1693e-01,\n",
       "                         1.4871e+00,  5.4809e-01,  5.3693e-01, -1.4192e+00, -6.5896e-02,\n",
       "                         7.0509e-01,  2.6693e-01, -2.6736e-01,  4.7039e-01, -1.6592e+00]],\n",
       "                      device='cpu')),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.0210, -0.0192,  0.0207], device='cpu'))]),\n",
       " 'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc2f7846d10>,\n",
       " 'val_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7fc2f71b3f50>,\n",
       " 'loss_fn': CrossEntropyLoss(),\n",
       " 'optimizer': {'state': {0: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.3685e-03, -9.7889e-04],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-1.5353e-04,  1.4701e-04],\n",
       "            [ 3.4770e-04,  5.6011e-04],\n",
       "            [ 4.0141e-04,  1.4776e-04],\n",
       "            [-2.5883e-04, -2.0992e-03],\n",
       "            [ 1.5449e-04,  2.8779e-04],\n",
       "            [-1.5961e-04, -2.1166e-03],\n",
       "            [-1.3842e-04, -2.2399e-03],\n",
       "            [ 1.5072e-04, -1.7804e-05],\n",
       "            [-6.3255e-03, -5.2268e-03],\n",
       "            [-6.8567e-03, -5.7894e-03],\n",
       "            [ 6.2771e-04,  2.4082e-04],\n",
       "            [-6.7329e-04, -1.5038e-04],\n",
       "            [-2.5339e-05,  1.1856e-03],\n",
       "            [-1.3936e-05,  5.5602e-04],\n",
       "            [ 1.4005e-03, -3.7320e-04],\n",
       "            [-1.1718e-04, -1.4054e-04],\n",
       "            [-1.7097e-03, -1.7043e-03],\n",
       "            [ 9.6552e-04, -1.8317e-04],\n",
       "            [-5.6341e-03, -4.8512e-03],\n",
       "            [-4.7633e-04, -6.8443e-05],\n",
       "            [ 3.9150e-04, -5.0092e-04],\n",
       "            [-5.4490e-05, -1.8349e-03],\n",
       "            [ 2.7189e-04,  7.2915e-05],\n",
       "            [ 1.9915e-04,  5.5347e-04],\n",
       "            [-5.7647e-04, -3.4285e-04],\n",
       "            [ 4.0012e-04,  9.2164e-04],\n",
       "            [-2.8781e-04, -2.5235e-04],\n",
       "            [ 1.9759e-04,  6.4435e-04],\n",
       "            [-4.3568e-04, -1.7314e-03],\n",
       "            [ 1.5158e-03, -3.9147e-04],\n",
       "            [ 1.1506e-04, -3.3335e-04],\n",
       "            [ 3.8423e-04,  6.4273e-04],\n",
       "            [ 3.6895e-04, -6.1120e-04],\n",
       "            [-8.1468e-05, -1.6746e-03],\n",
       "            [ 5.1763e-04,  1.1785e-04],\n",
       "            [-1.9991e-04,  1.0824e-03],\n",
       "            [ 1.2246e-04,  1.0715e-03],\n",
       "            [ 1.5480e-03, -1.0355e-03],\n",
       "            [ 8.7689e-04,  1.1037e-03],\n",
       "            [-1.0752e-03, -1.4165e-03],\n",
       "            [ 5.6452e-04,  3.2944e-04],\n",
       "            [-2.0407e-04, -2.4012e-03],\n",
       "            [ 1.8807e-04,  5.6039e-04],\n",
       "            [ 5.5348e-04,  6.4214e-04],\n",
       "            [-4.2972e-04, -3.0965e-04],\n",
       "            [ 1.5004e-04,  8.1886e-04],\n",
       "            [ 4.3808e-04,  8.1595e-04],\n",
       "            [-1.7890e-03, -1.7042e-03],\n",
       "            [ 1.0602e-03,  1.3846e-03],\n",
       "            [-8.7528e-04, -6.9610e-04],\n",
       "            [-4.5349e-05,  6.3485e-04],\n",
       "            [-5.5836e-04, -4.5324e-04],\n",
       "            [ 4.4856e-05,  1.9974e-04],\n",
       "            [-7.6765e-04, -4.7949e-04],\n",
       "            [-4.9034e-04, -2.5633e-04],\n",
       "            [-6.2581e-04, -1.3375e-04],\n",
       "            [-2.2984e-03, -2.6768e-03],\n",
       "            [ 1.5975e-03, -5.0898e-04],\n",
       "            [ 3.3004e-04,  5.1178e-04],\n",
       "            [-7.5813e-03, -6.5530e-03],\n",
       "            [-3.7074e-04, -2.8526e-03],\n",
       "            [ 1.8103e-03,  1.7346e-03],\n",
       "            [ 4.2191e-05,  2.5326e-04],\n",
       "            [ 3.1980e-05, -2.1523e-03],\n",
       "            [ 7.0600e-04,  8.8419e-04],\n",
       "            [ 1.2390e-03, -8.7540e-04],\n",
       "            [-7.0661e-04, -1.6852e-04],\n",
       "            [ 8.3661e-04, -1.3591e-04],\n",
       "            [ 1.4837e-04, -4.6583e-04],\n",
       "            [ 5.2257e-04, -4.6976e-04],\n",
       "            [-8.3341e-05, -1.1003e-04],\n",
       "            [ 2.2515e-05,  8.3550e-04],\n",
       "            [ 1.8113e-04,  2.3376e-05],\n",
       "            [ 4.5811e-04, -3.2224e-04],\n",
       "            [ 1.4914e-03, -2.5039e-04],\n",
       "            [ 4.8546e-04, -1.4889e-04],\n",
       "            [-6.2937e-04, -1.2823e-04],\n",
       "            [ 3.0234e-04, -4.3830e-05],\n",
       "            [-3.4690e-04,  7.5189e-04],\n",
       "            [ 2.0117e-04, -1.3202e-03],\n",
       "            [ 1.1593e-03,  1.2195e-03],\n",
       "            [ 4.2052e-04, -6.4088e-04],\n",
       "            [ 3.1860e-05,  6.9035e-04],\n",
       "            [ 2.3286e-04,  4.1042e-04],\n",
       "            [ 8.3210e-06, -1.5833e-05],\n",
       "            [-6.4171e-04, -9.9525e-05],\n",
       "            [ 0.0000e+00,  0.0000e+00],\n",
       "            [-2.1352e-04, -9.8869e-05],\n",
       "            [ 7.0911e-04, -2.0344e-04],\n",
       "            [-2.4645e-04, -3.9571e-04],\n",
       "            [ 5.6229e-04,  6.2525e-04],\n",
       "            [-6.9708e-05, -1.7574e-04],\n",
       "            [-5.6052e-45, -5.6052e-45],\n",
       "            [ 8.7715e-04,  1.8032e-04],\n",
       "            [-8.7034e-04,  2.4251e-04],\n",
       "            [-1.0598e-03, -8.6951e-04],\n",
       "            [ 3.9212e-04,  6.0674e-04],\n",
       "            [ 2.7102e-04, -3.0535e-04]], device='cpu'),\n",
       "    'exp_avg_sq': tensor([[2.9894e-05, 2.0862e-05],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [6.0251e-06, 7.8995e-06],\n",
       "            [5.5849e-06, 8.5187e-06],\n",
       "            [4.7381e-05, 2.4069e-05],\n",
       "            [2.1180e-05, 7.8678e-05],\n",
       "            [1.8898e-06, 4.0898e-06],\n",
       "            [2.6482e-05, 7.1318e-05],\n",
       "            [3.5205e-05, 9.7363e-05],\n",
       "            [2.9866e-05, 8.9027e-06],\n",
       "            [1.0974e-04, 6.7453e-05],\n",
       "            [1.1669e-04, 7.4314e-05],\n",
       "            [9.0335e-06, 1.7235e-05],\n",
       "            [6.9564e-06, 7.4705e-06],\n",
       "            [4.1496e-06, 9.2421e-06],\n",
       "            [1.2178e-05, 8.7653e-06],\n",
       "            [7.8970e-05, 2.5813e-05],\n",
       "            [5.2842e-06, 9.1980e-06],\n",
       "            [1.4356e-05, 8.9021e-06],\n",
       "            [3.3591e-05, 1.5344e-05],\n",
       "            [1.0071e-04, 7.5881e-05],\n",
       "            [8.1656e-06, 8.6439e-06],\n",
       "            [4.8495e-06, 4.6709e-06],\n",
       "            [2.1401e-05, 5.3582e-05],\n",
       "            [4.0187e-06, 9.7952e-06],\n",
       "            [5.2072e-06, 4.4688e-06],\n",
       "            [5.9999e-05, 3.8582e-05],\n",
       "            [9.8872e-06, 1.0581e-05],\n",
       "            [1.8265e-05, 7.7799e-06],\n",
       "            [4.3653e-06, 1.2428e-05],\n",
       "            [2.4383e-05, 4.5762e-05],\n",
       "            [9.2719e-05, 3.2864e-05],\n",
       "            [2.8440e-06, 3.0675e-06],\n",
       "            [2.1047e-06, 1.9826e-06],\n",
       "            [7.2711e-06, 5.9379e-06],\n",
       "            [2.4035e-05, 4.4343e-05],\n",
       "            [6.8647e-06, 1.4762e-05],\n",
       "            [5.6567e-06, 2.0663e-05],\n",
       "            [4.1377e-06, 5.7797e-06],\n",
       "            [3.5468e-05, 2.1003e-05],\n",
       "            [3.8189e-06, 5.7153e-06],\n",
       "            [3.6282e-06, 2.8937e-06],\n",
       "            [2.9132e-06, 5.3829e-06],\n",
       "            [1.8301e-05, 5.5533e-05],\n",
       "            [4.2198e-06, 3.8905e-06],\n",
       "            [2.1029e-06, 2.4976e-06],\n",
       "            [1.2512e-05, 9.3198e-06],\n",
       "            [3.7511e-06, 5.0748e-06],\n",
       "            [7.9378e-06, 4.4012e-06],\n",
       "            [1.5468e-05, 8.7927e-06],\n",
       "            [5.8105e-06, 1.0606e-05],\n",
       "            [3.9697e-06, 2.9507e-06],\n",
       "            [4.2912e-06, 1.0321e-05],\n",
       "            [2.9222e-05, 2.1532e-05],\n",
       "            [4.7618e-06, 1.2476e-05],\n",
       "            [5.3888e-06, 2.4542e-06],\n",
       "            [1.3708e-05, 5.2420e-06],\n",
       "            [1.2482e-05, 4.0013e-06],\n",
       "            [2.0079e-05, 1.4950e-05],\n",
       "            [4.7264e-05, 1.6006e-05],\n",
       "            [2.9141e-06, 2.3943e-06],\n",
       "            [1.3464e-04, 8.7124e-05],\n",
       "            [3.6629e-05, 1.1103e-04],\n",
       "            [1.1945e-05, 7.8221e-06],\n",
       "            [4.9133e-06, 9.5781e-06],\n",
       "            [2.6801e-05, 9.5245e-05],\n",
       "            [2.9837e-06, 6.4312e-06],\n",
       "            [1.5170e-05, 1.3957e-05],\n",
       "            [5.4162e-06, 4.7453e-06],\n",
       "            [7.9063e-06, 1.3170e-05],\n",
       "            [7.2473e-06, 6.0861e-06],\n",
       "            [1.3115e-05, 6.8743e-06],\n",
       "            [1.0159e-05, 5.3390e-06],\n",
       "            [5.8869e-06, 8.6440e-06],\n",
       "            [4.8304e-06, 1.0895e-05],\n",
       "            [4.3112e-06, 7.9128e-06],\n",
       "            [1.0641e-04, 2.9429e-05],\n",
       "            [2.0771e-05, 6.9678e-06],\n",
       "            [2.2088e-05, 1.3070e-05],\n",
       "            [1.2947e-06, 1.5947e-06],\n",
       "            [4.1441e-06, 2.3040e-05],\n",
       "            [2.2479e-05, 2.5862e-05],\n",
       "            [4.9452e-06, 9.2864e-06],\n",
       "            [7.5554e-06, 5.3895e-06],\n",
       "            [4.1172e-06, 1.1379e-05],\n",
       "            [7.0791e-06, 1.6573e-05],\n",
       "            [8.2115e-05, 4.8286e-05],\n",
       "            [1.2381e-05, 4.1259e-06],\n",
       "            [0.0000e+00, 0.0000e+00],\n",
       "            [1.0595e-05, 7.9708e-06],\n",
       "            [9.4128e-05, 3.4065e-05],\n",
       "            [3.9718e-05, 2.9561e-05],\n",
       "            [2.8540e-06, 7.8989e-06],\n",
       "            [9.6461e-05, 5.6295e-05],\n",
       "            [3.3248e-09, 2.4441e-08],\n",
       "            [6.3192e-05, 2.9412e-05],\n",
       "            [2.2291e-05, 5.4483e-05],\n",
       "            [8.4831e-06, 4.4685e-06],\n",
       "            [3.9400e-06, 1.5397e-05],\n",
       "            [4.6681e-06, 1.0764e-05]], device='cpu')},\n",
       "   1: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 1.2413e-03,  0.0000e+00,  2.1401e-03, -2.1070e-03,  1.2780e-04,\n",
       "             1.7331e-03, -5.4336e-05,  1.7280e-03,  1.8056e-03,  2.5196e-04,\n",
       "            -3.0120e-03, -3.2953e-03, -1.0933e-03,  4.0869e-06, -1.7176e-03,\n",
       "            -1.1794e-03, -4.2960e-04,  1.6638e-03, -9.4908e-04, -1.8080e-04,\n",
       "            -2.6602e-03,  1.0205e-03,  1.1631e-03,  1.4377e-03,  9.3997e-04,\n",
       "             2.4855e-03, -1.7002e-04, -1.4113e-03,  6.0061e-04, -1.4508e-03,\n",
       "             1.5234e-03, -4.4235e-04,  1.0702e-04,  4.2038e-04, -1.2972e-03,\n",
       "             1.3272e-03,  2.6415e-03, -5.5739e-04, -9.1029e-04,  1.3823e-03,\n",
       "            -4.0860e-04, -7.8731e-04,  1.2282e-03,  1.9547e-03,  1.1446e-03,\n",
       "             3.4610e-04,  3.3440e-04,  3.5703e-04,  1.1439e-03,  1.0327e-04,\n",
       "            -2.7144e-05, -6.7892e-04, -9.6110e-04,  6.7140e-04,  2.9252e-04,\n",
       "             2.1769e-04,  6.7627e-04,  9.0693e-04,  3.2402e-05, -6.0541e-04,\n",
       "             1.0902e-03, -3.6970e-03,  2.3651e-03,  1.7198e-03,  2.0758e-04,\n",
       "             1.6676e-03, -4.3561e-04,  1.2385e-03,  1.3972e-04, -5.2263e-04,\n",
       "             1.6364e-03,  1.2285e-03, -3.5640e-04, -2.0757e-03, -4.3214e-04,\n",
       "             1.1349e-03, -4.4187e-04, -1.1329e-04,  9.8619e-04, -4.9398e-04,\n",
       "            -2.8966e-04,  9.5354e-04,  9.8751e-04, -1.0231e-03, -7.8575e-04,\n",
       "             4.3610e-04,  2.5700e-04,  1.0849e-03,  0.0000e+00,  6.0341e-04,\n",
       "            -1.0964e-04,  9.0385e-05,  4.9824e-04,  2.7123e-04,  5.6052e-45,\n",
       "             6.7382e-05, -1.6602e-04, -8.3391e-04,  6.1497e-04,  9.9754e-04],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([2.4884e-05, 0.0000e+00, 1.1075e-04, 2.8478e-05, 1.9747e-05, 3.0582e-05,\n",
       "            1.4319e-05, 2.8817e-05, 3.9024e-05, 1.4432e-05, 5.5994e-05, 5.4243e-05,\n",
       "            6.1636e-05, 6.9576e-05, 1.0334e-04, 6.5142e-05, 2.7396e-05, 1.3353e-04,\n",
       "            4.8722e-05, 1.3593e-05, 5.1978e-05, 1.1991e-04, 6.6532e-06, 2.1585e-05,\n",
       "            4.6962e-05, 6.1669e-05, 2.6836e-05, 4.8969e-05, 9.5377e-06, 7.8949e-05,\n",
       "            2.3910e-05, 3.2371e-05, 2.3612e-05, 2.2335e-05, 9.3993e-05, 1.9217e-05,\n",
       "            6.5282e-05, 1.6510e-05, 7.6668e-05, 2.4473e-05, 2.6667e-05, 2.1374e-05,\n",
       "            1.5012e-05, 1.9666e-05, 4.2970e-05, 9.1575e-06, 8.7729e-06, 9.7040e-05,\n",
       "            4.2006e-05, 5.1129e-05, 3.9294e-05, 1.2390e-05, 4.6126e-05, 1.5978e-05,\n",
       "            1.0419e-05, 1.6949e-05, 9.2859e-06, 7.3573e-06, 9.7850e-05, 1.7123e-05,\n",
       "            2.2947e-05, 6.9213e-05, 4.1763e-05, 1.3542e-05, 9.2946e-06, 3.5421e-05,\n",
       "            2.5060e-05, 1.9104e-05, 4.6314e-05, 5.7135e-05, 1.0356e-04, 1.1956e-05,\n",
       "            3.3585e-05, 5.8598e-05, 4.1799e-05, 7.3911e-06, 3.4269e-05, 7.7023e-06,\n",
       "            1.5150e-05, 1.7780e-05, 1.3203e-05, 1.3162e-05, 7.2062e-06, 1.0011e-04,\n",
       "            4.5737e-05, 1.6265e-05, 4.0442e-05, 7.8629e-06, 0.0000e+00, 7.4622e-06,\n",
       "            3.2206e-05, 1.8701e-05, 7.0091e-06, 4.7804e-05, 6.9405e-09, 2.7263e-05,\n",
       "            2.7236e-05, 2.5877e-05, 1.1910e-05, 9.2307e-06], device='cpu')},\n",
       "   2: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([[ 1.9148e-03,  0.0000e+00, -6.4087e-04,  2.2770e-03,  9.1002e-05,\n",
       "              2.6836e-05,  1.8530e-03,  8.6032e-05,  3.9000e-05,  5.1196e-04,\n",
       "              6.9420e-06,  2.6434e-06,  1.7608e-03, -4.9971e-04,  3.1602e-03,\n",
       "              2.6920e-03,  1.8821e-04, -8.0562e-04,  1.1994e-03,  2.2188e-04,\n",
       "              2.8725e-07, -6.0225e-04,  2.0838e-03,  1.5501e-04,  2.5328e-03,\n",
       "              3.8492e-04,  1.4026e-09,  2.6370e-03, -4.6602e-04,  1.7343e-03,\n",
       "              2.2572e-04,  2.3688e-04,  1.7973e-03, -5.2248e-05,  2.6328e-03,\n",
       "              1.2512e-04, -1.4213e-04,  1.4913e-04,  2.9005e-03,  2.0072e-03,\n",
       "              1.6903e-03,  1.1882e-03,  9.4613e-04,  5.5799e-05,  4.6623e-04,\n",
       "              9.3147e-04,  2.5528e-04,  3.5379e-03,  7.0568e-04,  4.2017e-04,\n",
       "              1.1599e-03,  7.3700e-04,  2.5529e-03, -2.0822e-04, -8.5732e-06,\n",
       "              1.3828e-03,  6.4003e-04,  4.9042e-04,  1.0241e-03,  2.7613e-04,\n",
       "              4.7320e-04,  1.2209e-07,  8.7426e-05, -1.3467e-04,  2.5461e-05,\n",
       "              1.1793e-05,  2.0349e-03,  2.2759e-03, -1.2885e-04, -4.2406e-04,\n",
       "              1.9066e-03,  1.6041e-03,  7.4799e-04,  2.7313e-03,  3.3153e-03,\n",
       "              2.3426e-03,  1.8831e-04,  2.3103e-04,  4.1449e-04,  1.3264e-03,\n",
       "              2.1472e-04,  7.0703e-04, -6.7006e-05,  2.4181e-03,  2.4755e-03,\n",
       "              1.5362e-05,  3.5085e-07,  5.4447e-04,  0.0000e+00, -3.5008e-06,\n",
       "              1.1446e-04, -1.7291e-04, -3.1090e-06,  7.7901e-07, -5.6052e-45,\n",
       "              2.4671e-05,  9.3661e-05,  8.0640e-04, -2.2069e-05,  1.8491e-03],\n",
       "            [-1.8976e-03,  0.0000e+00, -5.3835e-03, -1.4445e-03,  2.4932e-06,\n",
       "             -3.0759e-05, -4.8041e-04, -1.0689e-04, -4.9258e-05, -5.5717e-04,\n",
       "             -1.4166e-03, -1.2623e-03, -7.2509e-04, -4.2311e-03, -1.5318e-03,\n",
       "             -1.0736e-03,  2.3063e-07, -6.4847e-03, -2.7663e-03,  6.5786e-06,\n",
       "             -1.3122e-03, -7.1421e-05, -2.1086e-03, -1.8271e-04,  5.2461e-05,\n",
       "             -4.5110e-03, -2.2947e-04, -1.3828e-03,  1.9977e-04, -1.4966e-03,\n",
       "             -2.1154e-05,  3.1748e-07, -1.1469e-03, -3.9914e-03, -1.9943e-03,\n",
       "             -1.4882e-04, -5.3266e-03, -4.9536e-03, -1.5862e-03, -2.0874e-03,\n",
       "             -1.1162e-03, -1.9307e-03, -4.2645e-03, -6.2926e-05, -4.5023e-03,\n",
       "             -2.5568e-03,  8.3519e-05, -2.6825e-03, -4.0807e-03, -1.9652e-03,\n",
       "             -3.8733e-04, -1.7048e-03, -1.7078e-03,  1.2500e-04, -4.4936e-03,\n",
       "             -5.2958e-03,  4.7173e-06, -2.9854e-05, -1.2530e-03,  4.6178e-08,\n",
       "             -4.0904e-03, -1.1643e-03, -1.0416e-04, -2.4701e-03, -5.4759e-03,\n",
       "             -1.1933e-05, -1.5765e-03, -2.2191e-03, -4.5739e-03, -3.1064e-03,\n",
       "             -4.6623e-04, -1.6386e-03, -9.9281e-04, -1.2042e-03, -1.5496e-03,\n",
       "             -2.1133e-03,  8.5606e-08,  4.4553e-07, -1.3893e-05, -7.9446e-04,\n",
       "             -6.3985e-03, -8.0693e-04, -3.8430e-03, -1.7195e-03, -1.3740e-03,\n",
       "             -4.7389e-03, -1.3716e-04, -1.8261e-05,  0.0000e+00,  1.3846e-04,\n",
       "              1.0599e-07,  1.4233e-04, -5.3392e-03, -1.3383e-04,  5.6052e-45,\n",
       "             -9.2179e-05, -3.9779e-03, -4.2430e-03, -5.2357e-03, -1.8627e-03],\n",
       "            [-1.7251e-05,  0.0000e+00,  6.0243e-03, -8.3248e-04, -9.3496e-05,\n",
       "              3.9232e-06, -1.3726e-03,  2.0857e-05,  1.0257e-05,  4.5207e-05,\n",
       "              1.4096e-03,  1.2597e-03, -1.0357e-03,  4.7308e-03, -1.6283e-03,\n",
       "             -1.6184e-03, -1.8844e-04,  7.2903e-03,  1.5670e-03, -2.2846e-04,\n",
       "              1.3119e-03,  6.7367e-04,  2.4728e-05,  2.7707e-05, -2.5853e-03,\n",
       "              4.1261e-03,  2.2947e-04, -1.2542e-03,  2.6626e-04, -2.3775e-04,\n",
       "             -2.0456e-04, -2.3719e-04, -6.5039e-04,  4.0437e-03, -6.3851e-04,\n",
       "              2.3703e-05,  5.4687e-03,  4.8044e-03, -1.3143e-03,  8.0191e-05,\n",
       "             -5.7415e-04,  7.4251e-04,  3.3183e-03,  7.1275e-06,  4.0361e-03,\n",
       "              1.6253e-03, -3.3880e-04, -8.5535e-04,  3.3751e-03,  1.5451e-03,\n",
       "             -7.7254e-04,  9.6780e-04, -8.4515e-04,  8.3221e-05,  4.5022e-03,\n",
       "              3.9130e-03, -6.4475e-04, -4.6057e-04,  2.2889e-04, -2.7618e-04,\n",
       "              3.6172e-03,  1.1641e-03,  1.6737e-05,  2.6048e-03,  5.4504e-03,\n",
       "              1.3980e-07, -4.5844e-04, -5.6775e-05,  4.7028e-03,  3.5305e-03,\n",
       "             -1.4403e-03,  3.4473e-05,  2.4482e-04, -1.5271e-03, -1.7657e-03,\n",
       "             -2.2934e-04, -1.8839e-04, -2.3148e-04, -4.0060e-04, -5.3195e-04,\n",
       "              6.1838e-03,  9.9894e-05,  3.9100e-03, -6.9856e-04, -1.1015e-03,\n",
       "              4.7235e-03,  1.3681e-04, -5.2621e-04,  0.0000e+00, -1.3496e-04,\n",
       "             -1.1457e-04,  3.0584e-05,  5.3424e-03,  1.3305e-04,  5.6052e-45,\n",
       "              6.7508e-05,  3.8843e-03,  3.4366e-03,  5.2577e-03,  1.3622e-05]],\n",
       "           device='cpu'),\n",
       "    'exp_avg_sq': tensor([[6.4908e-05, 0.0000e+00, 4.5172e-05, 7.2541e-05, 7.4253e-06, 1.4921e-05,\n",
       "             7.6572e-05, 1.8703e-05, 9.1779e-06, 1.2833e-05, 2.9514e-07, 8.1014e-08,\n",
       "             6.4832e-05, 4.8813e-05, 7.9747e-05, 1.1294e-04, 2.2889e-06, 4.2622e-05,\n",
       "             8.7528e-05, 4.5545e-06, 2.0528e-07, 2.2162e-05, 6.1479e-05, 1.7558e-05,\n",
       "             2.1804e-04, 6.2589e-05, 9.0310e-07, 1.2256e-04, 5.9290e-05, 4.3034e-05,\n",
       "             5.1999e-06, 3.9317e-06, 1.0906e-04, 9.4605e-05, 1.9262e-04, 1.5016e-05,\n",
       "             6.5589e-05, 3.2433e-06, 8.1426e-05, 5.8041e-05, 6.4111e-05, 7.9104e-05,\n",
       "             1.1771e-04, 6.5464e-06, 9.3228e-05, 8.4045e-05, 8.0960e-05, 9.8021e-05,\n",
       "             1.2328e-04, 4.1216e-05, 1.4068e-04, 6.0294e-05, 1.2128e-04, 2.2258e-05,\n",
       "             6.6251e-06, 1.8613e-04, 5.1501e-05, 3.8984e-05, 4.7221e-05, 3.2981e-06,\n",
       "             8.6060e-05, 6.4993e-08, 3.0537e-06, 2.1851e-05, 7.4476e-06, 7.2780e-06,\n",
       "             1.3315e-04, 5.2258e-05, 8.3260e-05, 4.9945e-05, 1.7031e-04, 5.6256e-05,\n",
       "             6.6114e-05, 7.5945e-05, 2.8194e-04, 4.6967e-05, 3.8770e-06, 1.2854e-05,\n",
       "             2.9463e-05, 2.0884e-05, 7.2924e-06, 3.2173e-05, 7.5972e-06, 1.3803e-04,\n",
       "             1.8576e-04, 3.9558e-06, 9.1571e-07, 5.5460e-05, 0.0000e+00, 4.1506e-05,\n",
       "             1.3975e-06, 3.6500e-05, 7.4952e-06, 6.6582e-07, 1.7253e-08, 4.6141e-06,\n",
       "             5.3332e-06, 1.1449e-04, 5.3597e-06, 6.4235e-05],\n",
       "            [6.6722e-05, 0.0000e+00, 1.3387e-04, 7.1131e-05, 9.7337e-07, 1.2453e-05,\n",
       "             9.1711e-05, 1.6653e-05, 7.4060e-06, 1.5622e-05, 1.0625e-05, 6.0159e-06,\n",
       "             5.7119e-05, 9.0648e-05, 1.1068e-04, 1.8146e-04, 7.2226e-07, 1.7081e-04,\n",
       "             6.4408e-05, 9.6095e-07, 1.0813e-05, 8.3958e-05, 6.5160e-05, 1.6684e-05,\n",
       "             2.1017e-04, 1.2507e-04, 1.5685e-05, 1.3952e-04, 6.5477e-06, 5.9716e-05,\n",
       "             3.3990e-06, 7.7238e-08, 8.0088e-05, 1.5967e-04, 1.1736e-04, 1.3784e-05,\n",
       "             2.4043e-04, 7.2247e-05, 1.1309e-04, 5.9302e-05, 1.1321e-04, 6.7086e-05,\n",
       "             3.1161e-04, 5.6012e-06, 1.7609e-04, 1.7313e-04, 1.0401e-05, 1.2129e-04,\n",
       "             1.8508e-04, 4.2316e-05, 2.4041e-04, 6.9049e-05, 1.7614e-04, 3.1937e-06,\n",
       "             5.9308e-05, 1.9877e-04, 8.0618e-06, 6.9463e-06, 2.7703e-05, 1.9432e-07,\n",
       "             1.7198e-04, 4.9560e-06, 2.5006e-06, 2.7078e-05, 9.8456e-05, 6.5633e-06,\n",
       "             2.2639e-04, 5.6147e-05, 1.1864e-04, 1.7805e-04, 1.0598e-04, 6.3804e-05,\n",
       "             5.8399e-05, 1.1424e-04, 2.9579e-04, 5.0576e-05, 1.2032e-07, 5.3376e-06,\n",
       "             8.3701e-06, 2.0288e-05, 1.2876e-04, 2.9857e-05, 3.1037e-05, 7.2702e-05,\n",
       "             2.6582e-04, 6.6650e-05, 1.5067e-05, 6.7038e-06, 0.0000e+00, 1.1897e-05,\n",
       "             8.5883e-08, 2.6474e-06, 8.8264e-05, 8.8810e-06, 9.3212e-09, 4.7053e-06,\n",
       "             6.3238e-05, 1.2195e-04, 7.5259e-05, 6.7891e-05],\n",
       "            [4.5509e-06, 0.0000e+00, 1.5556e-04, 2.7954e-05, 1.0383e-05, 5.1690e-07,\n",
       "             6.9467e-05, 5.9025e-07, 5.7430e-07, 2.9873e-06, 9.0229e-06, 5.5513e-06,\n",
       "             3.3280e-05, 1.1667e-04, 4.2215e-05, 9.2492e-05, 3.1782e-06, 1.9297e-04,\n",
       "             1.0182e-04, 5.5986e-06, 9.9865e-06, 9.4177e-05, 5.0393e-06, 5.6285e-07,\n",
       "             1.3614e-04, 1.4957e-04, 1.2885e-05, 3.9855e-05, 6.1949e-05, 2.5701e-05,\n",
       "             1.9740e-06, 4.4134e-06, 1.0760e-04, 1.8225e-04, 1.5694e-04, 7.3093e-07,\n",
       "             2.4798e-04, 7.6159e-05, 4.0709e-05, 2.4062e-06, 9.0308e-05, 1.0141e-04,\n",
       "             3.0613e-04, 1.2629e-06, 2.0115e-04, 1.7053e-04, 8.1140e-05, 3.6939e-05,\n",
       "             2.2321e-04, 5.6785e-05, 1.5545e-04, 7.6325e-05, 8.9253e-05, 2.3009e-05,\n",
       "             6.6458e-05, 2.5965e-04, 4.7672e-05, 3.5964e-05, 4.6474e-05, 3.8536e-06,\n",
       "             2.0909e-04, 4.4806e-06, 1.6336e-07, 5.0364e-05, 1.0358e-04, 4.8466e-07,\n",
       "             1.4324e-04, 3.7833e-06, 1.6976e-04, 1.6752e-04, 1.3052e-04, 1.0001e-05,\n",
       "             8.3333e-05, 6.1249e-05, 1.5919e-04, 4.4816e-06, 4.4414e-06, 2.2213e-05,\n",
       "             2.3331e-05, 2.0145e-05, 1.3291e-04, 2.8081e-06, 4.2382e-05, 1.1949e-04,\n",
       "             1.2478e-04, 7.1384e-05, 1.1799e-05, 5.3296e-05, 0.0000e+00, 5.4644e-05,\n",
       "             1.6489e-06, 3.7039e-05, 9.2785e-05, 7.1852e-06, 1.2497e-09, 9.6387e-06,\n",
       "             6.0108e-05, 1.8237e-04, 8.1837e-05, 7.3964e-06]], device='cpu')},\n",
       "   3: {'step': tensor(1071.),\n",
       "    'exp_avg': tensor([ 0.0031, -0.0027, -0.0004], device='cpu'),\n",
       "    'exp_avg_sq': tensor([0.0002, 0.0003, 0.0003], device='cpu')}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'params': [0, 1, 2, 3]}]},\n",
       " 'scheduler': {'factor': 0.1,\n",
       "  'min_lrs': [0],\n",
       "  'patience': 3,\n",
       "  'verbose': False,\n",
       "  'cooldown': 0,\n",
       "  'cooldown_counter': 0,\n",
       "  'mode': 'min',\n",
       "  'threshold': 0.0001,\n",
       "  'threshold_mode': 'rel',\n",
       "  'best': 0.0661608474329114,\n",
       "  'num_bad_epochs': 2,\n",
       "  'mode_worse': inf,\n",
       "  'eps': 1e-08,\n",
       "  'last_epoch': 63,\n",
       "  '_last_lr': [0.0001]},\n",
       " 'num_epochs': 100,\n",
       " 'patience': 6}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_trainer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 0,\n",
       "       2, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2,\n",
       "       2, 1, 0, 0, 2, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2,\n",
       "       1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 0, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 2,\n",
       "       2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 1, 0, 0, 0, 0, 1, 2, 1,\n",
       "       0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       2, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 2, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "y_prob = trainer.predict_step()\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 0,\n",
       "       2, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2,\n",
       "       2, 1, 0, 0, 2, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2,\n",
       "       1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 1, 2, 2, 0, 0, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 2,\n",
       "       2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 2, 0, 2, 1, 0, 0, 0, 0, 1, 2, 1,\n",
       "       0, 1, 2, 0, 0, 1, 2, 1, 0, 1, 2, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 0,\n",
       "       2, 1, 0, 2, 1, 2, 0, 0, 1, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 2, 1, 1, 0, 0, 0, 2, 1, 2, 2, 0, 2, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 2, 1, 0, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 2, 2, 2, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inference\n",
    "new_y_prob = new_trainer.predict_step()\n",
    "new_y_pred = np.argmax(new_y_prob, axis=1)\n",
    "new_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(y_pred == new_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Made-With-ML-Foundations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
