{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import PyTorch and set seeds for reproducibility. Note that PyTorch also required a seed since we will be generating random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7890544cb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(seed=SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "We'll first cover some basics with PyTorch such as creating tensors and converting from common data structures (lists, arrays, etc.) to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0461,  0.4024, -1.0115],\n",
      "        [ 0.2167, -0.6123,  0.5036]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a random tensor\n",
    "x = torch.randn(2, 3) # normal distribution (rand(2,3) -> uniform distribution)\n",
    "print(f\"Type: {x.type()}\")\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Zero and Ones tensor\n",
    "x = torch.zeros(2, 3)\n",
    "print (x)\n",
    "x = torch.ones(2, 3)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# List → Tensor\n",
    "x = torch.Tensor([[1, 2, 3],[4, 5, 6]])\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.1915, 0.6221, 0.4377],\n",
      "        [0.7854, 0.7800, 0.2726]])\n"
     ]
    }
   ],
   "source": [
    "# NumPy array → Tensor\n",
    "x = torch.Tensor(np.random.rand(2, 3))\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Changing tensor type\n",
    "x = torch.Tensor(3, 4)\n",
    "print(f\"Type: {x.type()}\")\n",
    "x = x.long()\n",
    "print(f\"Type: {x.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "Now we'll explore some basic operations with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0761, -0.6775, -0.3988],\n",
      "        [ 3.0633, -0.1589,  0.3514]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "z = x + y\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 1.0796, -0.0759],\n",
      "        [ 1.2746, -0.5134]])\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(3, 2)\n",
    "z = torch.mm(x, y)\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.8042, -0.1383,  0.3196],\n",
      "        [-1.0187, -1.3147,  2.5228]])\n",
      "Size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[ 0.8042, -1.0187],\n",
      "        [-0.1383, -1.3147],\n",
      "        [ 0.3196,  2.5228]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.t(x)\n",
    "print(f\"Size: {y.shape}\")\n",
    "print(f\"Values: \\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8042, -1.0187],\n",
       "        [-0.1383, -1.3147],\n",
       "        [ 0.3196,  2.5228]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[ 0.4501,  0.2709],\n",
      "        [-0.8087, -0.0217],\n",
      "        [-1.0413,  0.0702]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "x = torch.randn(2, 3)\n",
    "z = x.view(3, 2)\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3, 4])\n",
      "x: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [ 2,  2,  2,  2],\n",
      "         [ 3,  3,  3,  3]],\n",
      "\n",
      "        [[10, 10, 10, 10],\n",
      "         [20, 20, 20, 20],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "a: \n",
      "tensor([[ 1,  1,  1,  1,  2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3, 10, 10, 10, 10],\n",
      "        [20, 20, 20, 20, 30, 30, 30, 30]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 2, 4])\n",
      "b: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [10, 10, 10, 10]],\n",
      "\n",
      "        [[ 2,  2,  2,  2],\n",
      "         [20, 20, 20, 20]],\n",
      "\n",
      "        [[ 3,  3,  3,  3],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "c: \n",
      "tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],\n",
      "        [ 2,  2,  2,  2, 20, 20, 20, 20],\n",
      "        [ 3,  3,  3,  3, 30, 30, 30, 30]])\n"
     ]
    }
   ],
   "source": [
    "# Dangers of reshaping (unintended consequences)\n",
    "x = torch.tensor([\n",
    "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
    "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
    "])\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"x: \\n{x}\\n\")\n",
    "\n",
    "a = x.view(x.size(1), -1)\n",
    "print(f\"\\nSize: {a.shape}\")\n",
    "print(f\"a: \\n{a}\\n\")\n",
    "\n",
    "# Because x.transpose(0,1) is not already contiguous, x.transpose(0, 1).contiguous()\n",
    "# makes a copy of the underlying data and changes the memory layout. Therefore,\n",
    "# b.view(x.size(0), -1) returns a different view.\n",
    "b = x.transpose(0,1).contiguous()\n",
    "print(f\"\\nSize: {b.shape}\")\n",
    "print(f\"b: \\n{b}\\n\")\n",
    "\n",
    "c = b.view(b.size(0), -1)\n",
    "print(f\"\\nSize: {c.shape}\")\n",
    "print(f\"c: \\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[ 0.5797, -0.0599,  0.1816],\n",
      "        [-0.6797, -0.2567, -1.8189]])\n",
      "Values: \n",
      "tensor([-0.1000, -0.3166, -1.6373])\n",
      "Values: \n",
      "tensor([ 0.7013, -2.7553])\n"
     ]
    }
   ],
   "source": [
    "# Dimensional operations\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.sum(x, dim=0) # add each row's value for every column\n",
    "print(f\"Values: \\n{y}\")\n",
    "z = torch.sum(x, dim=1) # add each columns's value for every row\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "Now we'll look at how to extract, separate and join values from our tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[ 0.2111,  0.3372,  0.6638,  1.0397],\n",
      "        [ 1.8434,  0.6588, -0.2349, -0.0306],\n",
      "        [ 1.7462, -0.0722, -1.6794, -1.7010]])\n",
      "x[:1]: \n",
      "tensor([[0.2111, 0.3372, 0.6638, 1.0397]])\n",
      "x[:1, 1:3]: \n",
      "tensor([[0.3372, 0.6638]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print (f\"x: \\n{x}\")\n",
    "print (f\"x[:1]: \\n{x[:1]}\")\n",
    "print (f\"x[:1, 1:3]: \\n{x[:1, 1:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[ 0.6486,  1.7653,  1.0812],\n",
      "        [ 1.2436,  0.8971, -0.0784]])\n",
      "Values: \n",
      "tensor([[ 0.6486,  1.0812],\n",
      "        [ 1.2436, -0.0784]])\n",
      "Values: \n",
      "tensor([ 0.6486, -0.0784])\n"
     ]
    }
   ],
   "source": [
    "# Select with dimensional indices\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "\n",
    "col_indices = torch.LongTensor([0, 2])\n",
    "chosen = torch.index_select(x, dim=1, index=col_indices) # values from column 0 & 2\n",
    "print(f\"Values: \\n{chosen}\")\n",
    "\n",
    "row_indices = torch.LongTensor([0, 1])\n",
    "col_indices = torch.LongTensor([0, 2])\n",
    "chosen = x[row_indices, col_indices] # values from (0, 0) & (1, 2)\n",
    "print(f\"Values: \\n{chosen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining\n",
    "We can also combine our tensors via concatenation or stacking operations, which are consistent with NumPy's joining functions' behaviors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5548, -0.0845,  0.5903],\n",
      "        [-1.0032, -1.7873,  0.0538]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print (x)\n",
    "print (x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5548, -0.0845,  0.5903],\n",
      "        [-1.0032, -1.7873,  0.0538],\n",
      "        [ 0.5548, -0.0845,  0.5903],\n",
      "        [-1.0032, -1.7873,  0.0538]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "y = torch.cat([x, x], dim=0) # concat on a specified dimension\n",
    "print (y)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5548, -0.0845,  0.5903],\n",
      "         [-1.0032, -1.7873,  0.0538]],\n",
      "\n",
      "        [[ 0.5548, -0.0845,  0.5903],\n",
      "         [-1.0032, -1.7873,  0.0538]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "z = torch.stack([x, x], dim=0) # stack on new dimension\n",
    "print (z)\n",
    "print (z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "We can determine gradients (rate of change) of our tensors with respect to their constituents using gradient bookkeeping. The gradient is a vector that points in the direction of greatest increase of a function. We'll be using gradients in the next lesson to determine how to change our weights to affect a particular objective function (ex. loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[0.7379, 0.0846, 0.4245, 0.9778],\n",
      "        [0.6800, 0.3151, 0.3911, 0.8943],\n",
      "        [0.6889, 0.8389, 0.1780, 0.6442]], requires_grad=True)\n",
      "x.grad: \n",
      "tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# Tensors with gradient bookkeeping\n",
    "x = torch.rand(3, 4, requires_grad=True)\n",
    "y = 3*x + 2\n",
    "z = y.mean()\n",
    "z.backward() # z has to be scalar\n",
    "print(f\"x: \\n{x}\")\n",
    "print(f\"x.grad: \\n{x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA\n",
    "We also load our tensors onto the GPU for parallelized computation using CUDA (a parallel computing platform and API from Nvidia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3)\n",
    "print (x.is_cuda)\n",
    "x = torch.rand(2,3).to(device) # Tensor is stored on the GPU\n",
    "print (x.is_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Made-With-ML-Foundations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
